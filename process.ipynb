{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Methylation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_methy_df = pd.read_csv('./raw_data/CCLE_RRBS_TSS1kb_20181022.txt', sep='\\t')\n",
    "display(raw_methy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column locus_id should be separate the content after the  '_'\n",
    "raw_methy_df['locus_id'] = raw_methy_df['locus_id'].apply(lambda x: x.split('_')[0])\n",
    "# drop na in the column locus_id\n",
    "raw_methy_df = raw_methy_df.dropna(subset=['CpG_sites_hg19'])\n",
    "# remove the column CpG_sites_hg19 and avg_coverage\n",
    "raw_methy_df = raw_methy_df.drop(columns=['CpG_sites_hg19', 'avg_coverage'])\n",
    "display(raw_methy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns to convert (all except 'locus_id')\n",
    "cols_to_convert = raw_methy_df.columns.difference(['locus_id'])\n",
    "# Convert these columns to numeric (using pd.to_numeric for safety, which can handle errors)\n",
    "raw_methy_df[cols_to_convert] = raw_methy_df[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "raw_methy_df = raw_methy_df.fillna(0.0)\n",
    "display(raw_methy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now perform the groupby mean operation\n",
    "methy_df = raw_methy_df.groupby('locus_id', as_index=False).mean()\n",
    "display(methy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmg_promoter_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Promoter/BioMedGraphica_Conn_Promoter.csv')\n",
    "# keep BioMedGraphica_ID and HGNC_Symbol\n",
    "bmg_promoter_df = bmg_promoter_df[['BioMedGraphica_Conn_ID', 'HGNC_Symbol']]\n",
    "display(bmg_promoter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the biomedgraphica_id with the raw_methy_df\n",
    "merged_methy_df = pd.merge(bmg_promoter_df, methy_df, left_on='HGNC_Symbol', right_on='locus_id', how='inner')\n",
    "merged_methy_df.drop(columns=['HGNC_Symbol', 'locus_id'], inplace=True)\n",
    "display(merged_methy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_methy_df = pd.merge(bmg_promoter_df, methy_df, left_on='HGNC_Symbol', right_on='locus_id', how='left')\n",
    "# fill the NaN with 0.0\n",
    "final_merged_methy_df = final_merged_methy_df.fillna(0.0)\n",
    "final_merged_methy_df.drop(columns=['HGNC_Symbol', 'locus_id'], inplace=True)\n",
    "display(final_merged_methy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_gene_df = pd.read_csv('./raw_data/OmicsCNGene.csv')\n",
    "display(raw_gene_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, set the \"Unnamed: 0\" column as the index:\n",
    "raw_gene_t_df = raw_gene_df.set_index(\"Unnamed: 0\")\n",
    "# Then transpose the DataFrame:\n",
    "raw_gene_t_df = raw_gene_t_df.transpose()\n",
    "# move the index to a column and rename it as the gene_name\n",
    "raw_gene_t_df.reset_index(inplace=True)\n",
    "raw_gene_t_df.rename(columns={'index': 'gene_name'}, inplace=True)\n",
    "# column gene_name should be kept with the content by removing \"()\" and remove and \" \" content\n",
    "raw_gene_t_df['gene_name'] = raw_gene_t_df['gene_name'].apply(lambda x: x.split('(')[0].strip())\n",
    "# Optionally, if you want to view the result:\n",
    "display(raw_gene_t_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns to convert (all except 'Unnamed: 0' and 'gene_name')\n",
    "cols_to_convert = raw_gene_t_df.columns.difference(['Unnamed: 0', 'gene_name'])\n",
    "# Convert these columns to numeric (using pd.to_numeric for safety, which can handle errors)\n",
    "raw_gene_t_df[cols_to_convert] = raw_gene_t_df[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "raw_gene_t_df = raw_gene_t_df.fillna(0.0)\n",
    "display(raw_gene_t_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby the gene_name and calculate the mean\n",
    "gene_df = raw_gene_t_df.groupby('gene_name', as_index=False).mean()\n",
    "display(gene_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmg_gene_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Gene/BioMedGraphica_Conn_Gene.csv')\n",
    "# keep BioMedGraphica_ID and HGNC_Symbol\n",
    "bmg_gene_df = bmg_gene_df[['BioMedGraphica_Conn_ID', 'HGNC_Symbol']]\n",
    "display(bmg_gene_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the biomedgraphica_id with the raw_gene_t_df\n",
    "merged_gene_df = pd.merge(bmg_gene_df, gene_df, left_on='HGNC_Symbol', right_on='gene_name', how='inner')\n",
    "merged_gene_df.drop(columns=['HGNC_Symbol', 'gene_name'], inplace=True)\n",
    "display(merged_gene_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_gene_df = pd.merge(bmg_gene_df, gene_df, left_on='HGNC_Symbol', right_on='gene_name', how='left')\n",
    "# fill the NaN with -1.0\n",
    "final_merged_gene_df = final_merged_gene_df.fillna(0.0)\n",
    "final_merged_gene_df.drop(columns=['HGNC_Symbol', 'gene_name'], inplace=True)\n",
    "display(final_merged_gene_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_transcript_df = pd.read_csv('./raw_data/OmicsExpressionProteinCodingGenesTPMLogp1BatchCorrected.csv')\n",
    "display(raw_transcript_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, set the \"Unnamed: 0\" column as the index:\n",
    "raw_transcript_df = raw_transcript_df.set_index(\"Unnamed: 0\")\n",
    "# Then transpose the DataFrame:\n",
    "raw_transcript_df = raw_transcript_df.transpose()\n",
    "# move the index to a column and rename it as the gene_name\n",
    "raw_transcript_df.reset_index(inplace=True)\n",
    "raw_transcript_df.rename(columns={'index': 'gene_name'}, inplace=True)\n",
    "# column gene_name should be kept with the content by removing \"()\" and remove and\n",
    "raw_transcript_df['gene_name'] = raw_transcript_df['gene_name'].apply(lambda x: x.split('(')[0].strip())\n",
    "# Optionally, if you want to view the result:\n",
    "display(raw_transcript_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns to convert (all except 'Unnamed: 0' and 'gene_name')\n",
    "cols_to_convert = raw_transcript_df.columns.difference(['Unnamed: 0', 'gene_name'])\n",
    "# Convert these columns to numeric (using pd.to_numeric for safety, which can handle errors)\n",
    "raw_transcript_df[cols_to_convert] = raw_transcript_df[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "raw_transcript_df = raw_transcript_df.fillna(0.0)\n",
    "display(raw_transcript_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmg_transcript_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Transcript/BioMedGraphica_Conn_Transcript.csv')\n",
    "# keep BioMedGraphica_ID and HGNC_Symbol\n",
    "bmg_transcript_df = bmg_transcript_df[['BioMedGraphica_Conn_ID', 'HGNC_Symbol']]\n",
    "display(bmg_transcript_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the biomedgraphica_id with the raw_transcript_df\n",
    "merge_transcript_df = pd.merge(bmg_transcript_df, raw_transcript_df, left_on='HGNC_Symbol', right_on='gene_name', how='inner')\n",
    "merge_transcript_df.drop(columns=['HGNC_Symbol', 'gene_name'], inplace=True)\n",
    "display(merge_transcript_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the biomedgraphica_id with the raw_transcript_df\n",
    "final_merged_transcript_df = pd.merge(bmg_transcript_df, raw_transcript_df, left_on='HGNC_Symbol', right_on='gene_name', how='left')\n",
    "# fill the NaN with -1.0\n",
    "final_merged_transcript_df = final_merged_transcript_df.fillna(0.0)\n",
    "final_merged_transcript_df.drop(columns=['HGNC_Symbol', 'gene_name'], inplace=True)\n",
    "display(final_merged_transcript_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_protein_df = pd.read_csv('./raw_data/protein_quant_current_normalized.csv')\n",
    "raw_protein_df = raw_protein_df.drop(columns=['Protein_Id', 'Gene_Symbol', 'Description', 'Group_ID', 'Uniprot'])\n",
    "# Also drop columns names contain Peptides\n",
    "raw_protein_df = raw_protein_df[raw_protein_df.columns.drop(list(raw_protein_df.filter(regex='Peptides')))]\n",
    "display(raw_protein_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns to convert (all except 'Unnamed: 0' and 'protein_name')\n",
    "cols_to_convert = raw_protein_df.columns.difference(['Uniprot_Acc'])\n",
    "# Convert these columns to numeric (using pd.to_numeric for safety, which can handle errors)\n",
    "raw_protein_df[cols_to_convert] = raw_protein_df[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "raw_protein_df = raw_protein_df.fillna(0.0)\n",
    "display(raw_protein_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby the protein_name and calculate the mean\n",
    "protein_df = raw_protein_df.groupby('Uniprot_Acc', as_index=False).mean()\n",
    "display(protein_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the biomedgraphica_id with the raw_protein_df\n",
    "bmg_protein_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Protein/BioMedGraphica_Conn_Protein.csv')\n",
    "bmg_protein_df = bmg_protein_df[['BioMedGraphica_Conn_ID', 'Uniprot_ID']]\n",
    "display(bmg_protein_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the biomedgraphica_id with the raw_protein_df\n",
    "merged_protein_df = pd.merge(bmg_protein_df, protein_df, left_on='Uniprot_ID', right_on='Uniprot_Acc', how='inner')\n",
    "merged_protein_df.drop(columns=['Uniprot_ID', 'Uniprot_Acc'], inplace=True)\n",
    "display(merged_protein_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the biomedgraphica_id with the raw_protein_df\n",
    "final_merged_protein_df = pd.merge(bmg_protein_df, protein_df, left_on='Uniprot_ID', right_on='Uniprot_Acc', how='left')\n",
    "# fill the NaN with 0.0\n",
    "final_merged_protein_df = final_merged_protein_df.fillna(0.0)\n",
    "final_merged_protein_df.drop(columns=['Uniprot_ID', 'Uniprot_Acc'], inplace=True)\n",
    "display(final_merged_protein_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_drug_df = pd.read_csv('./raw_data/sanger-dose-response.csv')\n",
    "display(raw_drug_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep columns ['ARXSPAN_ID', 'DRUG_NAME', 'IC50_PUBLISHED']\n",
    "raw_drug_df = raw_drug_df[['ARXSPAN_ID', 'DRUG_NAME', 'IC50_PUBLISHED', 'AUC_PUBLISHED']]\n",
    "# check if there is nan in all of the dataframe\n",
    "print(raw_drug_df.isnull().sum())\n",
    "# drop the nan in this dataframe\n",
    "raw_drug_df = raw_drug_df.dropna().reset_index(drop=True)\n",
    "# check if there is nan in all of the dataframe again\n",
    "print(raw_drug_df.isnull().sum())\n",
    "display(raw_drug_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the drug_name as a independent dataframe\n",
    "drug_name_df = raw_drug_df[['DRUG_NAME']]\n",
    "# remove the duplicate in the drug_name_df\n",
    "drug_name_df = drug_name_df.drop_duplicates().reset_index(drop=True)\n",
    "display(drug_name_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmg_drug_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Drug/BioMedGraphica_Conn_Drug.csv')\n",
    "display(bmg_drug_df)\n",
    "bmg_drug_name_df = bmg_drug_df[['BioMedGraphica_Conn_ID', 'PubChem_Name', 'IUPAC_Name', 'UNII_Name', 'DrugBank_Name', 'PubChem_Synonym']]\n",
    "# keep BioMedGraphica_Conn_ID and Drug_Name\n",
    "display(bmg_drug_name_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 'PubChem_Name', 'IUPAC_Name', 'UNII_Name', 'DrugBank_Name', 'PubChem_Synonym' into one column called 'Drug_Name'\n",
    "bmg_drug_name_df['Drug_Name'] = bmg_drug_name_df[['PubChem_Name', 'IUPAC_Name', 'UNII_Name', 'DrugBank_Name', 'PubChem_Synonym']].apply(lambda x: ';'.join(x.dropna().astype(str)), axis=1)\n",
    "bmg_drug_name_df = bmg_drug_name_df[['BioMedGraphica_Conn_ID', 'Drug_Name']]\n",
    "display(bmg_drug_name_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since in the column drug name, there are lots of names split by \";\", if this space contain the name in the drug_name_df, then we should match this 2 rows and merge the drug_name_df with the bmg_drug_df\n",
    "# Fix the drug name processing\n",
    "# First, check if there are any NaN values in Drug_Name column\n",
    "print(f\"Number of NaN values in Drug_Name column: {bmg_drug_name_df['Drug_Name'].isna().sum()}\")\n",
    "\n",
    "# Fill NaN values with empty string to avoid errors\n",
    "bmg_drug_name_df['Drug_Name'] = bmg_drug_name_df['Drug_Name'].fillna('')\n",
    "\n",
    "# Convert to string to ensure split() works on all entries\n",
    "bmg_drug_name_df['drug_name_list'] = bmg_drug_name_df['Drug_Name'].astype(str).apply(lambda x: [name.strip() for name in x.split(';')] if x else [])\n",
    "\n",
    "# Similarly for drug_name_df\n",
    "drug_name_df['drug_name_list'] = drug_name_df['DRUG_NAME'].astype(str).apply(lambda x: [name.strip() for name in x.split(';')] if x else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bmg_drug_name_df)\n",
    "display(drug_name_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flattened mapping of drug names to their BMG IDs\n",
    "drug_name_to_bmg = {}\n",
    "for idx, row in bmg_drug_name_df.iterrows():\n",
    "    bmg_id = row['BioMedGraphica_Conn_ID']\n",
    "    for drug_name in row['drug_name_list']:\n",
    "        if drug_name:  # Avoid empty strings\n",
    "            drug_name_to_bmg[drug_name.upper()] = bmg_id\n",
    "\n",
    "# Create a new mapping from ARXSPAN_ID to BMG_ID based on drug name matches\n",
    "arxspan_to_bmg = {}\n",
    "for idx, row in drug_name_df.iterrows():\n",
    "    arxspan_id = row['DRUG_NAME']\n",
    "    for drug_name in row['drug_name_list']:\n",
    "        if drug_name.upper() in drug_name_to_bmg:\n",
    "            arxspan_to_bmg[arxspan_id] = drug_name_to_bmg[drug_name.upper()]\n",
    "            break\n",
    "\n",
    "# Create a mapping dataframe\n",
    "mapping_df = pd.DataFrame(list(arxspan_to_bmg.items()), columns=['DRUG_NAME', 'BioMedGraphica_Conn_ID'])\n",
    "\n",
    "# Display how many drug names were successfully matched\n",
    "print(f\"Successfully matched {len(mapping_df)} out of {len(drug_name_df)} drugs\")\n",
    "\n",
    "# Display the first few rows of the mapping\n",
    "print(\"\\nSample of drug name mappings:\")\n",
    "display(mapping_df)\n",
    "\n",
    "# Now you can use this mapping to merge with your drug_response_df\n",
    "# Example:\n",
    "# merged_df = pd.merge(drug_response_df, mapping_df, on='DRUG_NAME', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_drug_df = mapping_df.copy()\n",
    "# sort values by the column BioMedGraphica_ID\n",
    "final_merged_drug_df = final_merged_drug_df.sort_values(by='BioMedGraphica_Conn_ID').reset_index(drop=True)\n",
    "display(final_merged_drug_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the final drug score dataframe by filtering the 'DRUG_NAME' in the final_merged_drug_df DRUG_NAME\n",
    "final_drug_df = raw_drug_df[raw_drug_df['DRUG_NAME'].isin(final_merged_drug_df['DRUG_NAME'])].reset_index(drop=True)\n",
    "display(final_drug_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Coalign the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methy_samples = final_merged_methy_df.columns[1:]\n",
    "gene_samples = final_merged_gene_df.columns[1:]\n",
    "transcript_samples = final_merged_transcript_df.columns[1:]\n",
    "protein_samples = final_merged_protein_df.columns[1:]\n",
    "drug_samples = list(set(list(final_drug_df['ARXSPAN_ID'])))\n",
    "\n",
    "# print all samples\n",
    "print(methy_samples)\n",
    "print(gene_samples)\n",
    "print(transcript_samples)\n",
    "print(protein_samples)\n",
    "print(drug_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell line names in the protein samples, remove the content after the second \"_\"\n",
    "# result = ['_'.join(s.split('_')[:2]) for s in strings]\n",
    "protein_split_samples = ['_'.join(s.split('_')[:2]) for s in protein_samples]\n",
    "print(protein_split_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line_anno_df = pd.read_csv('./raw_data/Cell_lines_annotations_20181226.txt', sep='\\t')\n",
    "# drop NaN in the depMapID\n",
    "cell_line_anno_df = cell_line_anno_df.dropna(subset=['depMapID']).reset_index(drop=True)\n",
    "# drop NaN in the Pathology\n",
    "cell_line_anno_df = cell_line_anno_df.dropna(subset=['Pathology']).reset_index(drop=True)\n",
    "# drop rows if the column 'PATHOLOGIST_ANNOTATION' contains 'benign'\n",
    "# First handle NaN values in PATHOLOGIST_ANNOTATION\n",
    "cell_line_anno_df = cell_line_anno_df[~(\n",
    "    cell_line_anno_df['PATHOLOGIST_ANNOTATION'].fillna('').str.contains('benign', case=False)\n",
    ")]\n",
    "display(cell_line_anno_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(set(protein_split_samples))))\n",
    "# give me the duplicate elements in the protein_split_samples\n",
    "import collections\n",
    "rep_list = [item for item, count in collections.Counter(protein_split_samples).items() if count > 1]\n",
    "# for column names in final_merged_protein_df, if the column name contains the element in the rep_list, collect the column name in rep_col_list\n",
    "rep_col_list = [col for col in final_merged_protein_df.columns if any(rep in col for rep in rep_list)]\n",
    "print(rep_col_list)\n",
    "# display the rep_col_list in the final_merged_protein_df\n",
    "display(final_merged_protein_df[rep_col_list])\n",
    "\n",
    "# removed all of the rep_col_list in the final_merged_protein_df\n",
    "final_merged_protein_df = final_merged_protein_df.drop(columns=rep_col_list)\n",
    "display(final_merged_protein_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the overlapped cell lines in methy_samples with cell_line_anno_df by merge on cell line id\n",
    "# first format the methy_samples as dataframe\n",
    "methy_samples_df = pd.DataFrame(methy_samples, columns=['CCLE_Name'])\n",
    "# merge the methy_samples_df with the cell_line_anno_df\n",
    "merged_methy_samples_df = pd.merge(methy_samples_df, cell_line_anno_df, left_on='CCLE_Name', right_on='CCLE_ID', how='inner')\n",
    "display(merged_methy_samples_df)\n",
    "\n",
    "# get the map dictionary from the ccle id to depmap id\n",
    "methy_map_dict = dict(zip(merged_methy_samples_df['CCLE_Name'], merged_methy_samples_df['depMapID']))\n",
    "print(methy_map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the cleaned cell line names by removed the content after the second \"_\" in final_merged_protein_df.columns[1:]\n",
    "original_protein_samples = final_merged_protein_df.columns[1:]\n",
    "cleaned_protein_samples = ['_'.join(s.split('_')[:2]) for s in original_protein_samples]\n",
    "# get the cleaned_protein_samples_dict_df from dictionary\n",
    "cleaned_protein_samples_dict_df = pd.DataFrame({'CCLE_Name': original_protein_samples, 'cleaned_CCLE_Name': cleaned_protein_samples})\n",
    "# merge the cleaned_protein_samples_df with the cell_line_anno_df\n",
    "merged_cleaned_protein_samples_df = pd.merge(cleaned_protein_samples_dict_df, cell_line_anno_df, left_on='cleaned_CCLE_Name', right_on='CCLE_ID', how='inner')\n",
    "display(merged_cleaned_protein_samples_df)\n",
    "# get the depmap protein id\n",
    "depmap_protein_samples = merged_cleaned_protein_samples_df['depMapID'].to_list()\n",
    "\n",
    "# Create the map dictionary for the protein samples\n",
    "protein_map_dict = dict(zip(original_protein_samples, depmap_protein_samples))\n",
    "print(protein_map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the methy_mapped_samples and protein_mapped_samples from merged_methy_samples_df and merged_cleaned_protein_samples_df\n",
    "methy_mapped_samples = list(merged_methy_samples_df['depMapID'])\n",
    "protein_mapped_samples = list(merged_cleaned_protein_samples_df['depMapID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Aligning over omics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1 Aligning with intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the overlapped samples only over omics samples\n",
    "omics_overlapped_samples = sorted(list(set(methy_mapped_samples) & set(gene_samples) & set(transcript_samples) & set(protein_mapped_samples)))\n",
    "print(\"length of omics overlapped samples: \", len(omics_overlapped_samples))\n",
    "# check the overlapped samples with annotation samples\n",
    "annotation_samples = list(cell_line_anno_df['depMapID'])\n",
    "overlapped_omics_annotation_samples = sorted(list(set(omics_overlapped_samples) & set(annotation_samples)))\n",
    "print(\"length of overlapped omics and annotation samples: \", len(overlapped_omics_annotation_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.2 Aligning with union on omics and intersection with annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the union samples only over omics samples\n",
    "omics_union_samples = sorted(list(set(methy_mapped_samples) | set(gene_samples) | set(transcript_samples) | set(protein_mapped_samples)))\n",
    "print(\"length of omics union samples: \", len(omics_union_samples))\n",
    "# check the intersection of union samples with annotation samples\n",
    "overlapped_omics_union_annotation_samples = sorted(list(set(omics_union_samples) & set(annotation_samples)))\n",
    "print(\"length of overlapped omics and annotation samples: \", len(overlapped_omics_union_annotation_samples))\n",
    "print(overlapped_omics_union_annotation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3 overlapped_omics_union_annotation_samples (cancerous / non-cancerous) Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cancerous_samples_df = pd.read_csv('./raw_data/cell-lines-in-Non-Cancerous.csv')\n",
    "display(non_cancerous_samples_df)\n",
    "# get the depmap id from the non_cancerous_samples_df\n",
    "non_cancerous_samples = list(non_cancerous_samples_df['Depmap Id'])\n",
    "# get the overlapped non_cancerous samples with the overlapped_omics_union_annotation_samples\n",
    "overlapped_non_cancerous_samples = sorted(list(set(overlapped_omics_union_annotation_samples) & set(non_cancerous_samples)))\n",
    "print(\"length of overlapped omics and annotation samples: \", len(overlapped_omics_union_annotation_samples))\n",
    "print(\"length of overlapped non cancerous samples: \", len(overlapped_non_cancerous_samples))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Overlapping over DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the overlapped samples among all samples (methy_mapped_samples, gene_samples, transcript_samples, protein_mapped_samples, drug_samples)\n",
    "dti_overlapped_samples = sorted(list(set(overlapped_omics_union_annotation_samples) & set(drug_samples)))\n",
    "print(\"len(overlapped_samples):\", len(dti_overlapped_samples))\n",
    "# need to confirm zero intersection between the overlapped samples and non_cancerous_samples\n",
    "dti_overlapped_non_cancerous_samples = sorted(list(set(dti_overlapped_samples) & set(non_cancerous_samples)))\n",
    "print(\"len(overlapped_non_cancerous_samples):\", len(dti_overlapped_non_cancerous_samples))\n",
    "# if there are overlapped samples between the dti_overlapped_samples and non_cancerous_samples, then remove these samples from the dti_overlapped_samples\n",
    "if len(dti_overlapped_non_cancerous_samples) > 0:\n",
    "    dti_overlapped_samples = sorted(list(set(dti_overlapped_samples) - set(dti_overlapped_non_cancerous_samples)))\n",
    "# convert the overlapped_samples to the dataframe with annotation\n",
    "dti_overlapped_samples_df = pd.merge(pd.DataFrame(dti_overlapped_samples, columns=['depMapID']), cell_line_anno_df, on='depMapID', how='inner')\n",
    "display(dti_overlapped_samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir for processsing folder\n",
    "import os\n",
    "if not os.path.exists('./process_data'):\n",
    "    os.makedirs('./process_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti_overlapped_samples_df.to_csv('./process_data/dti_overlapped_samples.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dti_overlapped_samples_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Annotate the samples with disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Add annotation from Cellosaurus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://ftp.expasy.org/databases/cellosaurus/cellosaurus.obo'\n",
    "response = requests.get(url)\n",
    "\n",
    "with open('./raw_data/cellosaurus.obo', 'wb') as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the downloaded OBO file\n",
    "obo_path = './raw_data/cellosaurus.obo'\n",
    "\n",
    "entries = []\n",
    "current_entry = {}\n",
    "\n",
    "# Read and parse\n",
    "with open(obo_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line == \"[Term]\":\n",
    "            if current_entry.get(\"xref\") and any(\"NCBI_TaxID:9606\" in x for x in current_entry[\"xref\"]):\n",
    "                # Separate NCIt and ORDO xrefs\n",
    "                ncit_refs = [x for x in current_entry[\"xref\"] if x.startswith(\"NCIt:\")]\n",
    "                ordo_refs = [x for x in current_entry[\"xref\"] if x.startswith(\"ORDO:\")]\n",
    "                current_entry[\"xref_NCIt\"] = \"; \".join(ncit_refs)\n",
    "                current_entry[\"xref_ORDO\"] = \"; \".join(ordo_refs)\n",
    "                entries.append({\n",
    "                    \"id\": current_entry.get(\"id\", \"\"),\n",
    "                    \"name\": current_entry.get(\"name\", \"\"),\n",
    "                    \"synonym\": \"; \".join(current_entry.get(\"synonym\", [])),\n",
    "                    \"xref_NCIt\": current_entry.get(\"xref_NCIt\", \"\"),\n",
    "                    \"xref_ORDO\": current_entry.get(\"xref_ORDO\", \"\")\n",
    "                })\n",
    "            current_entry = {\"synonym\": [], \"xref\": []}\n",
    "\n",
    "        elif line.startswith(\"id:\"):\n",
    "            current_entry[\"id\"] = line.split(\"id:\")[1].strip()\n",
    "\n",
    "        elif line.startswith(\"name:\"):\n",
    "            current_entry[\"name\"] = line.split(\"name:\")[1].strip()\n",
    "\n",
    "        elif line.startswith(\"synonym:\"):\n",
    "            synonym = line.split(\"synonym:\")[1].split(\"RELATED\")[0].strip().strip('\"')\n",
    "            current_entry[\"synonym\"].append(synonym)\n",
    "\n",
    "        elif line.startswith(\"xref:\"):\n",
    "            current_entry[\"xref\"].append(line.split(\"xref:\")[1].strip())\n",
    "\n",
    "# Handle last entry\n",
    "if current_entry.get(\"xref\") and any(\"NCBI_TaxID:9606\" in x for x in current_entry[\"xref\"]):\n",
    "    ncit_refs = [x for x in current_entry[\"xref\"] if x.startswith(\"NCIt:\")]\n",
    "    ordo_refs = [x for x in current_entry[\"xref\"] if x.startswith(\"ORDO:\")]\n",
    "    entries.append({\n",
    "        \"id\": current_entry.get(\"id\", \"\"),\n",
    "        \"name\": current_entry.get(\"name\", \"\"),\n",
    "        \"synonym\": \"; \".join(current_entry.get(\"synonym\", [])),\n",
    "        \"xref_NCIt\": \"; \".join(ncit_refs),\n",
    "        \"xref_ORDO\": \"; \".join(ordo_refs)\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "cellosaurus_parsed_df = pd.DataFrame(entries)\n",
    "cellosaurus_parsed_df = cellosaurus_parsed_df[[\"id\", \"name\", \"synonym\", \"xref_NCIt\", \"xref_ORDO\"]]\n",
    "cellosaurus_parsed_df.to_csv('./raw_data/cellosaurus_parsed.csv', index=False)\n",
    "# Show preview\n",
    "display(cellosaurus_parsed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Keep the desired columns\n",
    "dti_overlapped_samples_desc_df = dti_overlapped_samples_df[['depMapID', 'Name', 'Pathology', 'Histology', 'type', 'PATHOLOGIST_ANNOTATION', 'tcga_code']]\n",
    "display(dti_overlapped_samples_desc_df)\n",
    "\n",
    "# Step 2: Try direct merge on Name == name using left join\n",
    "matched_df = pd.merge(\n",
    "    dti_overlapped_samples_desc_df,\n",
    "    cellosaurus_parsed_df,\n",
    "    left_on='Name',\n",
    "    right_on='name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 3: Find rows where no match occurred (name is NaN)\n",
    "unmatched_df = matched_df[matched_df['name'].isna()].copy()\n",
    "\n",
    "# Step 4: Drop the Cellosaurus columns to prep for synonym match\n",
    "cols_to_drop = [col for col in matched_df.columns if col in cellosaurus_parsed_df.columns]\n",
    "unmatched_df = unmatched_df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Step 5: Expand cellosaurus synonyms\n",
    "synonym_expanded_df = cellosaurus_parsed_df.copy()\n",
    "synonym_expanded_df = synonym_expanded_df.dropna(subset=['synonym'])\n",
    "synonym_expanded_df = synonym_expanded_df.assign(\n",
    "    synonym=synonym_expanded_df['synonym'].str.split(';')\n",
    ").explode('synonym')\n",
    "synonym_expanded_df['synonym'] = synonym_expanded_df['synonym'].str.strip()\n",
    "\n",
    "# Step 6: Left join unmatched rows with synonym-expanded Cellosaurus\n",
    "synonym_matched_df = pd.merge(\n",
    "    unmatched_df,\n",
    "    synonym_expanded_df,\n",
    "    left_on='Name',\n",
    "    right_on='synonym',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 7: Combine direct-matched (non-NaN name) and synonym-matched rows\n",
    "all_match_df = pd.concat(\n",
    "    [matched_df[matched_df['name'].notna()], synonym_matched_df],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Optional: Drop duplicates based on depMapID if needed\n",
    "all_match_df = all_match_df.drop_duplicates(subset=['depMapID'])\n",
    "display(all_match_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store primary and extra xref matches with better column handling\n",
    "def process_xref_columns_with_extras(df):\n",
    "    # Create a copy to avoid modifying the original\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Always create all the columns, even if they might end up empty\n",
    "    result_df['xref_NCIt_ID'] = ''\n",
    "    result_df['xref_NCIt_name'] = ''\n",
    "    result_df['xref_NCIt_extra_ID'] = ''\n",
    "    result_df['xref_NCIt_extra_name'] = ''\n",
    "    result_df['xref_ORDO_ID'] = ''\n",
    "    result_df['xref_ORDO_name'] = ''\n",
    "    result_df['xref_ORDO_extra_ID'] = ''\n",
    "    result_df['xref_ORDO_extra_name'] = ''\n",
    "    \n",
    "    # Process xref_NCIt if it exists\n",
    "    if 'xref_NCIt' in result_df.columns:\n",
    "        # Only process rows that have xref_NCIt values\n",
    "        mask = result_df['xref_NCIt'].notna() & (result_df['xref_NCIt'] != '')\n",
    "        \n",
    "        for idx in result_df[mask].index:\n",
    "            xref_value = result_df.loc[idx, 'xref_NCIt']\n",
    "            \n",
    "            if '; ' in xref_value:  # Multiple entries\n",
    "                entries = xref_value.split('; ')\n",
    "                \n",
    "                # Process first entry for primary columns\n",
    "                if ' ! ' in entries[0]:\n",
    "                    id_val, name_val = entries[0].split(' ! ', 1)\n",
    "                    result_df.loc[idx, 'xref_NCIt_ID'] = id_val\n",
    "                    result_df.loc[idx, 'xref_NCIt_name'] = name_val\n",
    "                \n",
    "                # Process additional entries for extra columns\n",
    "                extra_ids = []\n",
    "                extra_names = []\n",
    "                for entry in entries[1:]:\n",
    "                    if ' ! ' in entry:\n",
    "                        id_val, name_val = entry.split(' ! ', 1)\n",
    "                        extra_ids.append(id_val)\n",
    "                        extra_names.append(name_val)\n",
    "                \n",
    "                if extra_ids:\n",
    "                    result_df.loc[idx, 'xref_NCIt_extra_ID'] = '; '.join(extra_ids)\n",
    "                    result_df.loc[idx, 'xref_NCIt_extra_name'] = '; '.join(extra_names)\n",
    "                    \n",
    "            elif ' ! ' in xref_value:  # Single entry\n",
    "                id_val, name_val = xref_value.split(' ! ', 1)\n",
    "                result_df.loc[idx, 'xref_NCIt_ID'] = id_val\n",
    "                result_df.loc[idx, 'xref_NCIt_name'] = name_val\n",
    "        \n",
    "        # Drop the original column\n",
    "        result_df = result_df.drop(columns=['xref_NCIt'])\n",
    "    \n",
    "    # Process xref_ORDO if it exists\n",
    "    if 'xref_ORDO' in result_df.columns:\n",
    "        # Only process rows that have xref_ORDO values\n",
    "        mask = result_df['xref_ORDO'].notna() & (result_df['xref_ORDO'] != '')\n",
    "        \n",
    "        for idx in result_df[mask].index:\n",
    "            xref_value = result_df.loc[idx, 'xref_ORDO']\n",
    "            \n",
    "            if '; ' in xref_value:  # Multiple entries\n",
    "                entries = xref_value.split('; ')\n",
    "                \n",
    "                # Process first entry for primary columns\n",
    "                if ' ! ' in entries[0]:\n",
    "                    id_val, name_val = entries[0].split(' ! ', 1)\n",
    "                    result_df.loc[idx, 'xref_ORDO_ID'] = id_val\n",
    "                    result_df.loc[idx, 'xref_ORDO_name'] = name_val\n",
    "                \n",
    "                # Process additional entries for extra columns\n",
    "                extra_ids = []\n",
    "                extra_names = []\n",
    "                for entry in entries[1:]:\n",
    "                    if ' ! ' in entry:\n",
    "                        id_val, name_val = entry.split(' ! ', 1)\n",
    "                        extra_ids.append(id_val)\n",
    "                        extra_names.append(name_val)\n",
    "                \n",
    "                if extra_ids:\n",
    "                    result_df.loc[idx, 'xref_ORDO_extra_ID'] = '; '.join(extra_ids)\n",
    "                    result_df.loc[idx, 'xref_ORDO_extra_name'] = '; '.join(extra_names)\n",
    "                    \n",
    "            elif ' ! ' in xref_value:  # Single entry\n",
    "                id_val, name_val = xref_value.split(' ! ', 1)\n",
    "                result_df.loc[idx, 'xref_ORDO_ID'] = id_val\n",
    "                result_df.loc[idx, 'xref_ORDO_name'] = name_val\n",
    "        \n",
    "        # Drop the original column\n",
    "        result_df = result_df.drop(columns=['xref_ORDO'])\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Apply the function\n",
    "all_match_df = process_xref_columns_with_extras(all_match_df)\n",
    "\n",
    "# Update the column list to include the extra columns\n",
    "dti_overlapped_samples_desc_co_df = all_match_df[['depMapID', 'Name', 'Pathology', 'Histology', \n",
    "                                             'type', 'PATHOLOGIST_ANNOTATION', 'tcga_code', 'id', \n",
    "                                             'xref_NCIt_ID', 'xref_NCIt_name', 'xref_NCIt_extra_ID', 'xref_NCIt_extra_name',\n",
    "                                             'xref_ORDO_ID', 'xref_ORDO_name', 'xref_ORDO_extra_ID', 'xref_ORDO_extra_name']]\n",
    "display(dti_overlapped_samples_desc_co_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Cell line disease match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.1 Cell line disease hard match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmg_disease_name_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Disease/BioMedGraphica_Conn_Disease_GUI_Name.csv')\n",
    "display(bmg_disease_name_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Expand BMG_Disease_Name (still lowercased and exploded)\n",
    "bmg_expanded = bmg_disease_name_df.copy()\n",
    "\n",
    "# First, strip any surrounding quotes and fill NaN values with empty strings\n",
    "bmg_expanded['Disease_Name_List'] = bmg_expanded['Disease_Name_List'].fillna('')\n",
    "bmg_expanded['Disease_Name_List'] = bmg_expanded['Disease_Name_List'].str.replace('^\"|\"$', '', regex=True)\n",
    "\n",
    "# Split on pipe with spaces\n",
    "bmg_expanded['Disease_Name_List'] = bmg_expanded['Disease_Name_List'].str.split(' \\| ')\n",
    "\n",
    "# Apply strip only to non-empty lists\n",
    "bmg_expanded['Disease_Name_List'] = bmg_expanded['Disease_Name_List'].apply(\n",
    "    lambda x: [name.strip() for name in x] if isinstance(x, list) else []\n",
    ")\n",
    "\n",
    "# Explode the list into separate rows\n",
    "bmg_expanded = bmg_expanded.explode('Disease_Name_List')\n",
    "\n",
    "# Remove rows with empty disease names after exploding\n",
    "bmg_expanded = bmg_expanded[bmg_expanded['Disease_Name_List'].str.len() > 0]\n",
    "\n",
    "# Create lowercase version for easier matching\n",
    "bmg_expanded['Disease_Name_List_lower'] = bmg_expanded['Disease_Name_List'].str.lower()\n",
    "\n",
    "display(bmg_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lookup list of tuples: (Conn_ID, Original_Name, Lower_Name)\n",
    "bmg_records = bmg_expanded[['BioMedGraphica_Conn_ID', 'Disease_Name_List', 'Disease_Name_List_lower']].to_records(index=False)\n",
    "\n",
    "# Updated matching function: look for exact full-name match\n",
    "def match_bmg_disease_exact(xref_name, bmg_records):\n",
    "    if pd.isna(xref_name):\n",
    "        return (None, None)\n",
    "    xref_name_lower = str(xref_name).strip().lower()\n",
    "    \n",
    "    for conn_id, original_name, bmg_name_lower in bmg_records:\n",
    "        if xref_name_lower == bmg_name_lower:\n",
    "            return (conn_id, original_name)\n",
    "    \n",
    "    return (None, None)\n",
    "\n",
    "# NCIt\n",
    "ncit_matches = dti_overlapped_samples_desc_co_df['xref_NCIt_name'].apply(lambda x: match_bmg_disease_exact(x, bmg_records))\n",
    "dti_overlapped_samples_desc_co_df['NCIt_BMGC_ID'] = ncit_matches.apply(lambda x: x[0])\n",
    "dti_overlapped_samples_desc_co_df['NCIt_BMGC_name'] = ncit_matches.apply(lambda x: x[1])\n",
    "\n",
    "# ORDO\n",
    "ordo_matches = dti_overlapped_samples_desc_co_df['xref_ORDO_name'].apply(lambda x: match_bmg_disease_exact(x, bmg_records))\n",
    "dti_overlapped_samples_desc_co_df['ORDO_BMGC_ID'] = ordo_matches.apply(lambda x: x[0])\n",
    "dti_overlapped_samples_desc_co_df['ORDO_BMGC_name'] = ordo_matches.apply(lambda x: x[1])\n",
    "\n",
    "display(dti_overlapped_samples_desc_co_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the columns ['depMapID', 'Name', 'Pathology', 'Histology', 'type', 'PATHOLOGIST_ANNOTATION', 'tcga_code', 'id', 'xref_NCIt_ID', 'xref_NCIt_name', 'NCIt_BMGC_ID', 'NCIt_BMGC_name', 'xref_ORDO_ID', 'xref_ORDO_name', 'ORDO_BMGC_ID', 'ORDO_BMGC_name']\n",
    "dti_overlapped_samples_desc_co_df = dti_overlapped_samples_desc_co_df[['depMapID', 'Name', 'Pathology', 'Histology', 'type', 'PATHOLOGIST_ANNOTATION', 'tcga_code', 'id', 'xref_NCIt_ID', 'xref_NCIt_name', 'NCIt_BMGC_ID', 'NCIt_BMGC_name', 'xref_ORDO_ID', 'xref_ORDO_name', 'ORDO_BMGC_ID', 'ORDO_BMGC_name']]\n",
    "display(dti_overlapped_samples_desc_co_df)\n",
    "dti_overlapped_samples_desc_co_df.to_csv('./process_data/dti_overlapped_samples_desc_co.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge NCIt_BMGC_ID/ORDO_BMGC_ID and NCIt_BMGC_name/ORDO_BMGC_name into BMGC_Matched columns\n",
    "# Strategy:\n",
    "# 1. Prioritize NCIt data when both are available\n",
    "# 2. Use NCIt data if only NCIt is available\n",
    "# 3. Use ORDO data if only ORDO is available\n",
    "# 4. Leave as null if both are null\n",
    "\n",
    "dti_matched_df = dti_overlapped_samples_desc_co_df.copy()\n",
    "\n",
    "# Create new merged ID column\n",
    "dti_matched_df['BMGC_Matched_ID'] = (\n",
    "    dti_matched_df['NCIt_BMGC_ID'].fillna(\n",
    "        dti_matched_df['ORDO_BMGC_ID']\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create new merged name column\n",
    "dti_matched_df['BMGC_Matched_name'] = (\n",
    "    dti_matched_df['NCIt_BMGC_name'].fillna(\n",
    "        dti_matched_df['ORDO_BMGC_name']\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the dataframe with new columns\n",
    "display(dti_matched_df)\n",
    "\n",
    "# Check number of null values in new columns\n",
    "print(f\"Null values in BMGC_Matched_ID: {dti_matched_df['BMGC_Matched_ID'].isna().sum()}\")\n",
    "print(f\"Null values in BMGC_Matched_name: {dti_matched_df['BMGC_Matched_name'].isna().sum()}\")\n",
    "\n",
    "# only keep the columns where the BMGC_Matched_ID is not null\n",
    "dti_matched_df = dti_matched_df[dti_matched_df['BMGC_Matched_ID'].notna()].reset_index(drop=True)\n",
    "display(dti_matched_df)\n",
    "\n",
    "# Save to CSV\n",
    "dti_matched_df.to_csv('./process_data/dti_matched.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.2 Cell line disease soft match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the unmatched samples in the dti_overlapped_samples_desc_co_df by checking the NaN in the NCIt_BMGC_ID and ORDO_BMGC_ID\n",
    "unmatched_samples_df = dti_overlapped_samples_desc_co_df[dti_overlapped_samples_desc_co_df['NCIt_BMGC_ID'].isna() & dti_overlapped_samples_desc_co_df['ORDO_BMGC_ID'].isna()]\n",
    "# keep the columns ['depMapID', 'Name', 'Pathology', 'Histology', 'type', 'PATHOLOGIST_ANNOTATION', 'tcga_code', 'id', 'xref_NCIt_name', , 'xref_ORDO_name']\n",
    "unmatched_samples_df = unmatched_samples_df[['depMapID', 'Name', 'Pathology', 'Histology', 'type', 'PATHOLOGIST_ANNOTATION', 'tcga_code', 'id', 'xref_NCIt_name', 'xref_ORDO_name']]\n",
    "display(unmatched_samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the disease name for bmg_disease_df by bert-based model\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, sentences: List[str]):\n",
    "        self.sentences = sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sentences[idx]\n",
    "\n",
    "\n",
    "class TextEncoder():\n",
    "    def __init__(self, model_path: str = \"dmis-lab/biobert-v1.1\", device: str = \"cuda\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_path (str, optional): Path to the deberta model. Defaults to 'dmis-lab/biobert-v1.1'.\n",
    "            device (str, optional): Device to run the model on ('cpu' or 'cuda'). Defaults to 'cpu'.\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.device = device\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Load the deberta model and tokenizer from the specified model path.\n",
    "        \"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n",
    "        self.model = AutoModel.from_pretrained(self.model_path).to(self.device)\n",
    "\n",
    "    def generate_embeddings(self, sentences: List[str], batch_size: int = 32, seq_emb_dim: int = 64) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Generate a single-dimensional embedding for each sentence.\n",
    "\n",
    "        Args:\n",
    "            sentences (List[str]): List of sentences to embed.\n",
    "            batch_size (int, optional): Batch size for DataLoader. Defaults to 32.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: List of single-dimensional embeddings.\n",
    "        \"\"\"\n",
    "        dataset = SentenceDataset(sentences)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        embedding_batches = []\n",
    "        for batch in tqdm(dataloader, desc=\"Embedding sentences\", unit=\"batch\"):\n",
    "            inputs = self.tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "            # Handle single batch case properly\n",
    "            mean_embeddings = torch.mean(outputs.last_hidden_state, dim=1)  # [batch_size, hidden_dim]\n",
    "            \n",
    "            # For adaptive pooling, we need to reshape for 1D adaptive pooling\n",
    "            # [batch_size, 1, hidden_dim] -> [batch_size, 1, seq_emb_dim] -> [batch_size, seq_emb_dim]\n",
    "            batch_size = mean_embeddings.size(0)\n",
    "            reshaped = mean_embeddings.view(batch_size, 1, -1)\n",
    "            projected = torch.nn.functional.adaptive_avg_pool1d(reshaped, output_size=seq_emb_dim)\n",
    "            projected = projected.squeeze(1)  # Only squeeze dimension 1, keep batch dimension\n",
    "            embedding_batches.append(projected)\n",
    "        return torch.cat(embedding_batches, dim=0)\n",
    "\n",
    "    def save_embeddings(self, embeddings, output_npy_path):\n",
    "        \"\"\"\n",
    "        Save embeddings to a .npy file.\n",
    "        \n",
    "        Args:\n",
    "            embeddings (torch.Tensor): The embeddings to save.\n",
    "            output_npy_path (str): Path to save the embeddings file.\n",
    "        \"\"\"\n",
    "        # Move embeddings to CPU before converting to numpy\n",
    "        embeddings_cpu = embeddings.cpu().numpy()\n",
    "        np.save(output_npy_path, embeddings_cpu)\n",
    "        print(f\"Embeddings saved at {output_npy_path} with shape {embeddings_cpu.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the bmg_disease_name_df to the list of disease names of each rows\n",
    "disease_names = list(bmg_disease_name_df['Disease_Name_List'])\n",
    "# to make sure each disease name is a string\n",
    "disease_names = [str(name) for name in disease_names]\n",
    "print(len(disease_names))\n",
    "print(disease_names[:5])\n",
    "print(disease_names[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Use language model to embed the name and description\n",
    "name_sentence_list = disease_names\n",
    "text_encoder = TextEncoder()\n",
    "text_encoder.load_model()\n",
    "name_embeddings = text_encoder.generate_embeddings(name_sentence_list, batch_size=32, seq_emb_dim=768)\n",
    "print(name_embeddings.shape)\n",
    "# mkdir folder BMG_emb\n",
    "if not os.path.exists('./BMG_emb'):\n",
    "    os.makedirs('./BMG_emb')\n",
    "text_encoder.save_embeddings(name_embeddings, './BMG_emb/disease_name_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each row in the unmatched_samples_df to a sentence like \"Name: NIH:OVCAR-3, Pathology: OVARY, Histology: CARCINOMA, type: CANCER, PATHOLOGIST_ANNOTATION: OVARY, tcga_code: OV\"\n",
    "depmap_desc_sentence_list = []\n",
    "for idx, row in unmatched_samples_df.iterrows():\n",
    "    depmap_desc_sentence_list.append(f\" {row['type']}, {row['PATHOLOGIST_ANNOTATION']}\")\n",
    "\n",
    "# and create the ncit_desc_sentence_list and ordo_desc_sentence_list\n",
    "ncit_desc_sentence_list = list(unmatched_samples_df['xref_NCIt_name'])\n",
    "ordo_desc_sentence_list = list(unmatched_samples_df['xref_ORDO_name'])\n",
    "\n",
    "# make sure each element in the depmap_desc_sentence_list, ncit_desc_sentence_list and ordo_desc_sentence_list is a string\n",
    "depmap_desc_sentence_list = [str(name) for name in depmap_desc_sentence_list]\n",
    "ncit_desc_sentence_list = [str(name) for name in ncit_desc_sentence_list]\n",
    "ordo_desc_sentence_list = [str(name) for name in ordo_desc_sentence_list]\n",
    "\n",
    "print(depmap_desc_sentence_list)\n",
    "print(ncit_desc_sentence_list)\n",
    "print(ordo_desc_sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sentence lists to process and their corresponding prefixes\n",
    "sentence_list_mapping = {\n",
    "    'depmap': depmap_desc_sentence_list,\n",
    "    'ncit': ncit_desc_sentence_list,\n",
    "    'ordo': ordo_desc_sentence_list\n",
    "}\n",
    "\n",
    "# Define top_k for this matching task\n",
    "top_k = 2\n",
    "\n",
    "# Process each sentence list and add the matches to the DataFrame\n",
    "for prefix, sentence_list in sentence_list_mapping.items():\n",
    "    # Lists to store the matches for each description\n",
    "    all_matched_lists = [[] for _ in range(top_k)]\n",
    "    all_matched_name_lists = [[] for _ in range(top_k)]\n",
    "    all_similarity_lists = [[] for _ in range(top_k)]\n",
    "    \n",
    "    for desc in sentence_list:\n",
    "        desc_embeddings = text_encoder.generate_embeddings([desc], batch_size=1, seq_emb_dim=768)\n",
    "        # Calculate cosine similarity\n",
    "        cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        similarity = cos(name_embeddings, desc_embeddings)\n",
    "        # Find the index of top k most similar diseases\n",
    "        top_k_idx = torch.argsort(similarity, descending=True)[:top_k]\n",
    "        \n",
    "        # Process each of the top k matches\n",
    "        for rank, idx in enumerate(top_k_idx):\n",
    "            idx_int = idx.item()\n",
    "            disease_id = bmg_disease_name_df.iloc[idx_int]['BioMedGraphica_Conn_ID']\n",
    "            disease_name = disease_names[idx_int]\n",
    "            sim_score = similarity[idx_int].item()\n",
    "            \n",
    "            # Store in the corresponding lists\n",
    "            all_matched_lists[rank].append(disease_id)\n",
    "            all_matched_name_lists[rank].append(disease_name)\n",
    "            all_similarity_lists[rank].append(sim_score)\n",
    "    \n",
    "    # Add the matched data to the DataFrame with the appropriate prefix\n",
    "    for i in range(top_k):\n",
    "        rank = i + 1\n",
    "        unmatched_samples_df[f'{prefix}_match_{rank}_disease'] = all_matched_lists[i]\n",
    "        unmatched_samples_df[f'{prefix}_match_{rank}_disease_name'] = all_matched_name_lists[i]\n",
    "        unmatched_samples_df[f'{prefix}_match_{rank}_similarity'] = all_similarity_lists[i]\n",
    "    \n",
    "    print(f\"Finished processing {prefix} descriptions\")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "display(unmatched_samples_df)\n",
    "\n",
    "# Save the updated DataFrame to CSV\n",
    "unmatched_samples_df.to_csv('./process_data/unmatched_samples_softmatch.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Manual filter and match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_samples_df = pd.read_csv('./process_data/unmatched_samples_softmatch.csv')\n",
    "# add the 2 empty columnns 'BMGC_manual_ID' and 'BMGC_manual_name' to the unmatched_samples_manual_df\n",
    "unmatched_samples_manual_df = unmatched_samples_df.copy()\n",
    "unmatched_samples_manual_df['BMGC_manual_ID'] = None\n",
    "unmatched_samples_manual_df['BMGC_manual_name'] = None\n",
    "# change the order of the columns to make the 'BMGC_manual_ID' and 'BMGC_manual_name' after id\n",
    "unmatched_samples_manual_df = unmatched_samples_manual_df[['depMapID', 'Name', 'Pathology', 'Histology', 'type', 'PATHOLOGIST_ANNOTATION', 'tcga_code', 'id', 'BMGC_manual_ID', 'BMGC_manual_name', 'xref_NCIt_name', 'xref_ORDO_name', 'depmap_match_1_disease', 'depmap_match_1_disease_name', 'depmap_match_2_disease', 'depmap_match_2_disease_name', 'ncit_match_1_disease', 'ncit_match_1_disease_name', 'ncit_match_2_disease', 'ncit_match_2_disease_name', 'ordo_match_1_disease', 'ordo_match_1_disease_name', 'ordo_match_2_disease', 'ordo_match_2_disease_name']]\n",
    "display(unmatched_samples_manual_df)\n",
    "unmatched_samples_manual_df.to_csv('./process_data/unmatched_samples_manual.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Combine matched and manual_unmatached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matched samples, rename BMGC_Matched_ID and BMGC_Matched_name to BMGC_ID and BMGC_name\n",
    "dti_matched_df = pd.read_csv('./process_data/dti_matched.csv').rename(columns={'BMGC_Matched_ID': 'BMGC_Disease_ID', 'BMGC_Matched_name': 'BMGC_Disease_name'})\n",
    "# keep the columns ['depMapID', 'Name', 'BMGC_Disease_ID', 'BMGC_Disease_name', 'Pathology', 'Histology', 'type', 'PATHOLOGIST_ANNOTATION', 'tcga_code', 'xref_NCIt_ID', 'xref_NCIt_name', 'xref_ORDO_ID', 'xref_ORDO_name']\n",
    "dti_matched_df = dti_matched_df[['depMapID', 'Name', 'BMGC_Disease_ID', 'BMGC_Disease_name', 'Pathology', 'Histology', 'type', 'PATHOLOGIST_ANNOTATION', 'tcga_code']]\n",
    "display(dti_matched_df)\n",
    "# Unmatched samples, rename BMGC_manual_ID and BMGC_manual_name to BMGC_Disease_ID and BMGC_Disease_name\n",
    "dti_unmatched_manual_df = pd.read_csv('./process_data/unmatched_samples_manual.csv').rename(columns={'BMGC_manual_ID': 'BMGC_Disease_ID', 'BMGC_manual_name': 'BMGC_Disease_name'})\n",
    "display(dti_unmatched_manual_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti_unmatched_manual_valid_df = pd.read_csv('./process_data/unmatched_samples_manual_valid.csv').rename(columns={'BMGC_manual_ID': 'BMGC_Disease_ID', 'BMGC_manual_name': 'BMGC_Disease_name'})\n",
    "display(dti_unmatched_manual_valid_df)\n",
    "# concatenate the dti_matched_df and dti_unmatched_manual_df and sort by depMapID\n",
    "dti_combined_df = pd.concat([dti_matched_df, dti_unmatched_manual_valid_df], ignore_index=True)\n",
    "# sort the dti_combined_df by depMapID\n",
    "dti_combined_df = dti_combined_df.sort_values(by='depMapID').reset_index(drop=True)\n",
    "# check if there is any empty value in the BMGC_ID and BMGC_name columns\n",
    "print(dti_combined_df[['BMGC_Disease_ID', 'BMGC_Disease_name']].isnull().sum())\n",
    "# convert all content in 'BMGC_Disease_name' to lower case\n",
    "dti_combined_df['BMGC_Disease_name'] = dti_combined_df['BMGC_Disease_name'].str.lower()\n",
    "display(dti_combined_df)\n",
    "dti_combined_df.to_csv('./process_data/dti_combined_samples.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Split train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 DTI integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti_overlapped_samples = list(dti_overlapped_samples_df['depMapID'])\n",
    "print(dti_overlapped_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maped_methy_df = final_merged_methy_df.rename(columns=methy_map_dict)\n",
    "display(maped_methy_df)\n",
    "# insert the samples that is in the overlapped_samples but not in the maped_methy_df\n",
    "for sample in dti_overlapped_samples:\n",
    "    if sample not in maped_methy_df.columns:\n",
    "        maped_methy_df[sample] = 0.0\n",
    "# filter out the samples that is not in the dti_overlapped_samples\n",
    "dti_methy_df = maped_methy_df[['BioMedGraphica_Conn_ID'] + dti_overlapped_samples]\n",
    "display(dti_methy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_protein_df = final_merged_protein_df.rename(columns=protein_map_dict)\n",
    "display(mapped_protein_df)\n",
    "# insert the samples that is in the dti_overlapped_samples but not in the mapped_protein_df\n",
    "for sample in dti_overlapped_samples:\n",
    "    if sample not in mapped_protein_df.columns:\n",
    "        mapped_protein_df[sample] = 0.0\n",
    "# filter out the samples that is not in the dti_overlapped_samples\n",
    "dti_protein_df = mapped_protein_df[['BioMedGraphica_Conn_ID'] + dti_overlapped_samples]\n",
    "display(dti_protein_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the missing samples in the final_merged_gene_df\n",
    "for sample in dti_overlapped_samples:\n",
    "    if sample not in final_merged_gene_df.columns:\n",
    "        final_merged_gene_df[sample] = 0.0\n",
    "# fill in the missing samples in the final_merged_transcript_df\n",
    "for sample in dti_overlapped_samples:\n",
    "    if sample not in final_merged_transcript_df.columns:\n",
    "        final_merged_transcript_df[sample] = 0.0\n",
    "# get the final gene, transcript, drug dataframe by filtering the dti_overlapped_samples\n",
    "dti_gene_df = final_merged_gene_df[['BioMedGraphica_Conn_ID'] + dti_overlapped_samples]\n",
    "display(dti_gene_df)\n",
    "dti_transcript_df = final_merged_transcript_df[['BioMedGraphica_Conn_ID'] + dti_overlapped_samples]\n",
    "display(dti_transcript_df)\n",
    "dti_drug_overlap_df = final_drug_df[final_drug_df['ARXSPAN_ID'].isin(dti_overlapped_samples)].reset_index(drop=True)\n",
    "dti_drug_overlap_df = pd.merge(dti_drug_overlap_df, dti_combined_df, left_on='ARXSPAN_ID', right_on='depMapID', how='left')\n",
    "dti_drug_overlap_df = pd.merge(dti_drug_overlap_df, final_merged_drug_df, on='DRUG_NAME', how='left').rename(columns={'BMGC_Disease_name': 'BMGC_Disease_Name', 'DRUG_NAME': 'BMGC_Drug_Name', 'BioMedGraphica_Conn_ID': 'BMGC_Drug_ID', 'Name': 'Cell_Line_Name', 'AUC_PUBLISHED': 'AUC'})\n",
    "# only keep columns ['depMapID', 'Cell_Line_Name', 'BMGC_Drug_ID', 'BMGC_Drug_Name', 'BMGC_Disease_ID', 'BMGC_Disease_Name', 'AUC']\n",
    "dti_drug_overlap_df = dti_drug_overlap_df[['depMapID', 'Cell_Line_Name', 'BMGC_Drug_ID', 'BMGC_Drug_Name', 'BMGC_Disease_ID', 'BMGC_Disease_Name', 'AUC']]\n",
    "# check if there is null values in the dti_drug_overlap_df\n",
    "print(dti_drug_overlap_df.isnull().sum())\n",
    "display(dti_drug_overlap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any empty or Null values in the dti_drug_overlap_df\n",
    "print(dti_drug_overlap_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti_omics_df = pd.concat([dti_methy_df, dti_gene_df, dti_transcript_df, dti_protein_df], axis=0).reset_index(drop=True)\n",
    "display(dti_omics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 DTI Split the samples for training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti_samples =  dti_combined_df['depMapID'].tolist()\n",
    "print(dti_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the overlapped samples into training samples and test samples\n",
    "ratio = 0.8\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "# shuffle the overlapped_samples\n",
    "np.random.shuffle(dti_samples)\n",
    "# get the training samples and test samples\n",
    "dti_training_samples = dti_samples[:int(len(dti_samples) * ratio)]\n",
    "dti_test_samples = dti_samples[int(len(dti_samples) * ratio):]\n",
    "print(\"len(dti_training_samples):\", len(dti_training_samples))\n",
    "print(\"len(dti_test_samples):\", len(dti_test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the drugs into training samples and test samples\n",
    "np.random.seed(0)\n",
    "# shuffle the drug_samples\n",
    "display(final_merged_drug_df)\n",
    "dti_drugs = final_merged_drug_df['BioMedGraphica_Conn_ID'].to_list()\n",
    "np.random.shuffle(dti_drugs)\n",
    "# get the training samples and test samples\n",
    "dti_training_drugs = dti_drugs[:int(len(dti_drugs) * ratio)]\n",
    "dti_test_drugs = dti_drugs[int(len(dti_drugs) * ratio):]\n",
    "print(\"len(dti_training_drugs):\", len(dti_training_drugs))\n",
    "print(\"len(dti_test_drugs):\", len(dti_test_drugs))\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the drug screen by training and test with condition that meet both cell line test samples and drug test samples for test\n",
    "final_training_drug_screen_df = dti_drug_overlap_df[dti_drug_overlap_df['depMapID'].isin(dti_training_samples) & dti_drug_overlap_df['BMGC_Drug_ID'].isin(dti_training_drugs)].reset_index(drop=True)\n",
    "display(final_training_drug_screen_df)\n",
    "# and calculate the final training drug ids and cell line ids\n",
    "training_drug_ids = list(set(final_training_drug_screen_df['BMGC_Drug_ID']))\n",
    "training_cell_line_ids = list(set(final_training_drug_screen_df['depMapID']))\n",
    "print(\"len(training_drug_ids):\", len(training_drug_ids))\n",
    "print(\"len(training_cell_line_ids):\", len(training_cell_line_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the rest of the drug screen is the test drug screen\n",
    "final_test_drug_screen_df = dti_drug_overlap_df[~dti_drug_overlap_df.index.isin(final_training_drug_screen_df.index)].reset_index(drop=True)\n",
    "display(final_test_drug_screen_df)\n",
    "# and calculate the final test drug ids and cell line ids\n",
    "test_drug_ids = list(set(final_test_drug_screen_df['BMGC_Drug_ID']))\n",
    "test_cell_line_ids = list(set(final_test_drug_screen_df['depMapID']))\n",
    "print(\"len(test_drug_ids):\", len(test_drug_ids))\n",
    "print(\"len(test_cell_line_ids):\", len(test_cell_line_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Pretrain samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the rest of samples not using in dti task (difference between overlapped_omics_union_annotation_samples and dti_overlapped_samples_df)\n",
    "rest_samples = list(set(overlapped_omics_union_annotation_samples) - set(dti_overlapped_samples))\n",
    "print(\"len(rest_samples):\", len(rest_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pretraining samples by concatenating the training_cell_line_ids and rest_samples\n",
    "pretraining_samples = list(set(training_cell_line_ids) | set(rest_samples))\n",
    "print(\"len(pretraining_samples):\", len(pretraining_samples))\n",
    "print(pretraining_samples[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cancerous_samples_df = pd.read_csv('./raw_data/cell-lines-in-Non-Cancerous.csv')\n",
    "# get the depmap id from the non_cancerous_samples_df\n",
    "non_cancerous_samples = list(non_cancerous_samples_df['Depmap Id'])\n",
    "# get the overlapped non_cancerous samples with the overlapped_omics_union_annotation_samples\n",
    "overlapped_non_cancerous_samples = sorted(list(set(overlapped_omics_union_annotation_samples) & set(non_cancerous_samples)))\n",
    "print(\"length of overlapped omics and annotation samples: \", len(overlapped_omics_union_annotation_samples))\n",
    "print(\"length of overlapped non cancerous samples: \", len(overlapped_non_cancerous_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the non_cancerous_samples, get the non_cancerous_pretrain_samples in the pretraining_samples\n",
    "non_cancerous_pretrain_samples = sorted(list(set(pretraining_samples) & set(overlapped_non_cancerous_samples)))\n",
    "print(\"length of non cancerous pretrain samples: \", len(non_cancerous_pretrain_samples))\n",
    "cancerous_pretrain_samples = sorted(list(set(pretraining_samples) - set(non_cancerous_pretrain_samples)))\n",
    "print(\"length of cancerous pretrain samples: \", len(cancerous_pretrain_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Pretrain integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maped_methy_df = final_merged_methy_df.rename(columns=methy_map_dict)\n",
    "display(maped_methy_df)\n",
    "# insert the samples that is in the overlapped_samples but not in the maped_methy_df\n",
    "for sample in pretraining_samples:\n",
    "    if sample not in maped_methy_df.columns:\n",
    "        maped_methy_df[sample] = 0.0\n",
    "# filter out the samples that is not in the pretraining_samples\n",
    "pretrain_methy_df = maped_methy_df[['BioMedGraphica_Conn_ID'] + pretraining_samples]\n",
    "display(pretrain_methy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_protein_df = final_merged_protein_df.rename(columns=protein_map_dict)\n",
    "display(mapped_protein_df)\n",
    "# insert the samples that is in the pretraining_samples but not in the mapped_protein_df\n",
    "for sample in pretraining_samples:\n",
    "    if sample not in mapped_protein_df.columns:\n",
    "        mapped_protein_df[sample] = 0.0\n",
    "# filter out the samples that is not in the pretraining_samples\n",
    "pretrain_protein_df = mapped_protein_df[['BioMedGraphica_Conn_ID'] + pretraining_samples]\n",
    "display(pretrain_protein_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the missing samples in the final_merged_gene_df for pretraining samples\n",
    "for sample in pretraining_samples:\n",
    "    if sample not in final_merged_gene_df.columns:\n",
    "        final_merged_gene_df[sample] = 0.0\n",
    "# fill in the missing samples in the final_merged_transcript_df for pretraining samples\n",
    "for sample in pretraining_samples:\n",
    "    if sample not in final_merged_transcript_df.columns:\n",
    "        final_merged_transcript_df[sample] = 0.0\n",
    "# get the final gene, transcript, drug dataframe by filtering the pretraining_samples\n",
    "pretrain_gene_df = final_merged_gene_df[['BioMedGraphica_Conn_ID'] + pretraining_samples]\n",
    "display(pretrain_gene_df)\n",
    "pretrain_transcript_df = final_merged_transcript_df[['BioMedGraphica_Conn_ID'] + pretraining_samples]\n",
    "display(pretrain_transcript_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_omics_df = pd.concat([pretrain_methy_df, pretrain_gene_df, pretrain_transcript_df, pretrain_protein_df], axis=0).reset_index(drop=True)\n",
    "display(pretrain_omics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Convert to numpy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the numpy file folders with name DTI_data and Pretrain_data\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('./DTI_data', exist_ok=True)\n",
    "os.makedirs('./Pretrain_data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Load BMGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmgc_entity_df = pd.read_csv('./BioMedGraphica-Conn/Entity/BioMedGraphica_Conn_Entity.csv')\n",
    "bmgc_relation_df = pd.read_csv('./BioMedGraphica-Conn/Relation/BioMedGraphica_Conn_Relation.csv')\n",
    "display(bmgc_entity_df)\n",
    "display(bmgc_relation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the null values in the bmgc_entity_df and bmgc_relation_df\n",
    "print(bmgc_entity_df.isnull().sum())\n",
    "print(bmgc_relation_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the rows where BMGC_From_ID is null in the bmgc_relation_df\n",
    "print(bmgc_relation_df[bmgc_relation_df['BMGC_From_ID'].isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 DTI numpy files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.1 Merge files for X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the columns ['BioMedGraphica_Conn_ID'] in the bmgc_entity_df\n",
    "dti_bmgc_entity_df = bmgc_entity_df[['BioMedGraphica_Conn_ID']].copy()\n",
    "# left join the dti_bmgc_entity_df with the dti_omics_df on BioMedGraphica_Conn_ID\n",
    "dti_bmgc_omics_df = pd.merge(dti_bmgc_entity_df, dti_omics_df, on='BioMedGraphica_Conn_ID', how='left')\n",
    "# fill NaN values with 0.0\n",
    "dti_bmgc_omics_df = dti_bmgc_omics_df.fillna(0.0)\n",
    "display(dti_bmgc_omics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.2 Add the index files for samples and nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an index data file for cell lines and save it to the DTI_data folder\n",
    "samples = dti_bmgc_omics_df.columns[1:]\n",
    "# create sample index ranging from 0 to len(samples)-1\n",
    "sample_index = np.arange(len(samples))\n",
    "sample_index_data = pd.DataFrame({'Sample': samples, 'Index': sample_index})\n",
    "display(sample_index_data)\n",
    "sample_index_data.to_csv('./DTI_data/sample_index.csv', index=False)\n",
    "\n",
    "# create an index data file for nodes and save it to the DTI_data folder\n",
    "nodes = dti_bmgc_omics_df['BioMedGraphica_Conn_ID'].tolist()\n",
    "# create nodes index ranging from 0 to len(nodes)-1\n",
    "nodes_index = np.arange(len(nodes))\n",
    "nodes_index_data = pd.DataFrame({'Node': nodes, 'Index': nodes_index})\n",
    "nodes_index_data = pd.merge(nodes_index_data, bmgc_entity_df[['BioMedGraphica_Conn_ID', 'Type']], left_on='Node', right_on='BioMedGraphica_Conn_ID', how='left').drop(columns=['BioMedGraphica_Conn_ID'])\n",
    "display(nodes_index_data)\n",
    "nodes_index_data.to_csv('./DTI_data/nodes_index.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.3 Convert to numpy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dti_bmgc_omics_df to numpy array aside from the first column (BioMedGraphica_Conn_ID) and save it to the DTI_data folder\n",
    "dti_bmgc_omics_array = dti_bmgc_omics_df.iloc[:, 1:].to_numpy()\n",
    "# transpose the array\n",
    "dti_bmgc_omics_array_T = dti_bmgc_omics_array.T\n",
    "print('The shape of dti_bmgc_omics_array_T is:', dti_bmgc_omics_array_T.shape)\n",
    "print(dti_bmgc_omics_array_T)\n",
    "# save the numpy array to the DTI_data folder\n",
    "np.save('./DTI_data/dti_bmgc_omics.npy', dti_bmgc_omics_array_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dti_drug_overlap_df, final_training_drug_screen_df and final_test_drug_screen_df to the DTI_data folder\n",
    "dti_drug_overlap_df.to_csv('./DTI_data/dti_drug_overlap.csv', index=False)\n",
    "final_training_drug_screen_df.to_csv('./DTI_data/final_training_drug_screen.csv', index=False)\n",
    "final_test_drug_screen_df.to_csv('./DTI_data/final_test_drug_screen.csv', index=False)\n",
    "final_training_drug_screen_numpy_df = final_training_drug_screen_df[['depMapID', 'BMGC_Drug_ID', 'BMGC_Disease_ID', 'AUC']].copy()\n",
    "final_test_drug_screen_numpy_df = final_test_drug_screen_df[['depMapID', 'BMGC_Drug_ID', 'BMGC_Disease_ID', 'AUC']].copy()\n",
    "display(final_training_drug_screen_numpy_df)\n",
    "display(final_test_drug_screen_numpy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries using zip and dict()\n",
    "sample_index_dict = dict(zip(sample_index_data['Sample'], sample_index_data['Index']))\n",
    "# Print the first 10 items of sample_index_dict\n",
    "print(\"First 10 items in sample_index_dict:\")\n",
    "print(list(sample_index_dict.items())[:10])\n",
    "\n",
    "node_index_dict = dict(zip(nodes_index_data['Node'], nodes_index_data['Index']))\n",
    "# Print the first 10 items of node_index_dict\n",
    "print(\"\\nFirst 10 items in node_index_dict:\")\n",
    "print(list(node_index_dict.items())[:10])\n",
    "\n",
    "# Map the depMapID and [BMGC_Drug_ID, BMGC_Disease_ID] to the index\n",
    "final_training_drug_screen_numpy_mapped_df = final_training_drug_screen_numpy_df.copy()\n",
    "final_training_drug_screen_numpy_mapped_df['depMapID'] = final_training_drug_screen_numpy_mapped_df['depMapID'].map(sample_index_dict)\n",
    "final_training_drug_screen_numpy_mapped_df['BMGC_Drug_ID'] = final_training_drug_screen_numpy_mapped_df['BMGC_Drug_ID'].map(node_index_dict)\n",
    "final_training_drug_screen_numpy_mapped_df['BMGC_Disease_ID'] = final_training_drug_screen_numpy_mapped_df['BMGC_Disease_ID'].map(node_index_dict)\n",
    "\n",
    "# check the null values in the final_training_drug_screen_numpy_mapped_df\n",
    "print(\"Null values in final_training_drug_screen_numpy_mapped_df:\")\n",
    "print(final_training_drug_screen_numpy_mapped_df.isnull().sum())\n",
    "display(final_training_drug_screen_numpy_mapped_df)\n",
    "\n",
    "# convert the final_training_drug_screen_numpy_mapped_df to numpy array and save it to the DTI_data folder\n",
    "final_training_drug_screen_numpy_mapped_array = final_training_drug_screen_numpy_mapped_df[['depMapID', 'BMGC_Drug_ID', 'BMGC_Disease_ID', 'AUC']].to_numpy()\n",
    "print('The shape of final_training_drug_screen_numpy_mapped_array is:', final_training_drug_screen_numpy_mapped_array.shape)\n",
    "print(final_training_drug_screen_numpy_mapped_array)\n",
    "# save the numpy array to the DTI_data folder\n",
    "np.save('./DTI_data/final_training_drug_screen_numpy_mapped.npy', final_training_drug_screen_numpy_mapped_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the depMapID and [BMGC_Drug_ID, BMGC_Disease_ID] to the index for test set\n",
    "final_test_drug_screen_numpy_mapped_df = final_test_drug_screen_numpy_df.copy()\n",
    "final_test_drug_screen_numpy_mapped_df['depMapID'] = final_test_drug_screen_numpy_mapped_df['depMapID'].map(sample_index_dict)\n",
    "final_test_drug_screen_numpy_mapped_df['BMGC_Drug_ID'] = final_test_drug_screen_numpy_mapped_df['BMGC_Drug_ID'].map(node_index_dict)\n",
    "final_test_drug_screen_numpy_mapped_df['BMGC_Disease_ID'] = final_test_drug_screen_numpy_mapped_df['BMGC_Disease_ID'].map(node_index_dict)\n",
    "\n",
    "# check the null values in the final_test_drug_screen_numpy_mapped_df\n",
    "print(\"Null values in final_test_drug_screen_numpy_mapped_df:\")\n",
    "print(final_test_drug_screen_numpy_mapped_df.isnull().sum())\n",
    "display(final_test_drug_screen_numpy_mapped_df)\n",
    "\n",
    "# convert the final_test_drug_screen_numpy_mapped_df to numpy array and save it to the DTI_data folder\n",
    "final_test_drug_screen_numpy_mapped_array = final_test_drug_screen_numpy_mapped_df[['depMapID', 'BMGC_Drug_ID', 'BMGC_Disease_ID', 'AUC']].to_numpy()\n",
    "print('The shape of final_test_drug_screen_numpy_mapped_array is:', final_test_drug_screen_numpy_mapped_array.shape)\n",
    "print(final_test_drug_screen_numpy_mapped_array)\n",
    "# save the numpy array to the DTI_data folder\n",
    "np.save('./DTI_data/final_test_drug_screen_numpy_mapped.npy', final_test_drug_screen_numpy_mapped_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the bmgc_relation_df to numpy array and save it to the DTI_data folder as the edge_index.npy\n",
    "# keep the columns ['BMGC_From_ID', 'BMGC_To_ID']\n",
    "edge_index_df = bmgc_relation_df[['BMGC_From_ID', 'BMGC_To_ID']].copy()\n",
    "# Map the BMGC_From_ID and BMGC_To_ID by the node_index_dict\n",
    "edge_index_df['BMGC_From_ID'] = edge_index_df['BMGC_From_ID'].map(node_index_dict)\n",
    "edge_index_df['BMGC_To_ID'] = edge_index_df['BMGC_To_ID'].map(node_index_dict)\n",
    "# check the null values in the edge_index_df\n",
    "print(\"Null values in edge_index_df:\")\n",
    "print(edge_index_df.isnull().sum())\n",
    "display(edge_index_df)\n",
    "# convert the edge_index_df to numpy array and save it to the DTI_data folder\n",
    "edge_index_array = edge_index_df.to_numpy().T\n",
    "print('The shape of edge_index_array is:', edge_index_array.shape)\n",
    "print(edge_index_array)\n",
    "# save the numpy array to the DTI_data folder\n",
    "np.save('./DTI_data/edge_index.npy', edge_index_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the internal_edge_index by selecting bmgc_relation_df in Type ['Promoter-Gene', 'Gene-Transcript', 'Transcript-Protein']\n",
    "internal_edge_index_df = bmgc_relation_df[bmgc_relation_df['Type'].isin(['Promoter-Gene', 'Gene-Transcript', 'Transcript-Protein'])].copy()\n",
    "# keep the columns ['BMGC_From_ID', 'BMGC_To_ID']\n",
    "internal_edge_index_df = internal_edge_index_df[['BMGC_From_ID', 'BMGC_To_ID']].copy()\n",
    "# Map the BMGC_From_ID and BMGC_To_ID by the node_index_dict\n",
    "internal_edge_index_df['BMGC_From_ID'] = internal_edge_index_df['BMGC_From_ID'].map(node_index_dict)\n",
    "internal_edge_index_df['BMGC_To_ID'] = internal_edge_index_df['BMGC_To_ID'].map(node_index_dict)\n",
    "# check the null values in the internal_edge_index_df\n",
    "print(\"Null values in internal_edge_index_df:\")\n",
    "print(internal_edge_index_df.isnull().sum())\n",
    "# convert the internal_edge_index_df to numpy array and save it to the DTI_data folder\n",
    "internal_edge_index_array = internal_edge_index_df.to_numpy().T\n",
    "print('The shape of internal_edge_index_array is:', internal_edge_index_array.shape)\n",
    "print(internal_edge_index_array)\n",
    "# save the numpy array to the DTI_data folder\n",
    "np.save('./DTI_data/internal_edge_index.npy', internal_edge_index_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the ppi_edge_index by selecting bmgc_relation_df in Type ['Protein-Protein']\n",
    "ppi_edge_index_df = bmgc_relation_df[bmgc_relation_df['Type'].isin(['Protein-Protein'])].copy()\n",
    "# keep the columns ['BMGC_From_ID', 'BMGC_To_ID']\n",
    "ppi_edge_index_df = ppi_edge_index_df[['BMGC_From_ID', 'BMGC_To_ID']].copy()\n",
    "# Map the BMGC_From_ID and BMGC_To_ID by the node_index_dict\n",
    "ppi_edge_index_df['BMGC_From_ID'] = ppi_edge_index_df['BMGC_From_ID'].map(node_index_dict)\n",
    "ppi_edge_index_df['BMGC_To_ID'] = ppi_edge_index_df['BMGC_To_ID'].map(node_index_dict)\n",
    "# check the null values in the ppi_edge_index_df\n",
    "print(\"Null values in ppi_edge_index_df:\")\n",
    "print(ppi_edge_index_df.isnull().sum())\n",
    "# convert the ppi_edge_index_df to numpy array and save it to the DTI_data folder\n",
    "ppi_edge_index_array = ppi_edge_index_df.to_numpy().T\n",
    "print('The shape of ppi_edge_index_array is:', ppi_edge_index_array.shape)\n",
    "print(ppi_edge_index_array)\n",
    "# save the numpy array to the DTI_data folder\n",
    "np.save('./DTI_data/ppi_edge_index.npy', ppi_edge_index_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.4 DTI data with name and desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the name and desc files\n",
    "bmgc_promoter_name_id_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Promoter/BioMedGraphica_Conn_Promoter_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_gene_name_id_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Gene/BioMedGraphica_Conn_Gene_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_transcript_name_id_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Transcript/BioMedGraphica_Conn_Transcript_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_protein_name_id_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Protein/BioMedGraphica_Conn_Protein_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_pathway_name_id_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Pathway/BioMedGraphica_Conn_Pathway_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_metabolite_name_id_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Metabolite/BioMedGraphica_Conn_Metabolite_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_microbiota_name_id_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Microbiota/BioMedGraphica_Conn_Microbiota_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_exposure_name_id_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Exposure/BioMedGraphica_Conn_Exposure_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_phenotype_name_id_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Phenotype/BioMedGraphica_Conn_Phenotype_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_disease_name_id_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Disease/BioMedGraphica_Conn_Disease_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_drug_name_id_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Drug/BioMedGraphica_Conn_Drug_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of rows in each dataframe and sum the number of rows for those dataframes\n",
    "print(\"bmgc_promoter_name_id_df:\", len(bmgc_promoter_name_id_df))\n",
    "print(\"bmgc_gene_name_id_df:\", len(bmgc_gene_name_id_df))\n",
    "print(\"bmgc_transcript_name_id_df:\", len(bmgc_transcript_name_id_df))\n",
    "print(\"bmgc_protein_name_id_df:\", len(bmgc_protein_name_id_df))\n",
    "print(\"bmgc_pathway_name_id_df:\", len(bmgc_pathway_name_id_df))\n",
    "print(\"bmgc_metabolite_name_id_df:\", len(bmgc_metabolite_name_id_df))\n",
    "print(\"bmgc_microbiota_name_id_df:\", len(bmgc_microbiota_name_id_df))\n",
    "print(\"bmgc_exposure_name_id_df:\", len(bmgc_exposure_name_id_df))\n",
    "print(\"bmgc_phenotype_name_id_df:\", len(bmgc_phenotype_name_id_df))\n",
    "print(\"bmgc_disease_name_id_df:\", len(bmgc_disease_name_id_df))\n",
    "print(\"bmgc_drug_name_id_df:\", len(bmgc_drug_name_id_df))\n",
    "# sum the number of rows for those dataframes\n",
    "print(\"Total number of rows in all dataframes:\", len(bmgc_promoter_name_id_df) + len(bmgc_gene_name_id_df) + len(bmgc_transcript_name_id_df) + len(bmgc_protein_name_id_df) + len(bmgc_pathway_name_id_df) + len(bmgc_metabolite_name_id_df) + len(bmgc_microbiota_name_id_df) + len(bmgc_exposure_name_id_df) + len(bmgc_phenotype_name_id_df) + len(bmgc_disease_name_id_df) + len(bmgc_drug_name_id_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join those name_df into bmgc_entity_df\n",
    "bmgc_entity_cp_df = bmgc_entity_df[['BioMedGraphica_Conn_ID']].copy()\n",
    "display(bmgc_entity_cp_df)\n",
    "# concatenate all the name_id_df into one dataframe\n",
    "bmgc_name_id_tmp_df = pd.concat([bmgc_promoter_name_id_df, bmgc_gene_name_id_df, bmgc_transcript_name_id_df, bmgc_protein_name_id_df, bmgc_pathway_name_id_df, bmgc_metabolite_name_id_df, bmgc_microbiota_name_id_df, bmgc_exposure_name_id_df, bmgc_phenotype_name_id_df, bmgc_disease_name_id_df, bmgc_drug_name_id_df], ignore_index=True)\n",
    "display(bmgc_name_id_tmp_df)\n",
    "# left join the bmgc_name_id_tmp_df into bmgc_entity_cp_df on BioMedGraphica_Conn_ID\n",
    "bmgc_entity_cp_df = pd.merge(bmgc_entity_cp_df, bmgc_name_id_tmp_df, on='BioMedGraphica_Conn_ID', how='left')\n",
    "display(bmgc_entity_cp_df)\n",
    "bmgc_entity_cp_df.to_csv('./DTI_data/bmgc_name.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmgc_promoter_desc_df = bmgc_promoter_name_id_df.drop(columns=['Names_and_IDs'], axis=1).copy()\n",
    "bmgc_promoter_desc_df['Description'] = np.nan # add the Description column to bmgc_promoter_name_df with NaN values\n",
    "bmgc_gene_desc_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Gene/BioMedGraphica_Conn_Gene_Description_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_transcript_desc_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Transcript/BioMedGraphica_Conn_Transcript_Description_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_protein_desc_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Protein/BioMedGraphica_Conn_Protein_Description_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_pathway_desc_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Pathway/BioMedGraphica_Conn_Pathway_Description_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_metabolite_desc_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Metabolite/BioMedGraphica_Conn_Metabolite_Description_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_microbiota_desc_df = bmgc_microbiota_name_id_df.drop(columns=['Names_and_IDs'], axis=1).copy()\n",
    "bmgc_microbiota_desc_df['Description'] = np.nan # add the Description column to bmgc_microbiota_name_df with NaN values\n",
    "bmgc_exposure_desc_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Exposure/BioMedGraphica_Conn_Exposure_Description_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_phenotype_desc_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Phenotype/BioMedGraphica_Conn_Phenotype_Description_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_disease_desc_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Disease/BioMedGraphica_Conn_Disease_Description_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_drug_desc_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Drug/BioMedGraphica_Conn_Drug_Description_Combined.csv').drop(columns=['BioMedGraphica_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmgc_desc_tmp_df = pd.concat([bmgc_promoter_desc_df, bmgc_gene_desc_df, bmgc_transcript_desc_df, bmgc_protein_desc_df, bmgc_pathway_desc_df, bmgc_metabolite_desc_df, bmgc_microbiota_desc_df, bmgc_exposure_desc_df, bmgc_phenotype_desc_df, bmgc_disease_desc_df, bmgc_drug_desc_df], ignore_index=True)\n",
    "display(bmgc_desc_tmp_df)\n",
    "# left join the bmgc_desc_tmp_df into bmgc_entity_cp_df on BioMedGraphica_Conn_ID\n",
    "bmgc_entity_cp_df = bmgc_entity_df[['BioMedGraphica_Conn_ID']].copy()\n",
    "bmgc_desc_df = pd.merge(bmgc_entity_cp_df, bmgc_desc_tmp_df, on='BioMedGraphica_Conn_ID', how='left')\n",
    "# check the null values in the bmgc_desc_df\n",
    "print(\"Null values in bmgc_desc_df:\")\n",
    "print(bmgc_desc_df.isnull().sum())\n",
    "# fill the NaN values in the Description column with empty string\n",
    "bmgc_desc_df['Description'] = bmgc_desc_df['Description'].fillna(' ')\n",
    "# recheck the null values in the bmgc_desc_df\n",
    "print(\"Null values in bmgc_desc_df:\")\n",
    "print(bmgc_desc_df.isnull().sum())\n",
    "display(bmgc_desc_df)\n",
    "bmgc_desc_df.to_csv('./DTI_data/bmgc_desc.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a meta data file in the folder DTI_data to explain the dti_bmgc_omics.npy, final_training_drug_screen_numpy_mapped.npy, final_test_drug_screen_numpy_mapped.npy for following:\n",
    "# 1. dti_bmgc_omics.npy: each row is a sample, and each column is a feature. The row index corresponds to the sample index in the sample_index.csv file. The column index corresponds to the feature index in the nodes_index.csv file.\n",
    "# 2. final_training_drug_screen_numpy_mapped.npy: each row is a drug-screening sample, and it has 4 columns: depMapID sample index, BMGC_Drug_ID drug index, BMGC_Disease_ID disease index, AUC value. \n",
    "# By using the sample index to fetch the sample in dti_bmgc_omics.npy, and using the drug index and disease index to mark the drug and disease in the dti_bmgc_omics.npy as 1, and the rest as 0.\n",
    "# 3. final_test_drug_screen_numpy_mapped.npy: same as final_training_drug_screen_numpy_mapped.npy, but for test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Pretrain numpy files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3.1 Pretraining data for omics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load entity type ['Promoter', 'Gene', 'Transcript', 'Protein'] for bmgc_entity_df\n",
    "bmgc_entity_df = pd.read_csv('./BioMedGraphica-Conn/Entity/BioMedGraphica_Conn_Entity.csv')\n",
    "# check if there is any null values in the bmgc_entity_df\n",
    "print(bmgc_entity_df.isnull().sum())\n",
    "# filter out the rows with Type in the list ['promoter', 'gene', 'transcript', 'protein']\n",
    "bmgc_omics_df = bmgc_entity_df[bmgc_entity_df['Type'].isin(['Promoter', 'Gene', 'Transcript', 'Protein'])].reset_index(drop=True)\n",
    "# check if there is any null values in the bmgc_omics_df\n",
    "print(bmgc_omics_df.isnull().sum())\n",
    "display(bmgc_omics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the relation\n",
    "bmgc_relation_df = pd.read_csv('./BioMedGraphica-Conn/Relation/BioMedGraphica_Conn_Relation.csv')\n",
    "# check if there is any null values in the bmgc_relation_df\n",
    "print(bmgc_relation_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter our the rows with Relation type in the list ['Promoter-Gene', 'Gene-Transcript', 'Transcript-Protein', 'Protein-Protein']\n",
    "bmgc_omics_relation_df = bmgc_relation_df[bmgc_relation_df['Type'].isin(['Promoter-Gene', 'Gene-Transcript', 'Transcript-Protein', 'Protein-Protein'])].reset_index(drop=True)\n",
    "# check if there is any null values in the bmgc_omics_relation_df\n",
    "print(bmgc_omics_relation_df.isnull().sum())\n",
    "display(bmgc_omics_relation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_bmgc_omics_df = pd.merge(bmgc_omics_df['BioMedGraphica_Conn_ID'], pretrain_omics_df, on='BioMedGraphica_Conn_ID', how='left')\n",
    "# sort the columns orders ACH-xxxxxxx by ascending order aside from the first column (BioMedGraphica_Conn_ID)\n",
    "pretrain_bmgc_omics_df = pretrain_bmgc_omics_df[['BioMedGraphica_Conn_ID'] + sorted(pretrain_bmgc_omics_df.columns[1:])]\n",
    "display(pretrain_bmgc_omics_df)\n",
    "# check if there is any null values in the pretrain_bmgc_omics_df and null value over whole dataframe\n",
    "print(pretrain_bmgc_omics_df.isnull().sum())\n",
    "print(pretrain_bmgc_omics_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3.2 Add the index files for samples and nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the index for cell lines and entities in the pretrain_bmgc_omics_df\n",
    "samples = pretrain_bmgc_omics_df.columns[1:]\n",
    "# create sample index ranging from 0 to len(samples)-1\n",
    "sample_index = np.arange(len(samples))\n",
    "sample_index_data = pd.DataFrame({'Sample': samples, 'Index': sample_index})\n",
    "display(sample_index_data)\n",
    "# save the sample index data to the Pretrain_data folder\n",
    "sample_index_data.to_csv('./Pretrain_data/sample_index.csv', index=False)\n",
    "\n",
    "# Create the index data for nodes and save it to the Pretrain_data folder\n",
    "omics_nodes = pretrain_bmgc_omics_df['BioMedGraphica_Conn_ID'].tolist()\n",
    "# create nodes index ranging from 0 to len(nodes)-1\n",
    "omics_nodes_index = np.arange(len(omics_nodes))\n",
    "omics_nodes_index_data = pd.DataFrame({'Node': omics_nodes, 'Index': omics_nodes_index})\n",
    "omics_nodes_index_data = pd.merge(omics_nodes_index_data, bmgc_omics_df[['BioMedGraphica_Conn_ID', 'Type']], left_on='Node', right_on='BioMedGraphica_Conn_ID', how='left').drop(columns=['BioMedGraphica_Conn_ID'])\n",
    "display(omics_nodes_index_data)\n",
    "# save the nodes index data to the Pretrain_data folder\n",
    "omics_nodes_index_data.to_csv('./Pretrain_data/omics_nodes_index.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3.3 Convert to numpy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the pretrain_bmgc_omics_df to numpy array aside from the first column (BioMedGraphica_Conn_ID) and save it to the Pretrain_data folder\n",
    "pretrain_bmgc_omics_array = pretrain_bmgc_omics_df.iloc[:, 1:].to_numpy()\n",
    "# transpose the array\n",
    "pretrain_bmgc_omics_array_T = pretrain_bmgc_omics_array.T\n",
    "print('The shape of pretrain_bmgc_omics_array_T is:', pretrain_bmgc_omics_array_T.shape)\n",
    "print(pretrain_bmgc_omics_array_T)\n",
    "# save the numpy array to the Pretrain_data folder\n",
    "np.save('./Pretrain_data/pretrain_bmgc_omics.npy', pretrain_bmgc_omics_array_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-cancerous cell lines\n",
    "non_cancerous_samples_df = pd.read_csv('./raw_data/cell-lines-in-Non-Cancerous.csv')\n",
    "# Add the column 'Status' to the non_cancerous_samples_df with value of 0\n",
    "non_cancerous_samples_df['Status'] = 0\n",
    "# keep the columns ['Depmap Id', 'Status']\n",
    "non_cancerous_samples_df = non_cancerous_samples_df[['Depmap Id', 'Status']].copy()\n",
    "# display(non_cancerous_samples_df)\n",
    "\n",
    "# join the non_cancerous_samples_df with sample_index_data on Depmap Id\n",
    "pretrain_label_df = pd.merge(sample_index_data, non_cancerous_samples_df, left_on='Sample', right_on='Depmap Id', how='left')\n",
    "# display(pretrain_label_df)\n",
    "# fill NaN values with 1 in Status column\n",
    "pretrain_label_df['Status'] = pretrain_label_df['Status'].fillna(1)\n",
    "# keep the columns['Sample', 'Index', 'Status']\n",
    "pretrain_label_df = pretrain_label_df[['Sample', 'Index', 'Status']].copy()\n",
    "display(pretrain_label_df)\n",
    "\n",
    "# count the number of 0s and 1s in the Status column\n",
    "print(pretrain_label_df['Status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9.3.3.1 Upsampling training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Step 1: Split data into train and test sets while preserving class distribution\n",
    "train_df, test_df = train_test_split(\n",
    "    pretrain_label_df,\n",
    "    test_size=0.2,  # 80% train, 20% test\n",
    "    random_state=42,\n",
    "    stratify=pretrain_label_df['Status']  # Ensures same class distribution in train/test\n",
    ")\n",
    "\n",
    "# Reset indices\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# Display original distributions\n",
    "print(\"Before upsampling:\")\n",
    "print(\"Training set class distribution:\")\n",
    "print(train_df['Status'].value_counts())\n",
    "print(train_df['Status'].value_counts(normalize=True))\n",
    "\n",
    "# Step 2: Separate cancerous and non-cancerous samples in the training set\n",
    "train_cancerous = train_df[train_df['Status'] == True]\n",
    "train_non_cancerous = train_df[train_df['Status'] == False]\n",
    "\n",
    "# Count samples\n",
    "n_train_cancerous = len(train_cancerous)\n",
    "n_train_non_cancerous = len(train_non_cancerous)\n",
    "\n",
    "# Step 3: Upsample the minority class in the training set only\n",
    "if n_train_non_cancerous < n_train_cancerous:\n",
    "    # Upsample non-cancerous samples\n",
    "    train_non_cancerous_upsampled = resample(\n",
    "        train_non_cancerous,\n",
    "        replace=True,\n",
    "        n_samples=n_train_cancerous,\n",
    "        random_state=42\n",
    "    )\n",
    "    # Combine upsampled non-cancerous with original cancerous\n",
    "    balanced_train_df = pd.concat([train_cancerous, train_non_cancerous_upsampled])\n",
    "else:\n",
    "    # Upsample cancerous samples\n",
    "    train_cancerous_upsampled = resample(\n",
    "        train_cancerous,\n",
    "        replace=True, \n",
    "        n_samples=n_train_non_cancerous,\n",
    "        random_state=42\n",
    "    )\n",
    "    # Combine upsampled cancerous with original non-cancerous\n",
    "    balanced_train_df = pd.concat([train_cancerous_upsampled, train_non_cancerous])\n",
    "\n",
    "# Shuffle the balanced training set\n",
    "balanced_train_df = balanced_train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display final distributions\n",
    "print(\"\\nAfter upsampling:\")\n",
    "print(\"Training set class distribution:\")\n",
    "print(balanced_train_df['Status'].value_counts())\n",
    "print(balanced_train_df['Status'].value_counts(normalize=True))\n",
    "print(\"\\nTest set class distribution (unchanged):\")\n",
    "print(test_df['Status'].value_counts())\n",
    "print(test_df['Status'].value_counts(normalize=True))\n",
    "\n",
    "# Optionally save the datasets\n",
    "balanced_train_df.to_csv('./Pretrain_data/balanced_train.csv', index=False)\n",
    "test_df.to_csv('./Pretrain_data/balanced_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for overlapping samples between two dataframes\n",
    "def check_overlapping_samples(df1, df2, label='Status'):\n",
    "    \"\"\"\n",
    "    Check for overlapping samples between two dataframes\n",
    "    \n",
    "    Args:\n",
    "        df1, df2: The dataframes to compare\n",
    "        label: Optional column to exclude from comparison\n",
    "    \n",
    "    Returns:\n",
    "        Number of overlapping samples and the overlapping rows\n",
    "    \"\"\"\n",
    "    # Get columns to compare (all except possibly the label)\n",
    "    cols_to_compare = [col for col in df1.columns if col != label]\n",
    "    \n",
    "    # Method 1: Direct merge approach\n",
    "    merged = pd.merge(df1[cols_to_compare], df2[cols_to_compare], \n",
    "                      how='inner', indicator=False)\n",
    "    \n",
    "    # If we have any rows in the merged DataFrame, those are duplicates\n",
    "    num_duplicates = len(merged)\n",
    "    \n",
    "    # Method 2: Convert to tuples and use set intersection\n",
    "    # This is a verification step - should match the first method\n",
    "    df1_tuples = set(map(tuple, df1[cols_to_compare].values))\n",
    "    df2_tuples = set(map(tuple, df2[cols_to_compare].values))\n",
    "    intersection = df1_tuples.intersection(df2_tuples)\n",
    "    \n",
    "    print(f\"Number of duplicated samples: {num_duplicates}\")\n",
    "    print(f\"Verification: Set intersection found {len(intersection)} duplicates\")\n",
    "    \n",
    "    # Return the duplicated rows for inspection if any exist\n",
    "    if num_duplicates > 0:\n",
    "        return merged.drop_duplicates()\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Check for overlapping samples between our balanced training set and test set\n",
    "overlapping_samples = check_overlapping_samples(balanced_train_df, test_df)\n",
    "\n",
    "if len(overlapping_samples) > 0:\n",
    "    print(\"WARNING: Found overlapping samples between training and test sets!\")\n",
    "    print(\"Sample of duplicated data points:\")\n",
    "    print(overlapping_samples.head())\n",
    "else:\n",
    "    print(\"No overlapping samples found between training and test sets. Data split is clean.\")\n",
    "    \n",
    "# Additional check: Double-check that upsampling hasn't created duplicates within training set\n",
    "train_duplicates = balanced_train_df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicated rows within training set: {train_duplicates}\")\n",
    "\n",
    "# This is expected since we've upsampled and should see duplicates in training\n",
    "if train_duplicates > 0:\n",
    "    print(\"Note: Duplicates in training set are expected due to upsampling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract columns from balanced training set and convert to numpy array\n",
    "balanced_train_numpy_df = balanced_train_df[['Index', 'Status']].copy()\n",
    "balanced_train_numpy = balanced_train_numpy_df.to_numpy()\n",
    "print('The shape of balanced_train_numpy is:', balanced_train_numpy.shape)\n",
    "print(balanced_train_numpy[:10])  # Print first 10 rows as a sample\n",
    "\n",
    "# Save the balanced training numpy array\n",
    "np.save('./Pretrain_data/balanced_train.npy', balanced_train_numpy)\n",
    "\n",
    "# Extract columns from test set and convert to numpy array \n",
    "test_numpy_df = test_df[['Index', 'Status']].copy()\n",
    "test_numpy = test_numpy_df.to_numpy()\n",
    "print('\\nThe shape of test_numpy is:', test_numpy.shape)\n",
    "print(test_numpy[:10])  # Print first 10 rows as a sample\n",
    "\n",
    "# Save the test numpy array\n",
    "np.save('./Pretrain_data/balanced_test.npy', test_numpy)\n",
    "\n",
    "print(\"\\nNumPy arrays successfully saved to Pretrain_data folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9.3.3.2 Upsampliing the train minority and Downsampling test majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Step 1: Split data into train and test sets while preserving class distribution\n",
    "train_df, test_df = train_test_split(\n",
    "    pretrain_label_df,\n",
    "    test_size=0.2,  # 80% train, 20% test\n",
    "    random_state=42,\n",
    "    stratify=pretrain_label_df['Status']  # Ensures same class distribution in train/test\n",
    ")\n",
    "\n",
    "# Reset indices\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# Display original distributions\n",
    "print(\"Before upsampling/downsampling:\")\n",
    "print(\"Training set class distribution:\")\n",
    "print(train_df['Status'].value_counts())\n",
    "print(train_df['Status'].value_counts(normalize=True))\n",
    "print(\"\\nTest set original class distribution:\")\n",
    "print(test_df['Status'].value_counts())\n",
    "print(test_df['Status'].value_counts(normalize=True))\n",
    "\n",
    "# Step 2: Process training set - Upsample minority class to 30% (70/30 ratio)\n",
    "train_cancerous = train_df[train_df['Status'] == True]\n",
    "train_non_cancerous = train_df[train_df['Status'] == False]\n",
    "\n",
    "# Count samples\n",
    "n_train_cancerous = len(train_cancerous)\n",
    "n_train_non_cancerous = len(train_non_cancerous)\n",
    "\n",
    "# Calculate target numbers for 70-30 ratio in training set\n",
    "if n_train_cancerous > n_train_non_cancerous:\n",
    "    # Cancerous is majority (70%), non-cancerous is minority (30%)\n",
    "    target_non_cancerous = int(n_train_cancerous * 3/7)  # To achieve 70-30 ratio\n",
    "    \n",
    "    # Upsample non-cancerous samples\n",
    "    train_non_cancerous_upsampled = resample(\n",
    "        train_non_cancerous,\n",
    "        replace=True,\n",
    "        n_samples=target_non_cancerous,\n",
    "        random_state=42\n",
    "    )\n",
    "    # Combine upsampled non-cancerous with original cancerous\n",
    "    balanced_train_df = pd.concat([train_cancerous, train_non_cancerous_upsampled])\n",
    "else:\n",
    "    # Non-cancerous is majority (70%), cancerous is minority (30%)\n",
    "    target_cancerous = int(n_train_non_cancerous * 3/7)  # To achieve 70-30 ratio\n",
    "    \n",
    "    # Upsample cancerous samples\n",
    "    train_cancerous_upsampled = resample(\n",
    "        train_cancerous,\n",
    "        replace=True, \n",
    "        n_samples=target_cancerous,\n",
    "        random_state=42\n",
    "    )\n",
    "    # Combine upsampled cancerous with original non-cancerous\n",
    "    balanced_train_df = pd.concat([train_cancerous_upsampled, train_non_cancerous])\n",
    "\n",
    "# Step 3: Process test set - Downsample majority class to achieve 70/30 ratio\n",
    "test_cancerous = test_df[test_df['Status'] == True]\n",
    "test_non_cancerous = test_df[test_df['Status'] == False]\n",
    "\n",
    "n_test_cancerous = len(test_cancerous)\n",
    "n_test_non_cancerous = len(test_non_cancerous)\n",
    "\n",
    "if n_test_cancerous > n_test_non_cancerous:\n",
    "    # Cancerous is majority - downsample to 70%\n",
    "    # Calculate how many cancerous samples we need for a 70/30 ratio\n",
    "    target_cancerous = int(n_test_non_cancerous * 7/3)\n",
    "    \n",
    "    # Downsample cancerous samples without replacement\n",
    "    test_cancerous_downsampled = test_cancerous.sample(\n",
    "        n=target_cancerous,\n",
    "        random_state=42\n",
    "    )\n",
    "    # Combine downsampled cancerous with original non-cancerous\n",
    "    balanced_test_df = pd.concat([test_cancerous_downsampled, test_non_cancerous])\n",
    "else:\n",
    "    # Non-cancerous is majority - downsample to 70%\n",
    "    # Calculate how many non-cancerous samples we need for a 70/30 ratio\n",
    "    target_non_cancerous = int(n_test_cancerous * 7/3)\n",
    "    \n",
    "    # Downsample non-cancerous samples without replacement\n",
    "    test_non_cancerous_downsampled = test_non_cancerous.sample(\n",
    "        n=target_non_cancerous,\n",
    "        random_state=42\n",
    "    )\n",
    "    # Combine downsampled non-cancerous with original cancerous\n",
    "    balanced_test_df = pd.concat([test_cancerous, test_non_cancerous_downsampled])\n",
    "\n",
    "# Shuffle both datasets\n",
    "balanced_train_df = balanced_train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "balanced_test_df = balanced_test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display final distributions\n",
    "print(\"\\nAfter processing:\")\n",
    "print(\"Training set class distribution:\")\n",
    "print(balanced_train_df['Status'].value_counts())\n",
    "print(balanced_train_df['Status'].value_counts(normalize=True))\n",
    "print(\"\\nTest set class distribution:\")\n",
    "print(balanced_test_df['Status'].value_counts())\n",
    "print(balanced_test_df['Status'].value_counts(normalize=True))\n",
    "\n",
    "# Save the datasets\n",
    "balanced_train_df.to_csv('./Pretrain_data/balanced_train.csv', index=False)\n",
    "balanced_test_df.to_csv('./Pretrain_data/balanced_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract columns from balanced training set and convert to numpy array\n",
    "balanced_train_numpy_df = balanced_train_df[['Index', 'Status']].copy()\n",
    "balanced_train_numpy = balanced_train_numpy_df.to_numpy()\n",
    "print('The shape of balanced_train_numpy is:', balanced_train_numpy.shape)\n",
    "print('Class distribution in balanced training set:')\n",
    "print(np.bincount(balanced_train_numpy[:, 1].astype(int)))\n",
    "print('Sample rows:')\n",
    "print(balanced_train_numpy[:10])  # Print first 10 rows as a sample\n",
    "\n",
    "# Save the balanced training numpy array\n",
    "np.save('./Pretrain_data/balanced_train.npy', balanced_train_numpy)\n",
    "\n",
    "# Extract columns from balanced test set and convert to numpy array \n",
    "balanced_test_numpy_df = balanced_test_df[['Index', 'Status']].copy()\n",
    "balanced_test_numpy = balanced_test_numpy_df.to_numpy()\n",
    "print('\\nThe shape of balanced_test_numpy is:', balanced_test_numpy.shape)\n",
    "print('Class distribution in balanced test set:')\n",
    "print(np.bincount(balanced_test_numpy[:, 1].astype(int)))\n",
    "print('Sample rows:')\n",
    "print(balanced_test_numpy[:10])  # Print first 10 rows as a sample\n",
    "\n",
    "# Save the balanced test numpy array\n",
    "np.save('./Pretrain_data/balanced_test.npy', balanced_test_numpy)\n",
    "\n",
    "print(\"\\nNumPy arrays successfully saved to Pretrain_data folder with 70/30 class distribution.\")\n",
    "\n",
    "# Optional: Verify the saved files\n",
    "train_loaded = np.load('./Pretrain_data/balanced_train.npy')\n",
    "test_loaded = np.load('./Pretrain_data/balanced_test.npy')\n",
    "\n",
    "print(\"\\nVerification of saved files:\")\n",
    "print(f\"Train set shape: {train_loaded.shape}\")\n",
    "print(f\"Test set shape: {test_loaded.shape}\")\n",
    "print(\"Class distributions after loading:\")\n",
    "print(f\"Train: {np.bincount(train_loaded[:, 1].astype(int))}\")\n",
    "print(f\"Test: {np.bincount(test_loaded[:, 1].astype(int))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries using zip and dict()\n",
    "sample_index_dict = dict(zip(sample_index_data['Sample'], sample_index_data['Index']))\n",
    "# Print the first 10 items of sample_index_dict\n",
    "print(\"First 10 items in sample_index_dict:\")\n",
    "print(list(sample_index_dict.items())[:10])\n",
    "print(len(sample_index_dict))\n",
    "\n",
    "node_index_dict = dict(zip(nodes_index_data['Node'], nodes_index_data['Index']))\n",
    "# Print the first 10 items of node_index_dict\n",
    "print(\"\\nFirst 10 items in node_index_dict:\")\n",
    "print(list(node_index_dict.items())[:10])\n",
    "print(len(node_index_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the bmgc_omics_relation_df to numpy array and save it to the Pretrain_data folder as the edge_index.npy\n",
    "# Keep the columns ['BMGC_From_ID', 'BMGC_To_ID']\n",
    "edge_index_df = bmgc_omics_relation_df[['BMGC_From_ID', 'BMGC_To_ID']].copy()\n",
    "\n",
    "# Map the BMGC_From_ID and BMGC_To_ID by the node_index_dict\n",
    "edge_index_df['BMGC_From_ID'] = edge_index_df['BMGC_From_ID'].map(node_index_dict) # Can use the same node_index_dict with dti_samples\n",
    "edge_index_df['BMGC_To_ID'] = edge_index_df['BMGC_To_ID'].map(node_index_dict)\n",
    "\n",
    "# check the null values in the edge_index_df\n",
    "print(\"Null values in edge_index_df:\")\n",
    "print(edge_index_df.isnull().sum())\n",
    "# print the rows with null values in column BMGC_From_ID the edge_index_df\n",
    "print(edge_index_df[edge_index_df['BMGC_From_ID'].isnull()])\n",
    "display(edge_index_df)\n",
    "# convert the edge_index_df to numpy array and save it to the Pretrain_data folder\n",
    "edge_index_array = edge_index_df.to_numpy().T\n",
    "print('The shape of edge_index_array is:', edge_index_array.shape)\n",
    "print(edge_index_array[:10])  # Print first 10 rows as a sample\n",
    "# save the numpy array to the Pretrain_data folder\n",
    "np.save('./Pretrain_data/edge_index.npy', edge_index_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the internal_edge_index by Type belongs to ['Promoter-Gene', 'Gene-Transcript', 'Transcript-Protein']\n",
    "internal_edge_index_df = bmgc_omics_relation_df[bmgc_omics_relation_df['Type'].isin(['Promoter-Gene', 'Gene-Transcript', 'Transcript-Protein'])].reset_index(drop=True)\n",
    "internal_edge_index_df = internal_edge_index_df[['BMGC_From_ID', 'BMGC_To_ID']].copy()\n",
    "# Map the BMGC_From_ID and BMGC_To_ID by the node_index_dict\n",
    "internal_edge_index_df['BMGC_From_ID'] = internal_edge_index_df['BMGC_From_ID'].map(node_index_dict)\n",
    "internal_edge_index_df['BMGC_To_ID'] = internal_edge_index_df['BMGC_To_ID'].map(node_index_dict)\n",
    "display(internal_edge_index_df)\n",
    "# convert the internal_edge_index_df to numpy array and save it to the Pretrain_data folder\n",
    "internal_edge_index_array = internal_edge_index_df.to_numpy().T\n",
    "print('The shape of internal_edge_index_array is:', internal_edge_index_array.shape)\n",
    "print(internal_edge_index_array[:10])  # Print first 10 rows as a sample\n",
    "# save the numpy array to the Pretrain_data folder\n",
    "np.save('./Pretrain_data/internal_edge_index.npy', internal_edge_index_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the ppi_edge_index by Type belongs to ['Protein-Protein']\n",
    "ppi_edge_index_df = bmgc_omics_relation_df[bmgc_omics_relation_df['Type'].isin(['Protein-Protein'])].reset_index(drop=True)\n",
    "ppi_edge_index_df = ppi_edge_index_df[['BMGC_From_ID', 'BMGC_To_ID']].copy()\n",
    "# Map the BMGC_From_ID and BMGC_To_ID by the node_index_dict\n",
    "ppi_edge_index_df['BMGC_From_ID'] = ppi_edge_index_df['BMGC_From_ID'].map(node_index_dict)\n",
    "ppi_edge_index_df['BMGC_To_ID'] = ppi_edge_index_df['BMGC_To_ID'].map(node_index_dict)\n",
    "display(ppi_edge_index_df)\n",
    "# convert the ppi_edge_index_df to numpy array and save it to the Pretrain_data folder\n",
    "ppi_edge_index_array = ppi_edge_index_df.to_numpy().T\n",
    "print('The shape of ppi_edge_index_array is:', ppi_edge_index_array.shape)\n",
    "print(ppi_edge_index_array[:10])  # Print first 10 rows as a sample\n",
    "# save the numpy array to the Pretrain_data folder\n",
    "np.save('./Pretrain_data/ppi_edge_index.npy', ppi_edge_index_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3.4 Pretrain data with name and desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmgc_omics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the name and desc files\n",
    "bmgc_promoter_name_id_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Promoter/BioMedGraphica_Conn_Promoter_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_gene_name_id_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Gene/BioMedGraphica_Conn_Gene_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_transcript_name_id_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Transcript/BioMedGraphica_Conn_Transcript_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "bmgc_protein_name_id_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Protein/BioMedGraphica_Conn_Protein_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "\n",
    "bmgc_omics_name_id_tmp_df = pd.concat([bmgc_promoter_name_id_df, bmgc_gene_name_id_df, bmgc_transcript_name_id_df, bmgc_protein_name_id_df], axis=0).reset_index(drop=True)\n",
    "bmgc_omics_name_id_df = pd.merge(bmgc_omics_df[['BioMedGraphica_Conn_ID']], bmgc_omics_name_id_tmp_df, on='BioMedGraphica_Conn_ID', how='left')\n",
    "# check the null values in the bmgc_omics_name_id_df\n",
    "print(\"Null values in bmgc_omics_name_id_df:\")\n",
    "print(bmgc_omics_name_id_df.isnull().sum())\n",
    "# fill the NaN values in the Names_and_IDs column with empty string\n",
    "bmgc_omics_name_id_df['Names_and_IDs'] = bmgc_omics_name_id_df['Names_and_IDs'].fillna(' ')\n",
    "# recheck the null values in the bmgc_omics_name_id_df\n",
    "print(\"Null values in bmgc_omics_name_id_df:\")\n",
    "print(bmgc_omics_name_id_df.isnull().sum())\n",
    "display(bmgc_omics_name_id_df)\n",
    "bmgc_omics_name_id_df.to_csv('./Pretrain_data/bmgc_omics_name.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmgc_promoter_desc_df = bmgc_promoter_name_id_df.drop(columns=['Names_and_IDs'], axis=1).copy()\n",
    "bmgc_promoter_desc_df['Description'] = np.nan # add the Description column to bmgc_promoter_name_df with NaN values\n",
    "bmgc_gene_desc_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Gene/BioMedGraphica_Conn_Gene_Description_Combined.csv').drop(columns=['BioMedGraphica_ID'], axis=1)\n",
    "bmgc_transcript_desc_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Transcript/BioMedGraphica_Conn_Transcript_Description_Combined.csv').drop(columns=['BioMedGraphica_ID'], axis=1)\n",
    "bmgc_protein_desc_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Protein/BioMedGraphica_Conn_Protein_Description_Combined.csv').drop(columns=['BioMedGraphica_ID'], axis=1)\n",
    "\n",
    "# concat and drop BioMedGraphica_ID column\n",
    "bmgc_omics_desc_tmp_df = pd.concat([bmgc_promoter_desc_df, bmgc_gene_desc_df, bmgc_transcript_desc_df, bmgc_protein_desc_df], axis=0).reset_index(drop=True)\n",
    "# check the null values in the bmgc_omics_desc_tmp_df\n",
    "print(bmgc_omics_desc_tmp_df.isnull().sum())\n",
    "bmgc_omics_desc_df = pd.merge(bmgc_omics_df[['BioMedGraphica_Conn_ID']], bmgc_omics_desc_tmp_df, on='BioMedGraphica_Conn_ID', how='left')\n",
    "# check the null values in the bmgc_omics_desc_df\n",
    "print(bmgc_omics_desc_df.isnull().sum())\n",
    "# fill NaN values with empty string in Description column\n",
    "bmgc_omics_desc_df['Description'] = bmgc_omics_desc_df['Description'].fillna(' ')\n",
    "# recheck the null values in the bmgc_omics_desc_df\n",
    "print(bmgc_omics_desc_df.isnull().sum())\n",
    "display(bmgc_omics_desc_df)\n",
    "\n",
    "bmgc_omics_desc_df.to_csv('./Pretrain_data/bmgc_omics_desc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Add the pretraining biomarkers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.0 Entity markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation chain converging to the same node\n",
    "# fetch the promoter, gene, transcript and protein entity alone\n",
    "promoter_entity_df = bmgc_omics_df[bmgc_omics_df['Type'] == 'Promoter'].copy()\n",
    "gene_entity_df = bmgc_omics_df[bmgc_omics_df['Type'] == 'Gene'].copy()\n",
    "transcript_entity_df = bmgc_omics_df[bmgc_omics_df['Type'] == 'Transcript'].copy()\n",
    "protein_entity_df = bmgc_omics_df[bmgc_omics_df['Type'] == 'Protein'].copy()\n",
    "\n",
    "display(bmgc_omics_relation_df)\n",
    "# recheck the null values in bmgc_omics_relation_df\n",
    "print(\"Null values in bmgc_omics_relation_df:\")\n",
    "print(bmgc_omics_relation_df.isnull().sum())\n",
    "\n",
    "# fetch the Promoter-Gene, Gene-Transcript, Transcript-Protein relation alone\n",
    "promoter_gene_relation_df = bmgc_omics_relation_df[bmgc_omics_relation_df['Type'] == 'Promoter-Gene'].copy()\n",
    "gene_transcript_relation_df = bmgc_omics_relation_df[bmgc_omics_relation_df['Type'] == 'Gene-Transcript'].copy()\n",
    "transcript_protein_relation_df = bmgc_omics_relation_df[bmgc_omics_relation_df['Type'] == 'Transcript-Protein'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_transcript_entity_df = pd.merge(gene_entity_df, gene_transcript_relation_df[['BMGC_From_ID', 'BMGC_To_ID']], left_on='BioMedGraphica_Conn_ID', right_on='BMGC_From_ID', how='outer')\n",
    "gene_transcript_protein_entity_df = pd.merge(gene_transcript_entity_df, transcript_protein_relation_df[['BMGC_From_ID', 'BMGC_To_ID']], left_on='BMGC_To_ID', right_on='BMGC_From_ID', how='outer')\n",
    "# drop NaN values in BMGC_From_ID_x\tBMGC_To_ID_x BMGC_From_ID_y\tBMGC_To_ID_y\n",
    "gene_transcript_protein_entity_df = gene_transcript_protein_entity_df.dropna(subset=['BMGC_From_ID_x', 'BMGC_To_ID_x', 'BMGC_From_ID_y', 'BMGC_To_ID_y']).reset_index(drop=True)\n",
    "# keep the columns ['BioMedGraphica_Conn_ID', 'BMGC_To_ID_x', 'BMGC_To_ID_y'] and rename the columns to ['BMGC_GN_ID', 'BMGC_TS_ID', 'BMGC_PT_ID']\n",
    "gene_transcript_protein_entity_df = gene_transcript_protein_entity_df[['BioMedGraphica_Conn_ID', 'BMGC_To_ID_y']].rename(columns={'BioMedGraphica_Conn_ID': 'BMGC_GN_ID', 'BMGC_To_ID_y': 'BMGC_PT_ID'}).sort_values(by='BMGC_GN_ID').reset_index(drop=True)\n",
    "# drop duplicates rows in gene_transcript_protein_entity_df\n",
    "gene_transcript_protein_entity_df = gene_transcript_protein_entity_df.drop_duplicates().reset_index(drop=True)\n",
    "display(gene_transcript_protein_entity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just copy gene_transcript_protein_entity_df as promoter_gene_transcript_protein_entity_df\n",
    "bmgc_promoter_df = pd.read_csv('../BMG/BioMedGraphica-Conn/Entity/Promoter/BioMedGraphica_Conn_Promoter.csv')\n",
    "bmgc_gene_df = pd.read_csv('../BMG/BioMedGraphica-Conn/Entity/Gene/BioMedGraphica_Conn_Gene.csv')\n",
    "promoter_gene_transcript_protein_entity_df = gene_transcript_protein_entity_df.copy()\n",
    "promoter_gene_df = pd.concat([bmgc_promoter_df[['BioMedGraphica_Conn_ID']].rename(columns={'BioMedGraphica_Conn_ID': 'BMGC_PM_ID'}), bmgc_gene_df[['BioMedGraphica_Conn_ID']].rename(columns={'BioMedGraphica_Conn_ID': 'BMGC_GN_ID'})], axis=1)\n",
    "promoter_protein_entity_df = pd.merge(promoter_gene_transcript_protein_entity_df, promoter_gene_df, left_on='BMGC_GN_ID', right_on='BMGC_GN_ID', how='left').drop(columns=['BMGC_GN_ID'])\n",
    "promoter_protein_entity_df = promoter_protein_entity_df[['BMGC_PM_ID', 'BMGC_PT_ID']]\n",
    "display(promoter_protein_entity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_protein_entity_df = pd.merge(transcript_entity_df, transcript_protein_relation_df[['BMGC_From_ID', 'BMGC_To_ID']], left_on='BioMedGraphica_Conn_ID', right_on='BMGC_From_ID', how='outer')\n",
    "# drop NaN rows in the BMGC_From_ID and\tBMGC_To_ID\n",
    "transcript_protein_entity_df = transcript_protein_entity_df.dropna(subset=['BMGC_From_ID', 'BMGC_To_ID']).reset_index(drop=True)\n",
    "# keep the columns ['BioMedGraphica_Conn_ID', 'BMGC_To_ID'] and rename the columns to ['BMGC_TS_ID', 'BMGC_PT_ID']\n",
    "transcript_protein_entity_df = transcript_protein_entity_df[['BioMedGraphica_Conn_ID', 'BMGC_To_ID']].rename(columns={'BioMedGraphica_Conn_ID': 'BMGC_TS_ID', 'BMGC_To_ID': 'BMGC_PT_ID'}).sort_values(by='BMGC_TS_ID').reset_index(drop=True)\n",
    "# drop duplicates rows in transcript_protein_entity_df\n",
    "transcript_protein_entity_df = transcript_protein_entity_df.drop_duplicates().reset_index(drop=True)\n",
    "display(transcript_protein_entity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the columns ['BioMedGraphica_Conn_ID'] and rename the columns to ['BMGC_PT_ID']\n",
    "only_protein_entity_df = protein_entity_df[['BioMedGraphica_Conn_ID']].rename(columns={'BioMedGraphica_Conn_ID': 'BMGC_PT_ID'}).sort_values(by='BMGC_PT_ID').reset_index(drop=True)\n",
    "display(only_protein_entity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 CRISPR top 100 gene entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_crispr_df = pd.read_csv('./raw_data/CRISPRGeneEffect.csv')\n",
    "display(raw_crispr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the column names of the raw_crispr_df aside from the first column and convert this to a list\n",
    "raw_crispr_df_columns = raw_crispr_df.columns[1:].tolist()\n",
    "print(raw_crispr_df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, set the \"Unnamed: 0\" column as the index:\n",
    "raw_crispr_t_df = raw_crispr_df.set_index(\"Unnamed: 0\")\n",
    "# Then transpose the DataFrame:\n",
    "raw_crispr_t_df = raw_crispr_t_df.transpose()\n",
    "# move the index to a column and rename it as the gene_name\n",
    "raw_crispr_t_df.reset_index(inplace=True)\n",
    "raw_crispr_t_df.rename(columns={'index': 'gene_name'}, inplace=True)\n",
    "# column gene_name should be kept with the content by removing \"()\" and remove and \" \" content\n",
    "raw_crispr_t_df['gene_name'] = raw_crispr_t_df['gene_name'].apply(lambda x: x.split('(')[0].strip())\n",
    "# Optionally, if you want to view the result:\n",
    "display(raw_crispr_t_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns to convert (all except 'gene_name')\n",
    "cols_to_convert = raw_crispr_t_df.columns.difference(['gene_name'])\n",
    "# Convert these columns to numeric (using pd.to_numeric for safety, which can handle errors)\n",
    "raw_crispr_t_df[cols_to_convert] = raw_crispr_t_df[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "raw_crispr_t_df = raw_crispr_t_df.fillna(0.0)\n",
    "display(raw_crispr_t_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby the gene_name and calculate the mean\n",
    "crispr_df = raw_crispr_t_df.groupby('gene_name', as_index=False).mean()\n",
    "display(crispr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmg_gene_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Gene/BioMedGraphica_Conn_Gene.csv')\n",
    "# keep BioMedGraphica_ID and HGNC_Symbol\n",
    "bmg_gene_df = bmg_gene_df[['BioMedGraphica_Conn_ID', 'HGNC_Symbol']]\n",
    "display(bmg_gene_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the biomedgraphica_id with the crispr_df\n",
    "merged_crispr_df = pd.merge(bmg_gene_df, crispr_df, left_on='HGNC_Symbol', right_on='gene_name', how='inner')\n",
    "merged_crispr_df.drop(columns=['HGNC_Symbol', 'gene_name'], inplace=True)\n",
    "display(merged_crispr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the gene entity with gene_transcript_protein_entity_df\n",
    "protein_crispr_df = pd.merge(gene_transcript_protein_entity_df, merged_crispr_df, left_on='BMGC_GN_ID', right_on='BioMedGraphica_Conn_ID', how='left').drop(columns=['BioMedGraphica_Conn_ID'])\n",
    "# and drop nan in any rows from protein_crispr_df\n",
    "protein_crispr_df = protein_crispr_df.dropna().reset_index(drop=True)\n",
    "display(protein_crispr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapped_omics_union_annotation_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep BioMedGraphica_Conn_ID and columns that are in overlapped_omics_union_annotation_samples\n",
    "# For CRISPR data\n",
    "columns_to_keep = ['BMGC_GN_ID', 'BMGC_PT_ID'] + [col for col in protein_crispr_df.columns if col in overlapped_omics_union_annotation_samples]\n",
    "processed_crispr_df = protein_crispr_df[columns_to_keep]\n",
    "display(processed_crispr_df)\n",
    "processed_crispr_df.to_csv('./Pretrain_data/processed_crispr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the cell line id 'ACH-000001'\n",
    "cell_line_ach_id = 'ACH-000001'\n",
    "cell_line_index = sample_index_data[sample_index_data['Sample'] == cell_line_ach_id]['Index'].values[0]\n",
    "\n",
    "# Get the values of the cell line id 'ACH-000001' in the processed_crispr_df\n",
    "# Sort by ascending values and keep only the first 100 rows (lowest values)\n",
    "top_pt = 200\n",
    "sample_pt_crispr_df = processed_crispr_df[['BMGC_PT_ID', cell_line_ach_id]].sort_values(by=cell_line_ach_id, ascending=True).head(top_pt).reset_index(drop=True)\n",
    "\n",
    "# display the sample_pt_crispr_df\n",
    "display(sample_pt_crispr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_list = sample_pt_crispr_df['BMGC_PT_ID'].tolist()\n",
    "t_list = ['BMGC_PT013573', 'BMGC_PT013845', 'BMGC_PT059302', 'BMGC_PT086949', 'BMGC_PT087523', 'BMGC_PT019258', 'BMGC_PT015912', 'BMGC_PT032626', 'BMGC_PT078942', 'BMGC_PT022195', 'BMGC_PT043295', 'BMGC_PT092576', 'BMGC_PT040217', 'BMGC_PT016891', 'BMGC_PT017110', 'BMGC_PT042786', 'BMGC_PT017001', 'BMGC_PT015387', 'BMGC_PT018843', 'BMGC_PT015056', 'BMGC_PT014699', 'BMGC_PT015788', 'BMGC_PT049851', 'BMGC_PT019516', 'BMGC_PT017890', 'BMGC_PT014340', 'BMGC_PT035183', 'BMGC_PT034914', 'BMGC_PT018061', 'BMGC_PT103918', 'BMGC_PT014286', 'BMGC_PT032427', 'BMGC_PT013870', 'BMGC_PT013144', 'BMGC_PT018905', 'BMGC_PT036177', 'BMGC_PT034571', 'BMGC_PT011892', 'BMGC_PT010478', 'BMGC_PT046227', 'BMGC_PT031193', 'BMGC_PT017267', 'BMGC_PT017158', 'BMGC_PT095399', 'BMGC_PT015369', 'BMGC_PT049534', 'BMGC_PT048497', 'BMGC_PT073677', 'BMGC_PT036916', 'BMGC_PT027174']\n",
    "# check the overlapped pt between pt_list and t_list\n",
    "overlapped_pt = set(pt_list).intersection(set(t_list))\n",
    "print(\"Overlapped pt between pt_list and t_list:\", overlapped_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt_top100_df = pd.read_csv('../ACH000001_top100_proteins.txt', sep='\\t', header=None)\n",
    "# # give the name to the none header columns\n",
    "# gpt_top100_df.columns = ['Gene_Symbol']\n",
    "# # remove suffix before '. ' in the column content\n",
    "# gpt_top100_df['Gene_Symbol'] = gpt_top100_df['Gene_Symbol'].apply(lambda x: x.split('. ')[1])\n",
    "# # display(gpt_top100_df)\n",
    "# # Join the gene_symbol with bmgc_protein_entity\n",
    "# bmgc_protein_tmp_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Protein/BioMedGraphica_Conn_Protein.csv')\n",
    "# bmgc_protein_tmp_df = bmgc_protein_tmp_df[['BioMedGraphica_Conn_ID', 'HGNC_Symbol']].copy()\n",
    "# # Get the inner join with the bmgc_protein_tmp_df and gpt_top100_df\n",
    "# gpt_top100_df = pd.merge(bmgc_protein_tmp_df, gpt_top100_df, left_on='HGNC_Symbol', right_on='Gene_Symbol', how='inner')\n",
    "# # display(gpt_top100_df)\n",
    "# gpt_pt_list = gpt_top100_df['BioMedGraphica_Conn_ID'].tolist()\n",
    "\n",
    "# # check the overlapped pt between pt_list and gpt_pt_list\n",
    "# overlapped_gpt_pt = set(pt_list).intersection(set(gpt_pt_list))\n",
    "# print(\"Overlapped pt between pt_list and gpt_pt_list:\", overlapped_gpt_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 RNAi top 100 transcript entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_rna_combined_df = pd.read_csv('./raw_data/D2_combined_gene_dep_scores.csv')\n",
    "# fill NaN values with 0.0\n",
    "raw_rna_combined_df = raw_rna_combined_df.fillna(0.0)\n",
    "display(raw_rna_combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the Unnamed: 0 to a column and rename it as the gene_name\n",
    "raw_rna_combined_df.rename(columns={'Unnamed: 0': 'gene_name'}, inplace=True)\n",
    "# Clean the gene_name column by removing parentheses and extra spaces\n",
    "raw_rna_combined_df['gene_name'] = raw_rna_combined_df['gene_name'].apply(lambda x: x.split('(')[0].strip())\n",
    "# Display the result\n",
    "display(raw_rna_combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the overlapped cell lines in methy_samples with cell_line_anno_df by merge on cell line id\n",
    "rna_combined_samples = raw_rna_combined_df.columns[1:].tolist()\n",
    "# first format the methy_samples as dataframe\n",
    "rna_combined_samples_df = pd.DataFrame(rna_combined_samples, columns=['CCLE_Name'])\n",
    "# merge the methy_samples_df with the cell_line_anno_df\n",
    "rna_combined_samples_anno_df = pd.merge(rna_combined_samples_df, cell_line_anno_df, left_on='CCLE_Name', right_on='CCLE_ID', how='inner')\n",
    "display(rna_combined_samples_anno_df)\n",
    "\n",
    "# get the map dictionary from the ccle id to depmap id\n",
    "rna_combined_samples_map_dict = dict(zip(rna_combined_samples_anno_df['CCLE_Name'], rna_combined_samples_anno_df['depMapID']))\n",
    "print(rna_combined_samples_map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maped_rna_combined_df = raw_rna_combined_df.rename(columns=rna_combined_samples_map_dict)\n",
    "columns_to_keep = ['gene_name'] + sorted([col for col in maped_rna_combined_df.columns if col in overlapped_omics_union_annotation_samples])\n",
    "filtered_rna_df = maped_rna_combined_df[columns_to_keep]\n",
    "display(filtered_rna_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmg_transcript_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Transcript/BioMedGraphica_Conn_Transcript.csv')\n",
    "# keep BioMedGraphica_ID and HGNC_Symbol\n",
    "bmg_transcript_df = bmg_transcript_df[['BioMedGraphica_Conn_ID', 'HGNC_Symbol']]\n",
    "display(bmg_transcript_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the biomedgraphica_id with the raw_transcript_df\n",
    "merge_rna_df = pd.merge(bmg_transcript_df, filtered_rna_df, left_on='HGNC_Symbol', right_on='gene_name', how='inner')\n",
    "merge_rna_df.drop(columns=['HGNC_Symbol', 'gene_name'], inplace=True)\n",
    "display(merge_rna_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the transcript entity with transcript_protein_entity_df\n",
    "protein_rna_df = pd.merge(transcript_protein_entity_df, merge_rna_df, left_on='BMGC_TS_ID', right_on='BioMedGraphica_Conn_ID', how='left').drop(columns=['BioMedGraphica_Conn_ID'])\n",
    "# and drop nan in any rows from protein_rna_df\n",
    "processed_rna_df = protein_rna_df.dropna().reset_index(drop=True)\n",
    "display(processed_rna_df)\n",
    "processed_rna_df.to_csv('./Pretrain_data/processed_rna.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_crispr_samples = processed_crispr_df.columns[2:].tolist()\n",
    "processed_rna_samples = processed_rna_df.columns[2:].tolist()\n",
    "\n",
    "# get the union and intersection samples of the two lists\n",
    "overlapped_crispr_rna_samples = sorted(list(set(processed_crispr_samples) & set(processed_rna_samples)))\n",
    "print(\"The overlapped samples between protein_crispr_samples and protein_rna_samples are:\")\n",
    "print(len(overlapped_crispr_rna_samples))\n",
    "print(overlapped_crispr_rna_samples)\n",
    "\n",
    "# get the union set of samples of the two lists\n",
    "union_crispr_rna_samples = sorted(list(set(processed_crispr_samples) | set(processed_rna_samples)))\n",
    "print(\"The union samples between protein_crispr_samples and protein_rna_samples are:\")\n",
    "print(len(union_crispr_rna_samples))\n",
    "print(union_crispr_rna_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the intersection based on the overlapped over omics not union over omics by overlapped_omics_annotation_samples\n",
    "overlapped_omics_crispr_rna_samples = sorted(list(set(overlapped_crispr_rna_samples) & set(overlapped_omics_annotation_samples)))\n",
    "print(\"The overlapped samples between protein_crispr_samples and protein_rna_samples are:\")\n",
    "print(len(overlapped_omics_crispr_rna_samples))\n",
    "print(overlapped_omics_crispr_rna_samples)\n",
    "\n",
    "# get the intersection based on the overlapped over omics not union over omics by overlapped_omics_annotation_samples for union_crispr_rna_samples\n",
    "overlapped_omics_union_crispr_rna_samples = sorted(list(set(union_crispr_rna_samples) & set(overlapped_omics_annotation_samples)))\n",
    "print(\"The overlapped samples between protein_crispr_samples and protein_rna_samples are:\")\n",
    "print(len(overlapped_omics_union_crispr_rna_samples))\n",
    "print(overlapped_omics_union_crispr_rna_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the cell line id 'ACH-000001'\n",
    "cell_line_ach_id = 'ACH-000001'\n",
    "cell_line_index = sample_index_data[sample_index_data['Sample'] == cell_line_ach_id]['Index'].values[0]\n",
    "\n",
    "# Get the values of the cell line id 'ACH-000001' in the processed_crispr_df\n",
    "# Sort by ascending values and keep only the first 100 rows (lowest values)\n",
    "top_pt = 10000\n",
    "sample_pt_rna_df = processed_rna_df[['BMGC_PT_ID', cell_line_ach_id]].sort_values(by=cell_line_ach_id, ascending=True).head(top_pt).reset_index(drop=True)\n",
    "# display the sample_pt_rna_df\n",
    "display(sample_pt_rna_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the overlapped pt between pt_list and t_list\n",
    "overlapped_rna_pt = set(sample_pt_rna_df['BMGC_PT_ID'].tolist()).intersection(set(t_list))\n",
    "print(\"Overlapped pt between pt_list and t_list:\", overlapped_rna_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Statisitical comparisons of p value for top 100 promoters, genes, transcripts and proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final gene, transcript, drug dataframe by filtering the overlapped_non_cancerous_samples\n",
    "noncancer_gene_df = final_merged_gene_df[['BioMedGraphica_Conn_ID'] + overlapped_non_cancerous_samples]\n",
    "dti_tr_gene_df = final_merged_gene_df[['BioMedGraphica_Conn_ID'] + sorted(training_cell_line_ids)]\n",
    "display(noncancer_gene_df)\n",
    "display(dti_tr_gene_df)\n",
    "noncancer_transcript_df = final_merged_transcript_df[['BioMedGraphica_Conn_ID'] + overlapped_non_cancerous_samples]\n",
    "dti_tr_transcript_df = final_merged_transcript_df[['BioMedGraphica_Conn_ID'] + sorted(training_cell_line_ids)]\n",
    "display(noncancer_transcript_df)\n",
    "display(dti_tr_transcript_df)\n",
    "noncancer_protein_df = mapped_protein_df[['BioMedGraphica_Conn_ID'] + overlapped_non_cancerous_samples]\n",
    "dti_tr_protein_df = mapped_protein_df[['BioMedGraphica_Conn_ID'] + sorted(training_cell_line_ids)]\n",
    "display(noncancer_protein_df)\n",
    "display(dti_tr_protein_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gene p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_pvalues(disease_df, control_df):\n",
    "    \"\"\"\n",
    "    Calculate p-values for each gene in each sample of disease group\n",
    "    compared to the distribution of the same gene in control group using\n",
    "    Wilcoxon signed-rank test.\n",
    "    \n",
    "    Parameters:\n",
    "    disease_df: DataFrame containing disease samples\n",
    "    control_df: DataFrame containing control samples\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with same dimensions as disease_df but with p-values\n",
    "    \"\"\"\n",
    "    # Create an empty DataFrame to store p-values with the same structure as disease_df\n",
    "    pvalue_df = pd.DataFrame(index=disease_df.index, columns=disease_df.columns)\n",
    "    \n",
    "    # Copy the BioMedGraphica_Conn_ID column from disease_df\n",
    "    pvalue_df['BioMedGraphica_Conn_ID'] = disease_df['BioMedGraphica_Conn_ID']\n",
    "    \n",
    "    # Get sample columns (exclude the ID column)\n",
    "    disease_samples = disease_df.columns[1:]\n",
    "    control_samples = control_df.columns[1:]\n",
    "    \n",
    "    # Print summary of what we're calculating\n",
    "    print(f\"Calculating p-values for {len(disease_df)} genes across {len(disease_samples)} disease samples\")\n",
    "    print(f\"Control group: {len(control_samples)} samples\")\n",
    "    \n",
    "    # For each gene (row) - with progress bar\n",
    "    for i, gene_id in enumerate(tqdm(disease_df['BioMedGraphica_Conn_ID'], desc=\"Processing genes\")):\n",
    "        # Find the corresponding gene in control group\n",
    "        control_gene_row = control_df[control_df['BioMedGraphica_Conn_ID'] == gene_id]\n",
    "        \n",
    "        if len(control_gene_row) == 0:\n",
    "            # If gene not found in control, fill with NaN\n",
    "            pvalue_df.loc[i, disease_samples] = np.nan\n",
    "            continue\n",
    "        \n",
    "        # Get control values for this gene across all control samples\n",
    "        control_values = control_gene_row.iloc[0, 1:].values.astype(float)  # Convert to float\n",
    "        control_values = control_values[control_values != 0]  # Remove zeros if any\n",
    "        \n",
    "        if len(control_values) == 0:\n",
    "            # If no valid control values, fill with NaN\n",
    "            pvalue_df.loc[i, disease_samples] = np.nan\n",
    "            continue\n",
    "        \n",
    "        # Process samples in mini-batches for better progress visibility\n",
    "        batch_size = max(1, len(disease_samples) // 10)  # Process ~10 batches for better feedback\n",
    "        \n",
    "        # For each disease sample, calculate p-value\n",
    "        for j in range(0, len(disease_samples), batch_size):\n",
    "            batch_samples = disease_samples[j:j+batch_size]\n",
    "            \n",
    "            # Display current batch progress\n",
    "            print(f\"Processing batch {j//batch_size + 1}/{-(-len(disease_samples)//batch_size)} for gene {i+1}/{len(disease_df)}\")\n",
    "            \n",
    "            for sample in batch_samples:\n",
    "                # Optionally display each sample being processed\n",
    "                print(f\"  Processing sample: {sample}\")\n",
    "                \n",
    "                disease_value = disease_df.loc[i, sample]\n",
    "                \n",
    "                # Handle special case when disease value is 0\n",
    "                if disease_value == 0:\n",
    "                    pvalue_df.loc[i, sample] = np.nan\n",
    "                    continue\n",
    "                    \n",
    "                # Convert to float explicitly\n",
    "                disease_value = float(disease_value)\n",
    "                \n",
    "                # Calculate p-value using Wilcoxon signed-rank test\n",
    "                try:\n",
    "                    # For Wilcoxon test, we need to compare the distribution to the specific value\n",
    "                    # Create an array of differences between each control value and the disease value\n",
    "                    differences = control_values - disease_value\n",
    "                    \n",
    "                    # Use Wilcoxon signed-rank test (tests if differences are centered around 0)\n",
    "                    stat, p_value = stats.wilcoxon(differences)\n",
    "                    pvalue_df.loc[i, sample] = p_value\n",
    "                except (TypeError, ValueError) as e:\n",
    "                    # Wilcoxon test requires at least 1 non-zero difference\n",
    "                    # If all differences are zero or there are too few samples, we'll get an error\n",
    "                    # print(f\"Error in Wilcoxon test for gene {gene_id}, sample {sample}: {e}\")\n",
    "                    pvalue_df.loc[i, sample] = np.nan\n",
    "                \n",
    "        # Show a progress update for every 5% of genes\n",
    "        if i % max(1, len(disease_df) // 20) == 0 and i > 0:\n",
    "            completed = 100 * i / len(disease_df)\n",
    "            print(f\"Completed {completed:.1f}% ({i}/{len(disease_df)} genes)\")\n",
    "    \n",
    "    return pvalue_df\n",
    "\n",
    "# # Apply the function to calculate p-values\n",
    "# print(\"Starting p-value calculation...\")\n",
    "# dti_tr_gene1_df = dti_tr_gene_df[['BioMedGraphica_Conn_ID', 'ACH-000001']].copy()\n",
    "# pvalue_df = calculate_pvalues(dti_tr_gene1_df, noncancer_gene_df)\n",
    "\n",
    "# # Display the first few rows of the result\n",
    "# print(\"\\nP-value calculation complete. Here's a preview of the results:\")\n",
    "# print(pvalue_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter out the NaN values and get the lowest p-values\n",
    "# pvalue_c_df = pvalue_df.dropna(subset=['ACH-000001'])\n",
    "# pvalue_c_df = pvalue_c_df.sort_values(by='ACH-000001').reset_index(drop=True)\n",
    "\n",
    "# # Reset the display format to scientific notation\n",
    "# pd.reset_option('display.float_format')\n",
    "# # Set scientific notation with reasonable precision\n",
    "# pd.set_option('display.float_format', lambda x: '{:.2e}'.format(x) if abs(x) < 0.01 else '{:.4f}'.format(x))\n",
    "# display(pvalue_c_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Annotate pvalue_df with gene HGNC_Symbol by bmgc_gene_df\n",
    "# bmgc_gene_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Gene/BioMedGraphica_Conn_Gene.csv')\n",
    "# # keep BioMedGraphica_ID and HGNC_Symbol\n",
    "# bmgc_gene_df = bmgc_gene_df[['BioMedGraphica_Conn_ID', 'HGNC_Symbol']]\n",
    "# # merge the biomedgraphica_id with the pvalue_c_df\n",
    "# pvalue_hgnc_df = pd.merge(pvalue_c_df, bmgc_gene_df, on='BioMedGraphica_Conn_ID', how='left')\n",
    "# # drop the BioMedGraphica_Conn_ID column and drop NaN values in HGNC_Symbol column\n",
    "# pvalue_hgnc_df = pvalue_hgnc_df.drop(columns=['BioMedGraphica_Conn_ID']).reset_index(drop=True)\n",
    "# # display the pvalue_df\n",
    "# display(pvalue_hgnc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pvalue_answer(pvalue_hgnc_df, bmgc_gene_df, gene_transcript_protein_entity_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, top_bm=100):\n",
    "    # Convert the column to numeric type, forcing errors to become NaN\n",
    "    pvalue_hgnc_df[sample_ach_name] = pd.to_numeric(pvalue_hgnc_df[sample_ach_name], errors='coerce')\n",
    "    # Extract the lowest top_bm values for the given sample name\n",
    "    top_bm_genes = pvalue_hgnc_df.nsmallest(top_bm, sample_ach_name)[['HGNC_Symbol', sample_ach_name]]\n",
    "    # Sort the top bm genes by their values in ascending order\n",
    "    top_bm_genes = top_bm_genes.sort_values(by=sample_ach_name, ascending=True).reset_index(drop=True)\n",
    "    top_pvalue_bm_gene_hgnc_name_list = top_bm_genes['HGNC_Symbol'].tolist()\n",
    "    # Merge with the bmgc_gene_df to get the BioMedGraphica_Conn_ID\n",
    "    bmgc_gene_df = bmgc_gene_df[['BioMedGraphica_Conn_ID', 'HGNC_Symbol']].copy()\n",
    "    top_bm_bmgc_gene_df = pd.merge(bmgc_gene_df, top_bm_genes, left_on='HGNC_Symbol', right_on='HGNC_Symbol', how='inner')\n",
    "    # Get the corresponding proteins\n",
    "    top_bm_bmgc_gene_protein_df = pd.merge(gene_transcript_protein_entity_df, top_bm_bmgc_gene_df, \n",
    "                                          left_on='BMGC_GN_ID', right_on='BioMedGraphica_Conn_ID', \n",
    "                                          how='inner')\n",
    "    # Remove the BioMedGraphica_Conn_ID column\n",
    "    if 'BioMedGraphica_Conn_ID' in top_bm_bmgc_gene_protein_df:\n",
    "        top_bm_bmgc_gene_protein_df = top_bm_bmgc_gene_protein_df.drop(columns=['BioMedGraphica_Conn_ID'])\n",
    "    # Get additional protein information\n",
    "    top_bm_bmgc_gene_protein_info_df = pd.merge(top_bm_bmgc_gene_protein_df, bmgc_protein_llmnameid_combined_df, \n",
    "                                               left_on='BMGC_PT_ID', right_on='BioMedGraphica_Conn_ID', \n",
    "                                               how='inner')\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = ['BioMedGraphica_Conn_ID', 'BioMedGraphica_ID']\n",
    "    if sample_ach_name in top_bm_bmgc_gene_protein_info_df.columns:\n",
    "        columns_to_drop.append(sample_ach_name)\n",
    "    \n",
    "    top_bm_bmgc_gene_protein_info_df = top_bm_bmgc_gene_protein_info_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    # Extract the lists of protein IDs and names\n",
    "    top_bm_gene_protein_bmgc_id_list = top_bm_bmgc_gene_protein_info_df['BMGC_PT_ID'].tolist()\n",
    "    top_bm_gene_protein_bmgc_llmnameid_list = top_bm_bmgc_gene_protein_info_df['Names_and_IDs'].replace(r' \\| ', ' or ', regex=True).tolist()\n",
    "    \n",
    "    return top_pvalue_bm_gene_hgnc_name_list, top_bm_gene_protein_bmgc_id_list, top_bm_gene_protein_bmgc_llmnameid_list\n",
    "\n",
    "# # Example usage\n",
    "# sample_ach_name = 'ACH-000001'\n",
    "# top_bm = 100\n",
    "# bmgc_protein_llmnameid_combined_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Protein/BioMedGraphica_Conn_Protein_LLM_Name_ID_Combined.csv').drop(columns=['BioMedGraphica_ID'])\n",
    "# top_pvalue_bm_gene_hgnc_name_list, top_bm_gene_protein_bmgc_id_list, top_bm_gene_protein_bmgc_llmnameid_list = extract_pvalue_answer(pvalue_hgnc_df, bmgc_gene_df, gene_transcript_protein_entity_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, top_bm)\n",
    "# print(f\"Top {top_bm} Gene HGNC Names:\", top_pvalue_bm_gene_hgnc_name_list)\n",
    "# print(f\"Top {top_bm} Gene Protein BMGC IDs:\", top_bm_gene_protein_bmgc_id_list)\n",
    "# print(f\"Top {top_bm} Gene Protein BMGC LLM Name IDs:\", top_bm_gene_protein_bmgc_llmnameid_list)\n",
    "# # Save the [top_pvalue_bm_gene_hgnc_name_list] to a csv file\n",
    "# top_pvalue_bm_gene_hgnc_name_df = pd.DataFrame(top_pvalue_bm_gene_hgnc_name_list, columns=['HGNC_Symbol'])\n",
    "# # Make dir for P value data\n",
    "# import os\n",
    "# if not os.path.exists('../pvalues/'):\n",
    "#     os.makedirs('../pvalues/')\n",
    "# top_pvalue_bm_gene_hgnc_name_df.to_csv('../pvalues/top_pvalue_bm_gene_hgnc_name.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. LLM QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.0 Formulate the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cell_line_ids = list(set(final_training_drug_screen_df['depMapID']))\n",
    "dti_training_samples = sorted(training_cell_line_ids)\n",
    "print(\"The training samples are:\", len(dti_training_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_crispr_samples = sorted(list(set(processed_crispr_df.columns[2:])))\n",
    "print(\"The current crispr samples are:\", len(current_crispr_samples))\n",
    "current_rna_samples = sorted(list(set(processed_rna_df.columns[2:])))\n",
    "print(\"The current rna samples are:\", len(current_rna_samples))\n",
    "\n",
    "overlapped_crispr_rna_samples = sorted(list(set(current_crispr_samples) & set(current_rna_samples)))\n",
    "print(\"The overlapped samples between current_crispr_samples and current_rna_samples are:\", len(overlapped_crispr_rna_samples))\n",
    "\n",
    "# overlapped samples between dti_training_samples and overlapped_crispr_rna_samples\n",
    "overlapped_dti_crispr_rna_samples = sorted(list(set(dti_training_samples) & set(overlapped_crispr_rna_samples)))\n",
    "print(\"The overlapped samples between dti_training_samples and overlapped_crispr_rna_samples are:\", len(overlapped_dti_crispr_rna_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapped_dti_crispr_rna_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Fix all random seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)  # Also set NumPy seed if you're using it elsewhere\n",
    "\n",
    "# Make a copy of the list before shuffling to avoid modifying the original\n",
    "samples_to_shuffle = overlapped_dti_crispr_rna_samples.copy()\n",
    "random.shuffle(samples_to_shuffle)\n",
    "\n",
    "# Split into train and test sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(samples_to_shuffle) * split_ratio)\n",
    "train_dti_crispr_rna_samples = sorted(samples_to_shuffle[:split_index])\n",
    "test_dti_crispr_rna_samples = sorted(samples_to_shuffle[split_index:])\n",
    "\n",
    "print(\"The training samples are:\", len(train_dti_crispr_rna_samples))\n",
    "print(train_dti_crispr_rna_samples[:10])\n",
    "print(\"The testing samples are:\", len(test_dti_crispr_rna_samples))\n",
    "print(test_dti_crispr_rna_samples[:10])\n",
    "\n",
    "# Save the train and test samples to a csv file\n",
    "train_dti_crispr_rna_samples_df = pd.DataFrame(train_dti_crispr_rna_samples, columns=['Sample'])\n",
    "train_dti_crispr_rna_samples_df.to_csv('../QA_Data/train_dti_crispr_rna_samples.csv', index=False, header=True)\n",
    "test_dti_crispr_rna_samples_df = pd.DataFrame(test_dti_crispr_rna_samples, columns=['Sample'])\n",
    "test_dti_crispr_rna_samples_df.to_csv('../QA_Data/test_dti_crispr_rna_samples.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 CRISPR-QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.1 Cell Line and Disease Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell line information\n",
    "dti_sample_index = pd.read_csv('../BMG/DTI_data/sample_index.csv')\n",
    "dti_sample_info = pd.read_csv('../BMG/process_data/dti_combined_samples.csv')\n",
    "dti_sample_info_index = pd.merge(dti_sample_info, dti_sample_index, how='inner', left_on='depMapID', right_on='Sample').drop(columns=['Sample'])\n",
    "# Filter out the samples that are in the overlapped_dti_crispr_rna_samples\n",
    "dti_sample_info_index = dti_sample_info_index[dti_sample_info_index['depMapID'].isin(overlapped_dti_crispr_rna_samples)].reset_index(drop=True)\n",
    "# Replace \" | \" with \" or \" in the BMGC_Disease_name column\n",
    "dti_sample_info_index['BMGC_Disease_name'] = dti_sample_info_index['BMGC_Disease_name'].replace(r' \\| ', ' or ', regex=True)\n",
    "# Only keep the columns ['depMapID', 'Name', 'BMGC_Disease_ID', 'BMGC_Disease_name', 'Index']\n",
    "dti_sample_info_index = dti_sample_info_index[['depMapID', 'Name', 'BMGC_Disease_ID', 'BMGC_Disease_name', 'Index']].reset_index(drop=True)\n",
    "display(dti_sample_info_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.2 Omics Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Methylation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_methy_df = methy_df.rename(columns=methy_map_dict)\n",
    "promoter_overlapped_dti_crispr_rna_samples = sorted(list(set(mapped_methy_df.columns[1:]) & set(overlapped_dti_crispr_rna_samples)))\n",
    "dti_crispr_rna_methy_df = mapped_methy_df[['locus_id'] + promoter_overlapped_dti_crispr_rna_samples].copy()\n",
    "display(dti_crispr_rna_methy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmgc_promoter_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Promoter/BioMedGraphica_Conn_Promoter.csv')\n",
    "bmgc_protein_llmnameid_combined_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Protein/BioMedGraphica_Conn_Protein_LLM_Name_ID_Combined.csv')\n",
    "display(bmgc_protein_llmnameid_combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoter_gene_df = pd.concat([bmgc_promoter_df[['BioMedGraphica_Conn_ID']].rename(columns={'BioMedGraphica_Conn_ID': 'BMGC_PM_ID'}), bmgc_gene_df[['BioMedGraphica_Conn_ID']].rename(columns={'BioMedGraphica_Conn_ID': 'BMGC_GN_ID'})], axis=1)\n",
    "promoter_protein_entity_df = pd.merge(promoter_gene_transcript_protein_entity_df, promoter_gene_df, left_on='BMGC_GN_ID', right_on='BMGC_GN_ID', how='left').drop(columns=['BMGC_GN_ID'])\n",
    "promoter_protein_entity_df = promoter_protein_entity_df[['BMGC_PM_ID', 'BMGC_PT_ID']]\n",
    "display(promoter_protein_entity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pm_info(dti_crispr_rna_methy_df, bmgc_promoter_df, promoter_protein_entity_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, k=10):\n",
    "    # Extract the top k highest values for the given sample name\n",
    "    top_k_promoters = dti_crispr_rna_methy_df.nlargest(k, sample_ach_name)[['locus_id', sample_ach_name]]\n",
    "    # Sort the top k promoters by their values in descending order\n",
    "    top_k_promoters = top_k_promoters.sort_values(by=sample_ach_name, ascending=False).reset_index(drop=True)\n",
    "    top_k_promoter_name_list = top_k_promoters['locus_id'].tolist()\n",
    "    display(top_k_promoters)\n",
    "    # Merge with the bmgc_promoter_df to get the BioMedGraphica_Conn_ID\n",
    "    bmgc_promoter_df = bmgc_promoter_df[['BioMedGraphica_Conn_ID', 'HGNC_Symbol']].copy()\n",
    "    top_k_bmgc_promoter_df = pd.merge(bmgc_promoter_df, top_k_promoters, left_on='HGNC_Symbol', right_on='locus_id', how='inner')\n",
    "    # Get the corresponding proteins\n",
    "    top_k_bmgc_promoter_protein_df = pd.merge(promoter_protein_entity_df, top_k_bmgc_promoter_df, left_on='BMGC_PM_ID', right_on='BioMedGraphica_Conn_ID', how='inner').drop(columns=['BioMedGraphica_Conn_ID', 'locus_id'])\n",
    "    top_k_bmgc_promoter_protein_info_df = pd.merge(top_k_bmgc_promoter_protein_df, bmgc_protein_llmnameid_combined_df, left_on='BMGC_PT_ID', right_on='BioMedGraphica_Conn_ID', how='inner').drop(columns=['BioMedGraphica_Conn_ID', 'BioMedGraphica_ID', sample_ach_name])\n",
    "    top_k_promoter_protein_bmgc_id_list = top_k_bmgc_promoter_protein_info_df['BMGC_PT_ID'].tolist()\n",
    "    display(top_k_bmgc_promoter_protein_info_df)\n",
    "    top_k_promoter_protein_bmgc_llmnameid_list = top_k_bmgc_promoter_protein_info_df['Names_and_IDs'].replace(r' \\| ', ' or ', regex=True).tolist()\n",
    "    return top_k_promoter_name_list, top_k_promoter_protein_bmgc_id_list, top_k_promoter_protein_bmgc_llmnameid_list\n",
    "\n",
    "# Example usage\n",
    "sample_ach_name = 'ACH-000001'\n",
    "k=100\n",
    "top_k_promoter_name_list, top_k_promoter_protein_bmgc_id_list, top_k_promoter_protein_bmgc_llmnameid_list = extract_pm_info(dti_crispr_rna_methy_df, bmgc_promoter_df, promoter_protein_entity_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, k)\n",
    "print(f\"Top {k} Promoter Names:\", top_k_promoter_name_list)\n",
    "print(f\"Top {k} Promoter Protein BMGC IDs:\", top_k_promoter_protein_bmgc_id_list)\n",
    "print(f\"Top {k} Promoter Protein BMGC LLM Name IDs:\", top_k_promoter_protein_bmgc_llmnameid_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gene Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns in the overlapped_dti_crispr_rna_samples for gene_df\n",
    "dti_crispr_rna_gene_df = gene_df[['gene_name'] + sorted(overlapped_dti_crispr_rna_samples)].copy()\n",
    "display(dti_crispr_rna_gene_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmgc_gene_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Gene/BioMedGraphica_Conn_Gene.csv')\n",
    "bmgc_protein_llmnameid_combined_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Protein/BioMedGraphica_Conn_Protein_LLM_Name_ID_Combined.csv')\n",
    "display(bmgc_protein_llmnameid_combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gn_info(dti_crispr_rna_gene_df, bmgc_gene_df, gene_transcript_protein_entity_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, k=10):\n",
    "    # Check if sample_ach_name exists in dti_crispr_rna_gene_df columns\n",
    "    if sample_ach_name not in dti_crispr_rna_gene_df.columns:\n",
    "        return \"non-existed\", \"non-existed\", \"non-existed\"\n",
    "    # Extract the top k highest values for the given sample name\n",
    "    top_k_genes = dti_crispr_rna_gene_df.nlargest(k, sample_ach_name)[['gene_name', sample_ach_name]]\n",
    "    # Sort the top k genes by their values in descending order\n",
    "    top_k_genes = top_k_genes.sort_values(by=sample_ach_name, ascending=False).reset_index(drop=True)\n",
    "    top_k_gene_hgnc_name_list = top_k_genes['gene_name'].tolist()\n",
    "    # Merge with the bmgc_gene_df to get the BioMedGraphica_Conn_ID\n",
    "    bmgc_gene_df = bmgc_gene_df[['BioMedGraphica_Conn_ID', 'HGNC_Symbol']].copy()\n",
    "    top_k_bmgc_gene_df = pd.merge(bmgc_gene_df, top_k_genes, left_on='HGNC_Symbol', right_on='gene_name', how='inner')\n",
    "    # Get the corresponding proteins\n",
    "    top_k_bmgc_gene_protein_df = pd.merge(gene_transcript_protein_entity_df, top_k_bmgc_gene_df, left_on='BMGC_GN_ID', right_on='BioMedGraphica_Conn_ID', how='inner').drop(columns=['BioMedGraphica_Conn_ID', 'gene_name'])\n",
    "    top_k_bmgc_gene_protein_info_df = pd.merge(top_k_bmgc_gene_protein_df, bmgc_protein_llmnameid_combined_df, left_on='BMGC_PT_ID', right_on='BioMedGraphica_Conn_ID', how='inner').drop(columns=['BioMedGraphica_Conn_ID', 'BioMedGraphica_ID', sample_ach_name])\n",
    "    top_k_gene_protein_bmgc_id_list = top_k_bmgc_gene_protein_info_df['BMGC_PT_ID'].tolist()\n",
    "    top_k_gene_protein_bmgc_llmnameid_list = top_k_bmgc_gene_protein_info_df['Names_and_IDs'].replace(r' \\| ', ' or ', regex=True).tolist()\n",
    "    return top_k_gene_hgnc_name_list, top_k_gene_protein_bmgc_id_list, top_k_gene_protein_bmgc_llmnameid_list\n",
    "\n",
    "# Example usage\n",
    "sample_ach_name = 'ACH-000001'\n",
    "k=10\n",
    "top_k_gene_hgnc_name_list, top_k_gene_protein_bmgc_id_list, top_k_gene_protein_bmgc_llmnameid_list = extract_gn_info(dti_crispr_rna_gene_df, bmgc_gene_df, gene_transcript_protein_entity_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, k)\n",
    "print(f\"Top {k} Gene HGNC Names:\", top_k_gene_hgnc_name_list)\n",
    "print(f\"Top {k} Gene Protein BMGC IDs:\", top_k_gene_protein_bmgc_id_list)\n",
    "print(f\"Top {k} Gene Protein BMGC LLM Name IDs:\", top_k_gene_protein_bmgc_llmnameid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transcript Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns in the overlapped_dti_crispr_rna_samples for raw_transcript_df\n",
    "transcript_overlapped_dti_crispr_rna_samples = sorted(list(set(raw_transcript_df.columns[1:]) & set(overlapped_dti_crispr_rna_samples)))\n",
    "dti_crispr_rna_transcript_df = raw_transcript_df[['gene_name'] + transcript_overlapped_dti_crispr_rna_samples].copy()\n",
    "display(dti_crispr_rna_transcript_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmgc_transcript_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Transcript/BioMedGraphica_Conn_Transcript.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ts_info(dti_crispr_rna_transcript_df, bmgc_transcript_df, transcript_protein_entity_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, k=10):\n",
    "    # Check if sample_ach_name exists in dti_crispr_rna_transcript_df columns\n",
    "    if sample_ach_name not in dti_crispr_rna_transcript_df.columns:\n",
    "        return \"non-existed\", \"non-existed\", \"non-existed\"\n",
    "    # Extract the top k highest values for the given sample name\n",
    "    top_k_transcripts = dti_crispr_rna_transcript_df.nlargest(k, sample_ach_name)[['gene_name', sample_ach_name]]\n",
    "    # Sort the top k transcripts by their values in descending order\n",
    "    top_k_transcripts = top_k_transcripts.sort_values(by=sample_ach_name, ascending=False).reset_index(drop=True)\n",
    "    top_k_transcript_hgnc_name_list = top_k_transcripts['gene_name'].tolist()\n",
    "    # Merge with the bmgc_transcript_df to get the BioMedGraphica_Conn_ID\n",
    "    bmgc_transcript_df = bmgc_transcript_df[['BioMedGraphica_Conn_ID', 'HGNC_Symbol']].copy()\n",
    "    top_k_bmgc_transcript_df = pd.merge(bmgc_transcript_df, top_k_transcripts, left_on='HGNC_Symbol', right_on='gene_name', how='inner')\n",
    "    # Get the corresponding proteins\n",
    "    top_k_bmgc_transcript_protein_df = pd.merge(transcript_protein_entity_df, top_k_bmgc_transcript_df, left_on='BMGC_TS_ID', right_on='BioMedGraphica_Conn_ID', how='inner').drop(columns=['BioMedGraphica_Conn_ID', 'gene_name'])\n",
    "    top_k_bmgc_transcript_protein_info_df = pd.merge(top_k_bmgc_transcript_protein_df, bmgc_protein_llmnameid_combined_df, left_on='BMGC_PT_ID', right_on='BioMedGraphica_Conn_ID', how='inner').drop(columns=['BioMedGraphica_Conn_ID', 'BioMedGraphica_ID', sample_ach_name])\n",
    "    top_k_transcript_protein_bmgc_id_list = top_k_bmgc_transcript_protein_info_df['BMGC_PT_ID'].tolist()\n",
    "    top_k_transcript_protein_bmgc_llmnameid_list = top_k_bmgc_transcript_protein_info_df['Names_and_IDs'].replace(r' \\| ', ' or ', regex=True).tolist()\n",
    "    return top_k_transcript_hgnc_name_list, top_k_transcript_protein_bmgc_id_list, top_k_transcript_protein_bmgc_llmnameid_list\n",
    "\n",
    "# Example usage\n",
    "sample_ach_name = 'ACH-000001'\n",
    "k=10\n",
    "top_k_transcript_hgnc_name_list, top_k_transcript_protein_bmgc_id_list, top_k_transcript_protein_bmgc_llmnameid_list = extract_ts_info(dti_crispr_rna_transcript_df, bmgc_transcript_df, transcript_protein_entity_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, k)\n",
    "print(f\"Top {k} Transcript HGNC Names:\", top_k_transcript_hgnc_name_list)\n",
    "print(f\"Top {k} Transcript Protein BMGC IDs:\", top_k_transcript_protein_bmgc_id_list)\n",
    "print(f\"Top {k} Transcript Protein BMGC LLM Name IDs:\", top_k_transcript_protein_bmgc_llmnameid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Protein Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmg_protein_all_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Protein/BioMedGraphica_Conn_Protein.csv')\n",
    "bmg_protein_all_df = bmg_protein_all_df[['BioMedGraphica_Conn_ID', 'Uniprot_ID', 'HGNC_Symbol']].copy()\n",
    "display(bmg_protein_all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in raw_protein_df using the provided mapping\n",
    "raw_protein_map_df = raw_protein_df.rename(columns=protein_map_dict)\n",
    "# Merge with bmg_protein_all_df to get HGNC symbols\n",
    "symbol_protein_map_df = pd.merge(raw_protein_map_df, bmg_protein_all_df, left_on='Uniprot_Acc', right_on='Uniprot_ID', how='inner')\n",
    "# Reorder columns: keep Uniprot IDs and protein expression values\n",
    "symbol_protein_map_df = symbol_protein_map_df[['Uniprot_ID', 'Uniprot_Acc', 'HGNC_Symbol'] + sorted(set(symbol_protein_map_df.columns) - {'Uniprot_ID', 'Uniprot_Acc', 'HGNC_Symbol'})]\n",
    "# Identify overlapping samples between protein data and the provided sample list\n",
    "protein_overlapped_samples = sorted(set(symbol_protein_map_df.columns) & set(overlapped_dti_crispr_rna_samples))\n",
    "# Select only HGNC symbol and overlapping sample columns\n",
    "dti_crispr_rna_protein_df = symbol_protein_map_df[['HGNC_Symbol'] + protein_overlapped_samples].copy()\n",
    "# Split multiple HGNC symbols by \";\" and expand into multiple rows\n",
    "dti_crispr_rna_protein_df = dti_crispr_rna_protein_df.assign(HGNC_Symbol=dti_crispr_rna_protein_df['HGNC_Symbol'].str.split(';')).explode('HGNC_Symbol')\n",
    "\n",
    "# Remove leading/trailing whitespace in gene symbols\n",
    "dti_crispr_rna_protein_df['HGNC_Symbol'] = dti_crispr_rna_protein_df['HGNC_Symbol'].str.strip()\n",
    "# Drop rows with empty or missing gene symbols\n",
    "dti_crispr_rna_protein_df = dti_crispr_rna_protein_df[dti_crispr_rna_protein_df['HGNC_Symbol'].notna() & (dti_crispr_rna_protein_df['HGNC_Symbol'] != '')].reset_index(drop=True)\n",
    "\n",
    "# Display final dataframe\n",
    "display(dti_crispr_rna_protein_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmgc_protein_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Protein/BioMedGraphica_Conn_Protein.csv')\n",
    "display(bmgc_protein_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pt_info(dti_crispr_rna_protein_df, bmgc_protein_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, k=10):\n",
    "    # Check if sample_ach_name exists in dti_crispr_rna_protein_df columns\n",
    "    if sample_ach_name not in dti_crispr_rna_protein_df.columns:\n",
    "        return \"non-existed\", \"non-existed\", \"non-existed\"\n",
    "    # Extract the top k highest values for the given sample name\n",
    "    top_k_proteins = dti_crispr_rna_protein_df.nlargest(k, sample_ach_name)[['HGNC_Symbol', sample_ach_name]]\n",
    "    # Sort the top k proteins by their values in descending order\n",
    "    top_k_proteins = top_k_proteins.sort_values(by=sample_ach_name, ascending=False).reset_index(drop=True)\n",
    "    top_k_protein_hgnc_name_list = top_k_proteins['HGNC_Symbol'].tolist()\n",
    "    # Merge with the bmgc_protein_df to get the BioMedGraphica_Conn_ID\n",
    "    bmgc_protein_df = bmgc_protein_df[['BioMedGraphica_Conn_ID', 'HGNC_Symbol']].copy()\n",
    "    top_k_bmgc_protein_df = pd.merge(bmgc_protein_df, top_k_proteins, left_on='HGNC_Symbol', right_on='HGNC_Symbol', how='inner')\n",
    "    # Get the corresponding protein information\n",
    "    top_k_bmgc_protein_info_df = pd.merge(top_k_bmgc_protein_df, bmgc_protein_llmnameid_combined_df, left_on='BioMedGraphica_Conn_ID', right_on='BioMedGraphica_Conn_ID', how='inner').drop(columns=['BioMedGraphica_ID', sample_ach_name])\n",
    "    top_k_protein_bmgc_id_list = top_k_bmgc_protein_info_df['BioMedGraphica_Conn_ID'].tolist()\n",
    "    # Replace both \"|\" and \";\" with \" or \"\n",
    "    top_k_protein_bmgc_llmnameid_list = top_k_bmgc_protein_info_df['Names_and_IDs'].replace([r' \\| ', r';'], ' or ', regex=True).tolist()\n",
    "    return top_k_protein_hgnc_name_list, top_k_protein_bmgc_id_list, top_k_protein_bmgc_llmnameid_list\n",
    "\n",
    "# Example usage\n",
    "sample_ach_name = 'ACH-000001'\n",
    "k = 10\n",
    "top_k_protein_hgnc_name_list, top_k_protein_bmgc_id_list, top_k_protein_bmgc_llmnameid_list = extract_pt_info(dti_crispr_rna_protein_df, bmgc_protein_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, k)\n",
    "print(f\"Top {k} Protein HGNC Names:\", top_k_protein_hgnc_name_list)\n",
    "print(f\"Top {k} Protein BMGC IDs:\", top_k_protein_bmgc_id_list)\n",
    "print(f\"Top {k} Protein BMGC LLM Name IDs:\", top_k_protein_bmgc_llmnameid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.3 Related Proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_disease_protein(selected_sample_disease_bmgc_id, dti_edge_index_path, \n",
    "                    omics_node_index_df, nodeid_index_dict, index_nodeid_dict):\n",
    "    \"\"\"\n",
    "    Extract protein directly connected to a disease node.\n",
    "    \n",
    "    Args:\n",
    "        sample_disease_bmgc_id_index (int): Index of the disease node\n",
    "        dti_edge_index_path (str): Path to the DTI edge index file\n",
    "        omics_node_index_df (pd.DataFrame): DataFrame with node type information\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (disease_protein_index, disease_protein_bmgc_id)\n",
    "    \"\"\"\n",
    "    # Extract the index based on the selected disease BMGC ID\n",
    "    sample_disease_bmgc_id_index = nodeid_index_dict[selected_sample_disease_bmgc_id]\n",
    "    \n",
    "    # Load DTI edge index\n",
    "    dti_all_edge_index = np.load(dti_edge_index_path)\n",
    "    \n",
    "    # Find incoming edges (source nodes that point to the disease)\n",
    "    incoming_mask = dti_all_edge_index[1, :] == sample_disease_bmgc_id_index\n",
    "    incoming_source_nodes = dti_all_edge_index[0, incoming_mask]\n",
    "    \n",
    "    # Find outgoing edges (target nodes that the disease points to)\n",
    "    outgoing_mask = dti_all_edge_index[0, :] == sample_disease_bmgc_id_index\n",
    "    outgoing_target_nodes = dti_all_edge_index[1, outgoing_mask]\n",
    "    \n",
    "    # Combine all neighbor nodes (both incoming and outgoing)\n",
    "    disease_related_nodes = np.concatenate([incoming_source_nodes, outgoing_target_nodes])\n",
    "    unique_disease_related_nodes = np.unique(disease_related_nodes)\n",
    "    \n",
    "    # Get protein node index\n",
    "    protein_node_index_df = omics_node_index_df[omics_node_index_df['Type'] == 'Protein']\n",
    "    protein_node_index_list = protein_node_index_df['Index'].tolist()\n",
    "    \n",
    "    # Filter to get only protein nodes directly connected to the disease\n",
    "    disease_protein_index = sorted(\n",
    "        list(set(unique_disease_related_nodes) & set(protein_node_index_list))\n",
    "    )\n",
    "    \n",
    "    # Map protein index to BMGC id\n",
    "    disease_protein_bmgc_id = [index_nodeid_dict[i] for i in disease_protein_index]\n",
    "    \n",
    "    return disease_protein_index, disease_protein_bmgc_id\n",
    "\n",
    "\n",
    "def extract_ppi_nodes(disease_protein_index, dti_edge_index_path, omics_node_index_df, index_nodeid_dict):\n",
    "    \"\"\"\n",
    "    Extract protein-protein interaction (PPI) nodes that interact with disease-related protein.\n",
    "    \n",
    "    Args:\n",
    "        disease_protein_index (list): List of protein node index directly related to the disease\n",
    "        dti_edge_index_path (str): Path to the DTI edge index file\n",
    "        omics_node_index_df (pd.DataFrame): DataFrame with node type information\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (ppi_nodes_index, ppi_nodes_bmgc_id)\n",
    "    \"\"\"\n",
    "\n",
    "    # Load DTI edge index\n",
    "    dti_all_edge_index = np.load(dti_edge_index_path)\n",
    "    \n",
    "    # Get protein node index\n",
    "    protein_node_index_df = omics_node_index_df[omics_node_index_df['Type'] == 'Protein']\n",
    "    protein_node_index_list = protein_node_index_df['Index'].tolist()\n",
    "    \n",
    "    # Get all nodes related to the identified protein neighbors (second hop)\n",
    "    protein_related_nodes = []\n",
    "    \n",
    "    # Iterate through each protein neighbor node index\n",
    "    for protein_node_idx in disease_protein_index:\n",
    "        # Find incoming edges (nodes that point to this protein)\n",
    "        protein_incoming_mask = dti_all_edge_index[1, :] == protein_node_idx\n",
    "        protein_incoming_sources = dti_all_edge_index[0, protein_incoming_mask]\n",
    "        \n",
    "        # Find outgoing edges (nodes that this protein points to)\n",
    "        protein_outgoing_mask = dti_all_edge_index[0, :] == protein_node_idx\n",
    "        protein_outgoing_targets = dti_all_edge_index[1, protein_outgoing_mask]\n",
    "        \n",
    "        # Add these connected nodes to our list\n",
    "        protein_related_nodes.extend(protein_incoming_sources)\n",
    "        protein_related_nodes.extend(protein_outgoing_targets)\n",
    "    \n",
    "    # Convert to numpy array and get unique nodes\n",
    "    protein_related_nodes = np.array(protein_related_nodes)\n",
    "    unique_protein_related_nodes = np.unique(protein_related_nodes)\n",
    "    \n",
    "    # Remove any protein nodes themselves from this list to avoid duplication\n",
    "    unique_protein_related_nodes = np.setdiff1d(\n",
    "        unique_protein_related_nodes, disease_protein_index\n",
    "    )\n",
    "    \n",
    "    # Filter to only keep protein nodes among the second-hop neighbors\n",
    "    ppi_nodes_index = sorted(\n",
    "        list(set(unique_protein_related_nodes) & set(protein_node_index_list))\n",
    "    )\n",
    "    \n",
    "    # Map PPI node index to BMGC id\n",
    "    ppi_nodes_bmgc_id = [index_nodeid_dict[i] for i in ppi_nodes_index]\n",
    "\n",
    "    return ppi_nodes_index, ppi_nodes_bmgc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary between ID and Index\n",
    "nodeid_index_data = pd.read_csv('../BMG/DTI_data/nodes_index.csv')\n",
    "nodeid_index_dict = dict(zip(nodeid_index_data['Node'], nodeid_index_data['Index']))\n",
    "index_nodeid_dict = dict(zip(nodeid_index_data['Index'], nodeid_index_data['Node']))\n",
    "# use omics_node_index_df to get the node type\n",
    "omics_node_index_df = pd.read_csv('../BMG/Pretrain_data/omics_nodes_index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in raw_protein_df using the provided mapping\n",
    "raw_protein_map_df = raw_protein_df.rename(columns=protein_map_dict)\n",
    "# Merge with bmg_protein_all_df to get HGNC symbols\n",
    "symbol_protein_map_df = pd.merge(raw_protein_map_df, bmg_protein_all_df, left_on='Uniprot_Acc', right_on='Uniprot_ID', how='inner')\n",
    "# Reorder columns: keep Uniprot IDs and protein expression values\n",
    "symbol_protein_map_df = symbol_protein_map_df[['Uniprot_ID', 'Uniprot_Acc', 'HGNC_Symbol'] + sorted(set(symbol_protein_map_df.columns) - {'Uniprot_ID', 'Uniprot_Acc', 'HGNC_Symbol'})]\n",
    "# Identify overlapping samples between protein data and the provided sample list\n",
    "protein_overlapped_samples = sorted(set(symbol_protein_map_df.columns) & set(overlapped_dti_crispr_rna_samples))\n",
    "# Select only HGNC symbol and overlapping sample columns\n",
    "dti_crispr_rna_protein_df = symbol_protein_map_df[['HGNC_Symbol'] + protein_overlapped_samples].copy()\n",
    "# Split multiple HGNC symbols by \";\" and expand into multiple rows\n",
    "dti_crispr_rna_protein_df = dti_crispr_rna_protein_df.assign(HGNC_Symbol=dti_crispr_rna_protein_df['HGNC_Symbol'].str.split(';')).explode('HGNC_Symbol')\n",
    "\n",
    "# Remove leading/trailing whitespace in gene symbols\n",
    "dti_crispr_rna_protein_df['HGNC_Symbol'] = dti_crispr_rna_protein_df['HGNC_Symbol'].str.strip()\n",
    "# Drop rows with empty or missing gene symbols\n",
    "dti_crispr_rna_protein_df = dti_crispr_rna_protein_df[dti_crispr_rna_protein_df['HGNC_Symbol'].notna() & (dti_crispr_rna_protein_df['HGNC_Symbol'] != '')].reset_index(drop=True)\n",
    "\n",
    "# Display final dataframe\n",
    "display(dti_crispr_rna_protein_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmgc_pt_id_to_hgnc(bmgc_id_list, bmgc_protein_df):\n",
    "    \"\"\"\n",
    "    Convert a list of BioMedGraphica IDs to their corresponding HGNC symbols.\n",
    "    \n",
    "    Args:\n",
    "        bmgc_id_list (list): List of BioMedGraphica IDs\n",
    "        bmgc_protein_df (pd.DataFrame): DataFrame with BioMedGraphica IDs and HGNC symbols\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (\n",
    "            dict: Dictionary mapping each BioMedGraphica ID to its list of HGNC symbols,\n",
    "            list: Combined list of all HGNC symbols\n",
    "        )\n",
    "    \"\"\"\n",
    "    # Ensure bmgc_id_list is actually a list\n",
    "    if not isinstance(bmgc_id_list, list):\n",
    "        bmgc_id_list = [bmgc_id_list]\n",
    "    \n",
    "    results = {}\n",
    "    all_hgnc_symbols = []\n",
    "    \n",
    "    for bmgc_id in bmgc_id_list:\n",
    "        # Filter the DataFrame for the given BioMedGraphica ID\n",
    "        filtered_df = bmgc_protein_df[bmgc_protein_df['BioMedGraphica_Conn_ID'] == bmgc_id]\n",
    "        \n",
    "        # Skip if no match found\n",
    "        if filtered_df.empty:\n",
    "            results[bmgc_id] = []\n",
    "            continue\n",
    "            \n",
    "        # Get the HGNC symbols\n",
    "        hgnc_value = filtered_df['HGNC_Symbol'].values[0]\n",
    "        \n",
    "        # Skip if HGNC symbol is NaN\n",
    "        if pd.isna(hgnc_value):\n",
    "            results[bmgc_id] = []\n",
    "            continue\n",
    "        \n",
    "        # Process valid HGNC symbols\n",
    "        hgnc_list = list(set(hgnc_value.split(';')))\n",
    "        hgnc_list = [hgnc.strip() for hgnc in hgnc_list if hgnc.strip() != '']\n",
    "        \n",
    "        results[bmgc_id] = hgnc_list\n",
    "        all_hgnc_symbols.extend(hgnc_list)\n",
    "    \n",
    "    # Remove duplicates from the combined list\n",
    "    all_hgnc_symbols = list(set(all_hgnc_symbols))\n",
    "    \n",
    "    return results, all_hgnc_symbols\n",
    "\n",
    "# Example usage\n",
    "bmgc_ids = ['BMGC_PT000001', 'BMGC_PT013541']\n",
    "hgnc_dict, all_hgnc_symbols = bmgc_pt_id_to_hgnc(bmgc_ids, bmgc_protein_df)\n",
    "print(hgnc_dict)\n",
    "print(all_hgnc_symbols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hgnc_to_bmgc_pt_id(hgnc_list, bmgc_protein_df):\n",
    "    \"\"\"\n",
    "    Convert a list of HGNC symbols to their corresponding BioMedGraphica IDs.\n",
    "    \n",
    "    Args:\n",
    "        hgnc_list (list): List of HGNC symbols\n",
    "        bmgc_protein_df (pd.DataFrame): DataFrame with BioMedGraphica IDs and HGNC symbols\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (\n",
    "            dict: Dictionary mapping each HGNC symbol to its list of BioMedGraphica IDs,\n",
    "            list: Combined list of all BioMedGraphica IDs\n",
    "        )\n",
    "    \"\"\"\n",
    "    # Ensure hgnc_list is actually a list\n",
    "    if not isinstance(hgnc_list, list):\n",
    "        hgnc_list = [hgnc_list]\n",
    "    \n",
    "    results = {}\n",
    "    all_bmgc_ids = []\n",
    "    \n",
    "    for hgnc in hgnc_list:\n",
    "        # Filter the DataFrame for the given HGNC symbol\n",
    "        filtered_df = bmgc_protein_df[bmgc_protein_df['HGNC_Symbol'] == hgnc]\n",
    "        \n",
    "        # Skip if no match found\n",
    "        if filtered_df.empty:\n",
    "            results[hgnc] = []\n",
    "            continue\n",
    "        \n",
    "        # Get the BioMedGraphica IDs\n",
    "        bmgc_value = filtered_df['BioMedGraphica_Conn_ID'].values[0]\n",
    "        \n",
    "        # Skip if BioMedGraphica ID is NaN\n",
    "        if pd.isna(bmgc_value):\n",
    "            results[hgnc] = []\n",
    "            continue\n",
    "        \n",
    "        # Process valid BioMedGraphica IDs\n",
    "        bmgc_list = list(set(bmgc_value.split(';')))\n",
    "        bmgc_list = [bmgc.strip() for bmgc in bmgc_list if bmgc.strip() != '']\n",
    "        \n",
    "        results[hgnc] = bmgc_list\n",
    "        all_bmgc_ids.extend(bmgc_list)\n",
    "    \n",
    "    # Remove duplicates from the combined list\n",
    "    all_bmgc_ids = list(set(all_bmgc_ids))\n",
    "    \n",
    "    return results, all_bmgc_ids\n",
    "\n",
    "# Example usage\n",
    "hgnc_list = ['BRCA1', 'TP53']\n",
    "bmgc_dict, all_bmgc_ids = hgnc_to_bmgc_pt_id(hgnc_list, bmgc_protein_df)\n",
    "print(bmgc_dict)\n",
    "print(all_bmgc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kg_related_proteins(selected_sample_disease_bmgc_id, dti_edge_index_path,  # '../BMG/DTI_data/edge_index.npy'\n",
    "                               omics_node_index_df, nodeid_index_dict, index_nodeid_dict):\n",
    "    \"\"\"\n",
    "    Extract disease-related proteins and their interactions from the knowledge graph.\n",
    "    \n",
    "    Args:\n",
    "        selected_sample_disease_bmgc_id (str): BMGC ID of the selected disease\n",
    "        dti_edge_index_path (str): Path to the DTI edge index file\n",
    "        omics_node_index_df (pd.DataFrame): DataFrame with node type information\n",
    "        nodeid_index_dict (dict): Mapping from node ID to index\n",
    "        index_nodeid_dict (dict): Mapping from index to node ID\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (disease_protein_index, disease_protein_bmgc_id, ppi_nodes_index, ppi_nodes_bmgc_id)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract disease-protein connections\n",
    "    disease_protein_index, disease_protein_bmgc_id = extract_disease_protein(\n",
    "        selected_sample_disease_bmgc_id=selected_sample_disease_bmgc_id,\n",
    "        dti_edge_index_path=dti_edge_index_path,\n",
    "        omics_node_index_df=omics_node_index_df,\n",
    "        nodeid_index_dict=nodeid_index_dict,\n",
    "        index_nodeid_dict=index_nodeid_dict\n",
    "    )\n",
    "\n",
    "    # Extract protein-protein interactions (can replace this with LLM to generate PPI, may need NER and mapping to BMGC id)\n",
    "    ppi_nodes_index, ppi_nodes_bmgc_id = extract_ppi_nodes(\n",
    "        disease_protein_index=disease_protein_index,\n",
    "        dti_edge_index_path=dti_edge_index_path,\n",
    "        omics_node_index_df=omics_node_index_df,\n",
    "        index_nodeid_dict=index_nodeid_dict\n",
    "    )\n",
    "\n",
    "    # Convert the BMGC id into HGNC symbol\n",
    "\n",
    "    return disease_protein_index, disease_protein_bmgc_id, ppi_nodes_index, ppi_nodes_bmgc_id\n",
    "\n",
    "# Example usage\n",
    "# selected_sample_disease_bmgc_id = 'BMGC_DS16646'\n",
    "selected_sample_disease_bmgc_id = 'BMGC_DS07934'\n",
    "dti_edge_index_path = '../BMG/DTI_data/edge_index.npy'\n",
    "\n",
    "disease_protein_index, disease_protein_bmgc_id, ppi_nodes_index, ppi_nodes_bmgc_id = extract_kg_related_proteins(\n",
    "    selected_sample_disease_bmgc_id=selected_sample_disease_bmgc_id,\n",
    "    dti_edge_index_path=dti_edge_index_path,\n",
    "    omics_node_index_df=omics_node_index_df,\n",
    "    nodeid_index_dict=nodeid_index_dict,\n",
    "    index_nodeid_dict=index_nodeid_dict\n",
    ")\n",
    "print(\"Disease Protein Index:\", disease_protein_index)\n",
    "print(\"Disease Protein BMGC ID:\", disease_protein_bmgc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.4 CRISPR Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_crispr_df = crispr_df[['gene_name'] + sorted(overlapped_dti_crispr_rna_samples)].copy()\n",
    "display(answer_crispr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(answer_crispr_df, bmgc_gene_df, gene_transcript_protein_entity_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, top_bm=100):\n",
    "    # Extract the lowest top_bm values for the given sample name\n",
    "    top_bm_genes = answer_crispr_df.nsmallest(top_bm, sample_ach_name)[['gene_name', sample_ach_name]]\n",
    "    # Sort the top bm genes by their values in ascending order\n",
    "    top_bm_genes = top_bm_genes.sort_values(by=sample_ach_name, ascending=True).reset_index(drop=True)\n",
    "    top_bm_gene_hgnc_name_list = top_bm_genes['gene_name'].tolist()\n",
    "    # Merge with the bmgc_gene_df to get the BioMedGraphica_Conn_ID\n",
    "    bmgc_gene_df = bmgc_gene_df[['BioMedGraphica_Conn_ID', 'HGNC_Symbol']].copy()\n",
    "    top_bm_bmgc_gene_df = pd.merge(bmgc_gene_df, top_bm_genes, left_on='HGNC_Symbol', right_on='gene_name', how='inner')\n",
    "    # Get the corresponding proteins\n",
    "    top_bm_bmgc_gene_protein_df = pd.merge(gene_transcript_protein_entity_df, top_bm_bmgc_gene_df, left_on='BMGC_GN_ID', right_on='BioMedGraphica_Conn_ID', how='inner').drop(columns=['BioMedGraphica_Conn_ID', 'gene_name'])\n",
    "    top_bm_bmgc_gene_protein_info_df = pd.merge(top_bm_bmgc_gene_protein_df, bmgc_protein_llmnameid_combined_df, left_on='BMGC_PT_ID', right_on='BioMedGraphica_Conn_ID', how='inner').drop(columns=['BioMedGraphica_Conn_ID', 'BioMedGraphica_ID', sample_ach_name])\n",
    "    top_bm_gene_protein_bmgc_id_list = top_bm_bmgc_gene_protein_info_df['BMGC_PT_ID'].tolist()\n",
    "    top_bm_gene_protein_bmgc_llmnameid_list = top_bm_bmgc_gene_protein_info_df['Names_and_IDs'].replace(r' \\| ', ' or ', regex=True).tolist()\n",
    "    return top_bm_gene_hgnc_name_list, top_bm_gene_protein_bmgc_id_list, top_bm_gene_protein_bmgc_llmnameid_list\n",
    "\n",
    "# Example usage\n",
    "sample_ach_name = 'ACH-000001'\n",
    "top_bm = 1000\n",
    "bmgc_protein_llmnameid_combined_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Protein/BioMedGraphica_Conn_Protein_LLM_Name_ID_Combined.csv')\n",
    "top_bm_gene_hgnc_name_list, top_bm_gene_protein_bmgc_id_list, top_bm_gene_protein_bmgc_llmnameid_list = extract_answer(answer_crispr_df, bmgc_gene_df, gene_transcript_protein_entity_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, top_bm)\n",
    "print(f\"Top {top_bm} Gene HGNC Names:\", top_bm_gene_hgnc_name_list)\n",
    "print(f\"Top {top_bm} Gene Protein BMGC IDs:\", top_bm_gene_protein_bmgc_id_list)\n",
    "print(f\"Top {top_bm} Gene Protein BMGC LLM Name IDs:\", top_bm_gene_protein_bmgc_llmnameid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the overlap between CRISPR and pvalue answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the overlap elements/genes between top_pvalue_bm_gene_hgnc_name_list and top_bm_gene_hgnc_name_list\n",
    "# overlap_genes = list(set(top_bm_gene_hgnc_name_list) & set(top_pvalue_bm_gene_hgnc_name_list))\n",
    "# # Count the number of overlapping genes\n",
    "# overlap_count = len(overlap_genes)\n",
    "# # Print the overlapping genes and their count\n",
    "# print(f\"Number of overlapping genes: {overlap_count}\")\n",
    "# print(\"Overlap Genes:\", overlap_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.5 KG Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bmgc_protein_df)\n",
    "display(bmgc_relation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_protein_relationships(hgnc_symbols, bmgc_protein_df, bmgc_relation_df):\n",
    "    \"\"\"\n",
    "    Find relationships between a list of proteins based on HGNC symbols.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    hgnc_symbols : list\n",
    "        List of HGNC symbols to find relationships between\n",
    "    bmgc_protein_df : pandas DataFrame\n",
    "        DataFrame containing BioMedGraphica_Conn_ID and HGNC_Symbol columns\n",
    "    bmgc_relation_df : pandas DataFrame\n",
    "        DataFrame containing BMGC_From_ID and BMGC_To_ID columns\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple (pandas DataFrame, list)\n",
    "        - DataFrame with source_symbol, target_symbol and their relationship\n",
    "        - List of text descriptions of relationships in \"A -> B\" format\n",
    "    \"\"\"\n",
    "    # Filter the protein DataFrame to only include the proteins we care about\n",
    "    filtered_proteins = bmgc_protein_df[bmgc_protein_df['HGNC_Symbol'].isin(hgnc_symbols)]\n",
    "    \n",
    "    # Create a mapping from HGNC symbol to BMGC ID\n",
    "    hgnc_to_bmgc = dict(zip(filtered_proteins['HGNC_Symbol'], filtered_proteins['BioMedGraphica_Conn_ID']))\n",
    "    bmgc_to_hgnc = dict(zip(filtered_proteins['BioMedGraphica_Conn_ID'], filtered_proteins['HGNC_Symbol']))\n",
    "    \n",
    "    # Get all BMGC IDs of our proteins\n",
    "    bmgc_ids = list(hgnc_to_bmgc.values())\n",
    "    \n",
    "    # Filter the relationship DataFrame to only include relationships between our proteins\n",
    "    protein_relations = bmgc_relation_df[\n",
    "        bmgc_relation_df['BMGC_From_ID'].isin(bmgc_ids) & \n",
    "        bmgc_relation_df['BMGC_To_ID'].isin(bmgc_ids)\n",
    "    ]\n",
    "    \n",
    "    # Map the BMGC IDs back to HGNC symbols\n",
    "    result_data = []\n",
    "    text_descriptions = []\n",
    "    \n",
    "    for _, row in protein_relations.iterrows():\n",
    "        source_bmgc = row['BMGC_From_ID']\n",
    "        target_bmgc = row['BMGC_To_ID']\n",
    "        \n",
    "        if source_bmgc in bmgc_to_hgnc and target_bmgc in bmgc_to_hgnc:\n",
    "            source_symbol = bmgc_to_hgnc[source_bmgc]\n",
    "            target_symbol = bmgc_to_hgnc[target_bmgc]\n",
    "            \n",
    "            # Create text description\n",
    "            text_description = f\"{source_symbol} -> {target_symbol}\"\n",
    "            text_descriptions.append(text_description)\n",
    "            \n",
    "            # If relation_type column exists, include it in the description and data\n",
    "            relation_info = {\n",
    "                'source_symbol': source_symbol,\n",
    "                'target_symbol': target_symbol\n",
    "            }\n",
    "            \n",
    "            # Add relation type if it exists in the DataFrame\n",
    "            if 'relation_type' in bmgc_relation_df.columns:\n",
    "                relation_type = row['relation_type']\n",
    "                relation_info['relation_type'] = relation_type\n",
    "                text_descriptions[-1] = f\"{source_symbol} -{relation_type}-> {target_symbol}\"\n",
    "                \n",
    "            result_data.append(relation_info)\n",
    "    \n",
    "    # Create a DataFrame from the results\n",
    "    result_df = pd.DataFrame(result_data)\n",
    "    \n",
    "    return result_df, text_descriptions\n",
    "\n",
    "# Define the HGNC symbols\n",
    "hgnc_symbols = ['SNRPD3', 'RAN', 'RPS8', 'UBL5', 'SMU1', 'RRM1', 'PSMA6', 'PSMB3', 'WEE1', \n",
    "                'PHB1', 'BANF1', 'KIF11', 'SNRPD1', 'PSMA3', 'PSMD11', 'PRPF19', 'SNRPF', \n",
    "                'RPS29', 'CDC27', 'SRSF3', 'TUBGCP2', 'ECD', 'RPS20', 'PCNA', 'PSMA7', 'CDC7', \n",
    "                'RPL17', 'GINS1', 'PHB2', 'SRSF2', 'MAD2L1', 'MED14']\n",
    "\n",
    "# Call the function to find relationships\n",
    "relationships_df, relationship_texts = find_protein_relationships(hgnc_symbols, bmgc_protein_df, bmgc_relation_df)\n",
    "\n",
    "# You can now use both the DataFrame and text descriptions\n",
    "# Example usage:\n",
    "print(f\"Found {len(relationship_texts)} relationships between the proteins\")\n",
    "print(\"Example relationships:\")\n",
    "print(relationship_texts[:5])  # Print first 5 relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.6 Formulate into json QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_sample_info(sample_ach_name, selected_sample_disease_bmgc_id, k=100, top_bm=100):\n",
    "    # LLM Info\n",
    "    print(f\"Sample ACH Name: {sample_ach_name}\")\n",
    "    print(f\"Extracting top {k} gene information for {sample_ach_name}...\")\n",
    "    top_k_gene_hgnc_name_list, top_k_gene_protein_bmgc_id_list, top_k_gene_protein_bmgc_llmnameid_list = extract_gn_info(dti_crispr_rna_gene_df, bmgc_gene_df, gene_transcript_protein_entity_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, k)\n",
    "    print(f\"Extracting top {k} transcript information for {sample_ach_name}...\")\n",
    "    top_k_transcript_hgnc_name_list, top_k_transcript_protein_bmgc_id_list, top_k_transcript_protein_bmgc_llmnameid_list = extract_ts_info(dti_crispr_rna_transcript_df, bmgc_transcript_df, transcript_protein_entity_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, k)\n",
    "    print(f\"Extracting top {k} protein information for {sample_ach_name}...\")\n",
    "    top_k_protein_hgnc_name_list, top_k_protein_bmgc_id_list, top_k_protein_bmgc_llmnameid_list = extract_pt_info(dti_crispr_rna_protein_df, bmgc_protein_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, k)\n",
    "    # KG Info\n",
    "    dti_edge_index_path = '../BMG/DTI_data/edge_index.npy'\n",
    "    print(f\"Extracting disease-related proteins index and bmgc id for {selected_sample_disease_bmgc_id} ({sample_ach_name}) ...\")\n",
    "    disease_protein_index, disease_protein_bmgc_id, ppi_nodes_index, ppi_nodes_bmgc_id = extract_kg_related_proteins(selected_sample_disease_bmgc_id, dti_edge_index_path, omics_node_index_df, nodeid_index_dict, index_nodeid_dict)\n",
    "    print(f\"Knowledge Graph Info: Found {len(disease_protein_index)} disease-related proteins directly connected to {selected_sample_disease_bmgc_id} and {len(ppi_nodes_index)} proteins in their PPI network\")\n",
    "    print(f\"Mapping disease-related proteins to HGNC symbols...\")\n",
    "    disease_protein_hgnc_dict, disease_protein_hgnc_list = bmgc_pt_id_to_hgnc(disease_protein_bmgc_id, bmgc_protein_df)\n",
    "    print(f\"Mapping PPI-related proteins to HGNC symbols...\")\n",
    "    ppi_hgnc_dict, ppi_hgnc_list = bmgc_pt_id_to_hgnc(ppi_nodes_bmgc_id, bmgc_protein_df)\n",
    "    # LLM Used KG Info\n",
    "    print(f\"Extracting protein relationships from BMGC...\")\n",
    "    # Convert the any non-existed string in top_k_gene_hgnc_name_list + top_k_transcript_hgnc_name_list + top_k_protein_hgnc_name_list + disease_protein_hgnc_list into empty list []\n",
    "    if top_k_gene_hgnc_name_list == \"non-existed\": top_k_gene_hgnc_name_list = []\n",
    "    if top_k_transcript_hgnc_name_list == \"non-existed\": top_k_transcript_hgnc_name_list = []\n",
    "    if top_k_protein_hgnc_name_list == \"non-existed\": top_k_protein_hgnc_name_list = []\n",
    "    if disease_protein_hgnc_list == \"non-existed\": disease_protein_hgnc_list = []\n",
    "    # Combine all the HGNC symbols into a single list for relationship extraction\n",
    "    omics_disease_protein_hgnc_list = list(set(top_k_gene_hgnc_name_list + top_k_transcript_hgnc_name_list + top_k_protein_hgnc_name_list + disease_protein_hgnc_list))\n",
    "    relationships_df, relationship_texts = find_protein_relationships(omics_disease_protein_hgnc_list, bmgc_protein_df, bmgc_relation_df)\n",
    "    print(f\"Knowledge Graph Info: Found {len(omics_disease_protein_hgnc_list)} unique proteins and {len(relationship_texts)} relationships between them\")\n",
    "    # Answer Info\n",
    "    print(f\"Extracting top {top_bm} CRISPR gene information for {sample_ach_name}...\")\n",
    "    top_bm_gene_hgnc_name_list, top_bm_gene_protein_bmgc_id_list, top_bm_gene_protein_bmgc_llmnameid_list = extract_answer(answer_crispr_df, bmgc_gene_df, gene_transcript_protein_entity_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, top_bm)\n",
    "    return top_k_gene_hgnc_name_list, top_k_gene_protein_bmgc_id_list, top_k_gene_protein_bmgc_llmnameid_list, \\\n",
    "              top_k_transcript_hgnc_name_list, top_k_transcript_protein_bmgc_id_list, top_k_transcript_protein_bmgc_llmnameid_list, \\\n",
    "                top_k_protein_hgnc_name_list, top_k_protein_bmgc_id_list, top_k_protein_bmgc_llmnameid_list, \\\n",
    "                disease_protein_index, disease_protein_bmgc_id, ppi_nodes_index, ppi_nodes_bmgc_id, \\\n",
    "                    disease_protein_hgnc_dict, disease_protein_hgnc_list, ppi_hgnc_dict, ppi_hgnc_list, relationship_texts, \\\n",
    "                        top_bm_gene_hgnc_name_list, top_bm_gene_protein_bmgc_id_list, top_bm_gene_protein_bmgc_llmnameid_list\n",
    "\n",
    "# Example usage\n",
    "sample_ach_name = 'ACH-000001'\n",
    "selected_sample_disease_bmgc_id = 'BMGC_DS07934'\n",
    "k = 100\n",
    "top_bm = 100\n",
    "bmgc_protein_llmnameid_combined_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Protein/BioMedGraphica_Conn_Protein_LLM_Name_ID_Combined.csv')\n",
    "return_tuples = qa_sample_info(sample_ach_name, selected_sample_disease_bmgc_id, k=k, top_bm=top_bm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dti_sample_info_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Parameters\n",
    "# k = 10\n",
    "# top_bm = 100\n",
    "# save_every_n = 10\n",
    "# count = 0\n",
    "\n",
    "# # Output folder and filename\n",
    "# output_dir = \"../QA_Data/\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# output_filename = f\"multi_sample_qa_info_k{k}_bm{top_bm}.json\"\n",
    "# output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "# # Final output dictionary\n",
    "# multi_sample_qa_json = {}\n",
    "\n",
    "# # Iterate through the sample info dataframe\n",
    "# for _, row in tqdm(dti_sample_info_index.iterrows(), total=len(dti_sample_info_index)):\n",
    "#     count += 1\n",
    "\n",
    "#     sample_ach_name = row[\"depMapID\"]\n",
    "#     sample_dti_index = row[\"Index\"]\n",
    "#     cell_line_name = row[\"Name\"]\n",
    "#     disease = row[\"BMGC_Disease_name\"]\n",
    "#     disease_bmgc_id = row[\"BMGC_Disease_ID\"]\n",
    "\n",
    "#     print(f\"Processing sample: {sample_ach_name} ({cell_line_name})\")\n",
    "#     print(f\"Sample Disease: {disease}\")\n",
    "#     print(f\"Sample Disease BMGC ID: {disease_bmgc_id}\")\n",
    "\n",
    "#     try:\n",
    "#         (top_k_gene_hgnc, top_k_gene_bmgc, top_k_gene_llm,\n",
    "#         top_k_ts_hgnc, top_k_ts_bmgc, top_k_ts_llm,\n",
    "#         top_k_pt_hgnc, top_k_pt_bmgc, top_k_pt_llm,\n",
    "#         dis_pt_idx, dis_pt_bmgc, ppi_idx, ppi_bmgc,\n",
    "#         dis_pt_hgnc_dict, dis_pt_hgnc, ppi_hgnc_dict, ppi_hgnc, relationship_texts,\n",
    "#         ans_hgnc, ans_bmgc, ans_llm) = qa_sample_info(sample_ach_name, disease_bmgc_id, k=k, top_bm=top_bm)\n",
    "\n",
    "#         multi_sample_qa_json[sample_ach_name] = {\n",
    "#             \"cell_line_name\": cell_line_name,\n",
    "#             \"sample_dti_index\": sample_dti_index,\n",
    "#             \"disease\": disease,\n",
    "#             \"disease_bmgc_id\": disease_bmgc_id,\n",
    "#             \"input\": {\n",
    "#                 \"top_k_gene\": {\n",
    "#                     \"hgnc_symbols\": top_k_gene_hgnc,\n",
    "#                     \"protein_bmgc_ids\": top_k_gene_bmgc,\n",
    "#                     \"protein_llmname_ids\": top_k_gene_llm\n",
    "#                 },\n",
    "#                 \"top_k_transcript\": {\n",
    "#                     \"hgnc_symbols\": top_k_ts_hgnc,\n",
    "#                     \"protein_bmgc_ids\": top_k_ts_bmgc,\n",
    "#                     \"protein_llmname_ids\": top_k_ts_llm\n",
    "#                 },\n",
    "#                 \"top_k_protein\": {\n",
    "#                     \"hgnc_symbols\": top_k_pt_hgnc,\n",
    "#                     \"protein_bmgc_ids\": top_k_pt_bmgc,\n",
    "#                     \"protein_llmname_ids\": top_k_pt_llm\n",
    "#                 },\n",
    "#                 \"knowledge_graph\": {\n",
    "#                     \"disease_protein\": {\n",
    "#                         \"bmgc_ids\": dis_pt_bmgc,\n",
    "#                         \"hgnc_symbols\": dis_pt_hgnc,\n",
    "#                         \"indices\": dis_pt_idx\n",
    "#                     },\n",
    "#                     \"ppi_neighbors\": {\n",
    "#                         \"bmgc_ids\": ppi_bmgc,\n",
    "#                         \"hgnc_symbols\": ppi_hgnc,\n",
    "#                         \"indices\": ppi_idx\n",
    "#                     },\n",
    "#                     \"protein_relationships\": relationship_texts,\n",
    "#                 }\n",
    "#             },\n",
    "#             \"ground_truth_answer\": {\n",
    "#                 \"top_bm_gene\": {\n",
    "#                     \"hgnc_symbols\": ans_hgnc,\n",
    "#                     \"protein_bmgc_ids\": ans_bmgc,\n",
    "#                     \"protein_llmname_ids\": ans_llm\n",
    "#                 }\n",
    "#             }\n",
    "#         }\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"⚠️ Error processing {sample_ach_name}: {e}\")\n",
    "#         continue\n",
    "\n",
    "#     # Periodic save every 10 samples\n",
    "#     if count % save_every_n == 0:\n",
    "#         with open(output_path, \"w\") as f:\n",
    "#             json.dump(multi_sample_qa_json, f, indent=2, default=lambda o: int(o) if hasattr(o, 'item') else o)\n",
    "#         print(f\"💾 Auto-saved JSON at {count} samples to: {output_path}\")\n",
    "\n",
    "# # Final save after loop\n",
    "# with open(output_path, \"w\") as f:\n",
    "#     json.dump(multi_sample_qa_json, f, indent=2, default=lambda o: int(o) if hasattr(o, 'item') else o)\n",
    "\n",
    "# print(f\"✅ Final JSON saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Parameters\n",
    "k = 50\n",
    "top_bm = 100\n",
    "save_every_n = 10\n",
    "\n",
    "# Output folder and filename\n",
    "output_dir = \"../QA_Data/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_filename = f\"multi_sample_qa_info_k{k}_bm{top_bm}.json\"\n",
    "output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "# Load existing JSON file if it exists\n",
    "if os.path.exists(output_path):\n",
    "    with open(output_path, \"r\") as f:\n",
    "        multi_sample_qa_json = json.load(f)\n",
    "    print(f\"Loaded existing JSON with {len(multi_sample_qa_json)} processed samples\")\n",
    "else:\n",
    "    multi_sample_qa_json = {}\n",
    "    print(\"No existing JSON found, starting fresh\")\n",
    "\n",
    "# Load sample info data\n",
    "dti_sample_info_index = pd.read_csv('../BMG/process_data/dti_combined_samples.csv')\n",
    "dti_sample_index = pd.read_csv('../BMG/DTI_data/sample_index.csv')\n",
    "dti_sample_info_index = pd.merge(dti_sample_info_index, dti_sample_index, \n",
    "                                how='inner', left_on='depMapID', right_on='Sample').drop(columns=['Sample'])\n",
    "dti_sample_info_index = dti_sample_info_index[dti_sample_info_index['depMapID'].isin(overlapped_dti_crispr_rna_samples)].reset_index(drop=True)\n",
    "dti_sample_info_index['BMGC_Disease_name'] = dti_sample_info_index['BMGC_Disease_name'].replace(r' \\| ', ' or ', regex=True)\n",
    "\n",
    "# Get the list of samples that have already been processed\n",
    "processed_samples = set(multi_sample_qa_json.keys())\n",
    "print(f\"Found {len(processed_samples)} already processed samples\")\n",
    "\n",
    "count = len(processed_samples)\n",
    "total_to_process = len(dti_sample_info_index)\n",
    "remaining = total_to_process - count\n",
    "print(f\"Total samples to process: {total_to_process}, already processed: {count}, remaining: {remaining}\")\n",
    "\n",
    "# Iterate through the sample info dataframe, skipping already processed samples\n",
    "for idx, row_tuple in tqdm(enumerate(dti_sample_info_index.iterrows()), total=len(dti_sample_info_index)):\n",
    "    _, row = row_tuple  # Unpack the tuple - index and row data\n",
    "\n",
    "    sample_ach_name = row[\"depMapID\"]\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if sample_ach_name in processed_samples:\n",
    "        continue\n",
    "        \n",
    "    count += 1\n",
    "    sample_dti_index = row[\"Index\"]\n",
    "    cell_line_name = row[\"Name\"]\n",
    "    disease = row[\"BMGC_Disease_name\"]\n",
    "    disease_bmgc_id = row[\"BMGC_Disease_ID\"]\n",
    "\n",
    "    print(f\"Processing sample {count}/{total_to_process}: {sample_ach_name} ({cell_line_name})\")\n",
    "    print(f\"Sample DTI Index: {sample_dti_index}\")\n",
    "    print(f\"Sample Disease: {disease}\")\n",
    "    print(f\"Sample Disease BMGC ID: {disease_bmgc_id}\")\n",
    "\n",
    "    try:\n",
    "        (top_k_gene_hgnc, top_k_gene_bmgc, top_k_gene_llm,\n",
    "        top_k_ts_hgnc, top_k_ts_bmgc, top_k_ts_llm,\n",
    "        top_k_pt_hgnc, top_k_pt_bmgc, top_k_pt_llm,\n",
    "        dis_pt_idx, dis_pt_bmgc, ppi_idx, ppi_bmgc,\n",
    "        dis_pt_hgnc_dict, dis_pt_hgnc, ppi_hgnc_dict, ppi_hgnc, relationship_texts,\n",
    "        ans_hgnc, ans_bmgc, ans_llm) = qa_sample_info(sample_ach_name, disease_bmgc_id, k=k, top_bm=top_bm)\n",
    "\n",
    "        multi_sample_qa_json[sample_ach_name] = {\n",
    "            \"cell_line_name\": cell_line_name,\n",
    "            \"sample_dti_index\": sample_dti_index,\n",
    "            \"disease\": disease,\n",
    "            \"disease_bmgc_id\": disease_bmgc_id,\n",
    "            \"input\": {\n",
    "                \"top_k_gene\": {\n",
    "                    \"hgnc_symbols\": top_k_gene_hgnc,\n",
    "                    \"protein_bmgc_ids\": top_k_gene_bmgc,\n",
    "                    \"protein_llmname_ids\": top_k_gene_llm\n",
    "                },\n",
    "                \"top_k_transcript\": {\n",
    "                    \"hgnc_symbols\": top_k_ts_hgnc,\n",
    "                    \"protein_bmgc_ids\": top_k_ts_bmgc,\n",
    "                    \"protein_llmname_ids\": top_k_ts_llm\n",
    "                },\n",
    "                \"top_k_protein\": {\n",
    "                    \"hgnc_symbols\": top_k_pt_hgnc,\n",
    "                    \"protein_bmgc_ids\": top_k_pt_bmgc,\n",
    "                    \"protein_llmname_ids\": top_k_pt_llm\n",
    "                },\n",
    "                \"knowledge_graph\": {\n",
    "                    \"disease_protein\": {\n",
    "                        \"bmgc_ids\": dis_pt_bmgc,\n",
    "                        \"hgnc_symbols\": dis_pt_hgnc,\n",
    "                        \"indices\": dis_pt_idx\n",
    "                    },\n",
    "                    \"ppi_neighbors\": {\n",
    "                        \"bmgc_ids\": ppi_bmgc,\n",
    "                        \"hgnc_symbols\": ppi_hgnc,\n",
    "                        \"indices\": ppi_idx\n",
    "                    },\n",
    "                    \"protein_relationships\": relationship_texts,\n",
    "                }\n",
    "            },\n",
    "            \"ground_truth_answer\": {\n",
    "                \"top_bm_gene\": {\n",
    "                    \"hgnc_symbols\": ans_hgnc,\n",
    "                    \"protein_bmgc_ids\": ans_bmgc,\n",
    "                    \"protein_llmname_ids\": ans_llm\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {sample_ach_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Periodic save every N samples\n",
    "    if count % save_every_n == 0:\n",
    "        with open(output_path, \"w\") as f:\n",
    "            json.dump(multi_sample_qa_json, f, indent=2, default=lambda o: int(o) if hasattr(o, 'item') else o)\n",
    "        print(f\"💾 Auto-saved JSON at {count}/{total_to_process} samples to: {output_path}\")\n",
    "        print(f\"Last processed sample: {sample_ach_name}\")\n",
    "        processed = len(multi_sample_qa_json)\n",
    "        remaining = total_to_process - processed\n",
    "        print(f\"Progress: {processed}/{total_to_process} ({processed/total_to_process*100:.1f}%), Remaining: {remaining}\")\n",
    "\n",
    "# Final save after loop\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(multi_sample_qa_json, f, indent=2, default=lambda o: int(o) if hasattr(o, 'item') else o)\n",
    "\n",
    "print(f\"✅ Final JSON saved to: {output_path}\")\n",
    "print(f\"Total samples processed: {len(multi_sample_qa_json)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make up the sample_dti_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSON file\n",
    "input_path = \"../QA_Data/multi_sample_qa_info_k100_bm100.json\"\n",
    "with open(input_path, \"r\") as f:\n",
    "    multi_sample_qa_json = json.load(f)\n",
    "\n",
    "print(f\"Loaded JSON with {len(multi_sample_qa_json)} samples\")\n",
    "\n",
    "# Load sample info data with correct index mapping\n",
    "dti_sample_info_index = pd.read_csv('../BMG/process_data/dti_combined_samples.csv')\n",
    "dti_sample_index = pd.read_csv('../BMG/DTI_data/sample_index.csv')\n",
    "dti_sample_info_index = pd.merge(dti_sample_info_index, dti_sample_index, \n",
    "                               how='inner', left_on='depMapID', right_on='Sample').drop(columns=['Sample'])\n",
    "\n",
    "# Create a mapping from sample ID to index\n",
    "sample_to_index_map = dict(zip(dti_sample_info_index['depMapID'], dti_sample_info_index['Index']))\n",
    "\n",
    "# Update each sample's index in the JSON\n",
    "updated_count = 0\n",
    "for sample_ach_name in multi_sample_qa_json.keys():\n",
    "    if sample_ach_name in sample_to_index_map:\n",
    "        # Get the correct index from our mapping\n",
    "        sample_dti_index = sample_to_index_map[sample_ach_name]\n",
    "        \n",
    "        # Update the index in the JSON\n",
    "        old_index = multi_sample_qa_json[sample_ach_name][\"sample_dti_index\"]\n",
    "        multi_sample_qa_json[sample_ach_name][\"sample_dti_index\"] = int(sample_dti_index)\n",
    "        \n",
    "        # Track changes\n",
    "        if old_index != int(sample_dti_index):\n",
    "            updated_count += 1\n",
    "            print(f\"Updated {sample_ach_name}: {old_index} -> {sample_dti_index}\")\n",
    "    else:\n",
    "        print(f\"Warning: Sample {sample_ach_name} not found in index mapping\")\n",
    "\n",
    "print(f\"Updated {updated_count} sample indices\")\n",
    "\n",
    "# Save the updated JSON\n",
    "output_path = \"../QA_Data/multi_sample_qa_info_k100_bm100.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(multi_sample_qa_json, f, indent=2, default=lambda o: int(o) if hasattr(o, 'item') else o)\n",
    "print(f\"Updated JSON saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 RNAi-QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2.1 RNAi Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by gene_name to average the values for filtered_rna_df\n",
    "answer_rna_df = filtered_rna_df.groupby('gene_name').mean().reset_index()\n",
    "answer_rna_df = answer_rna_df[['gene_name'] + sorted(overlapped_dti_crispr_rna_samples)].copy()\n",
    "display(answer_rna_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rna_answer(answer_rna_df, bmgc_gene_df, gene_transcript_protein_entity_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, top_bm=100):\n",
    "    # Extract the lowest top_bm values for the given sample name\n",
    "    top_bm_genes = answer_rna_df.nsmallest(top_bm, sample_ach_name)[['gene_name', sample_ach_name]]\n",
    "    # Sort the top bm genes by their values in ascending order\n",
    "    top_bm_genes = top_bm_genes.sort_values(by=sample_ach_name, ascending=True).reset_index(drop=True)\n",
    "    top_bm_gene_hgnc_name_list = top_bm_genes['gene_name'].tolist()\n",
    "    # Merge with the bmgc_gene_df to get the BioMedGraphica_Conn_ID\n",
    "    bmgc_gene_df = bmgc_gene_df[['BioMedGraphica_Conn_ID', 'HGNC_Symbol']].copy()\n",
    "    top_bm_bmgc_gene_df = pd.merge(bmgc_gene_df, top_bm_genes, left_on='HGNC_Symbol', right_on='gene_name', how='inner')\n",
    "    # Get the corresponding proteins\n",
    "    top_bm_bmgc_gene_protein_df = pd.merge(gene_transcript_protein_entity_df, top_bm_bmgc_gene_df, left_on='BMGC_GN_ID', right_on='BioMedGraphica_Conn_ID', how='inner').drop(columns=['BioMedGraphica_Conn_ID', 'gene_name'])\n",
    "    top_bm_bmgc_gene_protein_info_df = pd.merge(top_bm_bmgc_gene_protein_df, bmgc_protein_llmnameid_combined_df, left_on='BMGC_PT_ID', right_on='BioMedGraphica_Conn_ID', how='inner').drop(columns=['BioMedGraphica_Conn_ID', 'BioMedGraphica_ID', sample_ach_name])\n",
    "    top_bm_gene_protein_bmgc_id_list = top_bm_bmgc_gene_protein_info_df['BMGC_PT_ID'].tolist()\n",
    "    top_bm_gene_protein_bmgc_llmnameid_list = top_bm_bmgc_gene_protein_info_df['Names_and_IDs'].replace(r' \\| ', ' or ', regex=True).tolist()\n",
    "    return top_bm_gene_hgnc_name_list, top_bm_gene_protein_bmgc_id_list, top_bm_gene_protein_bmgc_llmnameid_list\n",
    "\n",
    "# Example usage\n",
    "sample_ach_name = 'ACH-000001'\n",
    "top_bm = 100\n",
    "bmgc_protein_llmnameid_combined_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Protein/BioMedGraphica_Conn_Protein_LLM_Name_ID_Combined.csv')\n",
    "top_bm_gene_hgnc_name_list, top_bm_gene_protein_bmgc_id_list, top_bm_gene_protein_bmgc_llmnameid_list = extract_answer(answer_rna_df, bmgc_gene_df, gene_transcript_protein_entity_df, bmgc_protein_llmnameid_combined_df, sample_ach_name, top_bm)\n",
    "print(f\"Top {top_bm} Gene HGNC Names:\", top_bm_gene_hgnc_name_list)\n",
    "print(f\"Top {top_bm} Gene Protein BMGC IDs:\", top_bm_gene_protein_bmgc_id_list)\n",
    "print(f\"Top {top_bm} Gene Protein BMGC LLM Name IDs:\", top_bm_gene_protein_bmgc_llmnameid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2.2 Formulate into json QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Output folder and filename\n",
    "output_dir = \"../QA_Data/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_filename = \"multi_sample_qa_info_k100_bm100.json\"\n",
    "input_path = os.path.join(output_dir, input_filename)\n",
    "output_filename = \"multi_sample_qa_info_rnai_k100_bm100.json\"\n",
    "output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "# Load existing JSON file\n",
    "with open(input_path, \"r\") as f:\n",
    "    multi_sample_qa_json = json.load(f)\n",
    "print(f\"Loaded JSON with {len(multi_sample_qa_json)} samples\")\n",
    "\n",
    "# Update each sample's ground truth answer with RNAi data\n",
    "updated_count = 0\n",
    "sample_count = len(multi_sample_qa_json)\n",
    "\n",
    "for i, (sample_ach_name, sample_data) in enumerate(tqdm(multi_sample_qa_json.items(), total=sample_count, desc=\"Updating samples\")):\n",
    "    try:\n",
    "        # Get RNAi-based answers using extract_rna_answer\n",
    "        ans_hgnc, ans_bmgc, ans_llm = extract_rna_answer(\n",
    "            answer_rna_df, \n",
    "            bmgc_gene_df, \n",
    "            gene_transcript_protein_entity_df, \n",
    "            bmgc_protein_llmnameid_combined_df, \n",
    "            sample_ach_name, \n",
    "            top_bm=top_bm\n",
    "        )\n",
    "        \n",
    "        # Update the ground truth answer section\n",
    "        multi_sample_qa_json[sample_ach_name][\"ground_truth_answer\"] = {\n",
    "            \"top_bm_gene\": {\n",
    "                \"hgnc_symbols\": ans_hgnc,\n",
    "                \"protein_bmgc_ids\": ans_bmgc,\n",
    "                \"protein_llmname_ids\": ans_llm\n",
    "            }\n",
    "        }\n",
    "        updated_count += 1\n",
    "        \n",
    "        # Periodic save every 20 samples\n",
    "        if (i + 1) % 20 == 0:\n",
    "            with open(output_path, \"w\") as f:\n",
    "                json.dump(multi_sample_qa_json, f, indent=2, default=lambda o: int(o) if hasattr(o, 'item') else o)\n",
    "            print(f\"Processed {i+1}/{sample_count} samples, saved intermediate results\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error updating {sample_ach_name}: {str(e)}\")\n",
    "\n",
    "# Final save\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(multi_sample_qa_json, f, indent=2, default=lambda o: int(o) if hasattr(o, 'item') else o)\n",
    "\n",
    "print(f\"✅ Final JSON saved to: {output_path}\")\n",
    "print(f\"Updated {updated_count} out of {sample_count} samples with RNAi data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. TargetRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test samples\n",
    "train_dti_crispr_rna_samples_df = pd.read_csv('../QA_Data/train_dti_crispr_rna_samples.csv')\n",
    "test_dti_crispr_rna_samples_df = pd.read_csv('../QA_Data/test_dti_crispr_rna_samples.csv')\n",
    "# display(train_dti_crispr_rna_samples_df)\n",
    "# display(test_dti_crispr_rna_samples_df)\n",
    "test_dti_crispr_rna_samples = test_dti_crispr_rna_samples_df['Sample'].tolist()\n",
    "print(f\"Test samples: {len(test_dti_crispr_rna_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_gene_expression_df = pd.read_csv('./raw_data/OmicsExpressionGenesExpectedCountProfile.csv')\n",
    "display(raw_gene_expression_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read the map dict\n",
    "# cell_line_map_dict_df = pd.read_csv('./raw_data/Model.csv')\n",
    "# display(cell_line_map_dict_df.head(15))\n",
    "# # create the map diict by columns ModelID and PatientID\n",
    "# cell_line_map_dict = dict(zip(cell_line_map_dict_df['PatientID'], cell_line_map_dict_df['ModelID']))\n",
    "# print(f\"Test cell line map dict: {cell_line_map_dict['PT-gj46wT']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read another map dict file\n",
    "profile_map_dict_df = pd.read_csv('./raw_data/OmicsProfiles.csv')\n",
    "display(profile_map_dict_df.head(15))\n",
    "# create the map dict by columns ProfileID and ModelID\n",
    "profile_map_dict = dict(zip(profile_map_dict_df['ProfileID'], profile_map_dict_df['ModelID']))\n",
    "profile_reverse_map_dict = dict(zip(profile_map_dict_df['ModelID'], profile_map_dict_df['ProfileID']))\n",
    "print(f\"Test profile map dict: {profile_map_dict['PR-AdBjpG']}\")\n",
    "print(f\"Test profile reverse map dict: {profile_reverse_map_dict['ACH-000001']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 0\n",
    "gene_expression_df = raw_gene_expression_df.fillna(0).copy()\n",
    "# Renamed the column 'Unnamed: 0' to 'Gene_Symbol'\n",
    "gene_expression_df.rename(columns={'Unnamed: 0': 'Samples'}, inplace=True)\n",
    "# Map the conetent in column ['Samples'] to their corresponding model IDs using the profile_map_dict\n",
    "gene_expression_df['Samples'] = gene_expression_df['Samples'].map(profile_map_dict)\n",
    "# Remove rows with NaN values in the 'Samples' column\n",
    "gene_expression_df = gene_expression_df[gene_expression_df['Samples'].notna()]\n",
    "\n",
    "# For the column with name in format TSPAN6 (ENSG00000000003), only keep the second part ENSG00000000003 with out the brackets \"()\"\n",
    "gene_expression_df.rename(columns=lambda x: x.split('(')[-1].split(')')[0] if '(' in x else x, inplace=True)\n",
    "# Sort the DataFrame by the 'Samples' column\n",
    "gene_expression_df = gene_expression_df.sort_values(by='Samples').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the DataFrame properly\n",
    "gene_expression_t_df = gene_expression_df.set_index(\"Samples\")\n",
    "gene_expression_t_df = gene_expression_t_df.transpose()\n",
    "\n",
    "# Reset the index and rename it to 'gene_id'\n",
    "gene_expression_t_df.reset_index(inplace=True)\n",
    "gene_expression_t_df.rename(columns={'index': 'gene_id'}, inplace=True)\n",
    "\n",
    "# Fill any NaN values with 0\n",
    "gene_expression_t_df = gene_expression_t_df.fillna(0.0)\n",
    "display(gene_expression_t_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby the gene_name and calculate the mean\n",
    "gene_expression_t_df = gene_expression_t_df.groupby('gene_id', as_index=False).mean()\n",
    "# only keep the columns in the list test_dti_crispr_rna_samples\n",
    "gene_expression_t_df = gene_expression_t_df[['gene_id'] + sorted(test_dti_crispr_rna_samples)].copy()\n",
    "display(gene_expression_t_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Make folder called \"TargetRanker\"\n",
    "os.makedirs('TargetRanker', exist_ok=True)\n",
    "# Save the gene_df to a csv file in the TargetRanker folder\n",
    "gene_expression_t_df.to_csv('./TargetRanker/depmap_test_gene_expression.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./TargetRanker/samples', exist_ok=True)\n",
    "for sample in gene_expression_t_df.columns[1:]:\n",
    "    # Create a new DataFrame for each sample\n",
    "    sample_df = gene_expression_t_df[['gene_id', sample]].copy()\n",
    "    # Convert integer-like floats to integers\n",
    "    sample_df[sample] = sample_df[sample].apply(lambda x: int(x) if x == int(x) else x)\n",
    "    # Set gene_id as index\n",
    "    sample_df.set_index('gene_id', inplace=True)\n",
    "    # Save with tab delimiter and correct format\n",
    "    with open(f'./TargetRanker/samples/{sample}.tsv', 'w') as f:\n",
    "        f.write(f'\\t{sample}\\n')  # Write header with tab prefix\n",
    "        # Use to_csv with sep='\\t' but don't include a newline at the end of each line\n",
    "        sample_df.to_csv(f, sep='\\t', header=False, lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separate the samples by TCGA code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dti_combined_samples_df = pd.read_csv('./process_data/dti_combined_samples.csv')\n",
    "test_dti_crispr_rna_samples_df = pd.read_csv('./CRISPR-Graph/test_dti_crispr_rna_samples_index.csv')\n",
    "test_dti_crispr_rna_samples_info_df = pd.merge(test_dti_crispr_rna_samples_df, dti_combined_samples_df, how='inner', left_on='Sample', right_on='depMapID').drop(columns=['depMapID'])\n",
    "display(test_dti_crispr_rna_samples_info_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs('./TargetRanker/TCGA_Samples', exist_ok=True)\n",
    "\n",
    "# Group by TCGA code and process each group\n",
    "for tcga_code, group in test_dti_crispr_rna_samples_info_df.groupby('tcga_code'):\n",
    "    if pd.isna(tcga_code):\n",
    "        print(f\"Skipping samples with missing TCGA code\")\n",
    "        continue\n",
    "        \n",
    "    # Get samples for this TCGA code\n",
    "    tcga_samples = group['Sample'].tolist()\n",
    "    print(f\"Processing TCGA code {tcga_code} with {len(tcga_samples)} samples\")\n",
    "    \n",
    "    # Filter gene expression data for these samples\n",
    "    # Make sure to include the gene_id column\n",
    "    sample_tcga_df = gene_expression_t_df[['gene_id'] + tcga_samples]\n",
    "    \n",
    "    # Create a meaningful filename\n",
    "    # if tcga_code contains string \"/\", replace it with \"_\"\n",
    "    tcga_code = tcga_code.replace(\"/\", \"_\")\n",
    "    # Save the data as TSV\n",
    "    output_filename = f\"./TargetRanker/TCGA_Samples/sample_{tcga_code}_{len(tcga_samples)}.tsv\"\n",
    "    sample_tcga_df.to_csv(output_filename, index=False, sep='\\t')\n",
    "    print(f\"Saved {len(sample_tcga_df)} gene expressions for {len(tcga_samples)} samples to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Graph CRISPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 CRISPR train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dti_crispr_rna_samples_df = pd.read_csv('../QA_Data/train_dti_crispr_rna_samples.csv')\n",
    "# display(train_dti_crispr_rna_samples_df)\n",
    "test_dti_crispr_rna_samples_df = pd.read_csv('../QA_Data/test_dti_crispr_rna_samples.csv')\n",
    "# display(test_dti_crispr_rna_samples_df)\n",
    "dti_crispr_rna_samples_df = pd.concat([train_dti_crispr_rna_samples_df, test_dti_crispr_rna_samples_df], axis=0).reset_index(drop=True)\n",
    "dti_crispr_rna_samples_df = dti_crispr_rna_samples_df.sort_values(by='Sample').reset_index(drop=True)\n",
    "display(dti_crispr_rna_samples_df)\n",
    "# Convert dti_crispr_rna_samples_df to a dataframe with another column called Index ranging from 0 to len(dti_crispr_rna_samples_df)-1\n",
    "dti_crispr_rna_samples_df['Index'] = dti_crispr_rna_samples_df.index\n",
    "# Save the dti_crispr_rna_samples_df to a csv file in the TargetRanker folder\n",
    "dti_crispr_rna_samples_df.to_csv('./CRISPR-Graph/dti_crispr_rna_sample_index.csv', index=False)\n",
    "display(dti_crispr_rna_samples_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the omics data by index\n",
    "dti_crispr_rna_sample_index = pd.read_csv('./CRISPR-Graph/dti_crispr_rna_sample_index.csv')\n",
    "display(dti_crispr_rna_sample_index)\n",
    "pretrain_sample_index = pd.read_csv('./Pretrain_data/sample_index.csv')\n",
    "# rename the column Index to Pre_Index in pretrain_sample_index\n",
    "pretrain_sample_index.rename(columns={'Index': 'Pre_Index'}, inplace=True)\n",
    "# Merge dti_sample_index with dti_crispr_rna_sample_index on Sample column\n",
    "dti_crispr_rna_sample_index = pd.merge(dti_crispr_rna_sample_index, pretrain_sample_index, how='inner', on='Sample')\n",
    "\n",
    "# Merge pretrain_sample_index_df with train_dti_crispr_rna_samples_df and test_dti_crispr_rna_samples_df\n",
    "train_dti_crispr_rna_samples_index_df = pd.merge(train_dti_crispr_rna_samples_df, dti_crispr_rna_sample_index, how='inner', on='Sample')\n",
    "train_dti_crispr_rna_samples_index_df = train_dti_crispr_rna_samples_index_df.sort_values(by='Pre_Index').reset_index(drop=True)\n",
    "train_dti_crispr_rna_samples_index_list = train_dti_crispr_rna_samples_index_df['Pre_Index'].tolist()\n",
    "test_dti_crispr_rna_samples_index_df = pd.merge(test_dti_crispr_rna_samples_df, dti_crispr_rna_sample_index, how='inner', on='Sample')\n",
    "test_dti_crispr_rna_samples_index_df = test_dti_crispr_rna_samples_index_df.sort_values(by='Index').reset_index(drop=True)\n",
    "test_dti_crispr_rna_samples_index_list = test_dti_crispr_rna_samples_index_df['Pre_Index'].tolist()\n",
    "dti_crispr_rna_samples_index_df = dti_crispr_rna_sample_index.copy()\n",
    "dti_crispr_rna_samples_index_list = dti_crispr_rna_samples_index_df['Pre_Index'].tolist()\n",
    "\n",
    "\n",
    "pretrain_bmgc_omics_array_T = np.load('./Pretrain_data/pretrain_bmgc_omics.npy')\n",
    "print(f\"Pretrain omics data shape: {pretrain_bmgc_omics_array_T.shape}\")\n",
    "# Convert train_dti_crispr_rna_samples_index_list and test_dti_crispr_rna_samples_index_list into numpy array\n",
    "train_dti_crispr_rna_samples_index_array =  np.array(train_dti_crispr_rna_samples_index_list)\n",
    "test_dti_crispr_rna_samples_index_array =  np.array(test_dti_crispr_rna_samples_index_list)\n",
    "dti_crispr_rna_samples_index_array =  np.array(dti_crispr_rna_samples_index_list)\n",
    "# Select the omics data by index\n",
    "dti_train_crispr_rna_samples_omics_array = pretrain_bmgc_omics_array_T[train_dti_crispr_rna_samples_index_array, :]\n",
    "print(f\"Train crispr omics data shape: {dti_train_crispr_rna_samples_omics_array.shape}\")\n",
    "dti_test_crispr_rna_samples_omics_array = pretrain_bmgc_omics_array_T[test_dti_crispr_rna_samples_index_array, :]\n",
    "print(f\"Test crispr omics data shape: {dti_test_crispr_rna_samples_omics_array.shape}\")\n",
    "dti_crispr_rna_samples_omics_array = pretrain_bmgc_omics_array_T[dti_crispr_rna_samples_index_array, :]\n",
    "print(f\"All crispr omics data shape: {dti_crispr_rna_samples_omics_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make folder called \"CRISPR-Graph\"\n",
    "os.makedirs('CRISPR-Graph', exist_ok=True)\n",
    "# Save train_dti_crispr_rna_samples_index_df to a csv file in the CRISPR-Graph folder\n",
    "train_dti_crispr_rna_samples_index_df.to_csv('./CRISPR-Graph/train_dti_crispr_rna_samples_index.csv', index=False)\n",
    "# Save test_dti_crispr_rna_samples_index_df to a csv file in the CRISPR-Graph folder\n",
    "test_dti_crispr_rna_samples_index_df.to_csv('./CRISPR-Graph/test_dti_crispr_rna_samples_index.csv', index=False)\n",
    "# Save dti_crispr_rna_samples_index_df to a csv file in the CRISPR-Graph folder\n",
    "dti_crispr_rna_samples_index_df.to_csv('./CRISPR-Graph/dti_crispr_rna_samples_index.csv', index=False)\n",
    "\n",
    "# Save dti_crispr_rna_samples_omics_array to a numpy file in the CRISPR-Graph folder\n",
    "np.save('./CRISPR-Graph/dti_train_crispr_rna_samples_omics.npy', dti_train_crispr_rna_samples_omics_array)\n",
    "np.save('./CRISPR-Graph/dti_test_crispr_rna_samples_omics.npy', dti_test_crispr_rna_samples_omics_array)\n",
    "np.save('./CRISPR-Graph/dti_crispr_rna_samples_omics.npy', dti_crispr_rna_samples_omics_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 CRISPR node and edge information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omics_nodes_index_data_df = pd.read_csv('./Pretrain_data/omics_nodes_index.csv')\n",
    "display(omics_nodes_index_data_df.head(5))\n",
    "# Save the omics_nodes_index_data_df to a csv file in the CRISPR-Graph folder\n",
    "omics_nodes_index_data_df.to_csv('./CRISPR-Graph/omics_nodes_index.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create omics_node_index_dict\n",
    "omics_node_index_dict = dict(zip(omics_nodes_index_data_df['Node'], omics_nodes_index_data_df['Index']))\n",
    "print(f\"Omics node index dict: {omics_node_index_dict['BMGC_PM00001']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmgc_relation_df = pd.read_csv('./BioMedGraphica-Conn/Relation/BioMedGraphica_Conn_Relation.csv')\n",
    "# filter our the rows with Relation type in the list ['Promoter-Gene', 'Gene-Transcript', 'Transcript-Protein', 'Protein-Protein']\n",
    "bmgc_omics_relation_df = bmgc_relation_df[bmgc_relation_df['Type'].isin(['Promoter-Gene', 'Gene-Transcript', 'Transcript-Protein', 'Protein-Protein'])].reset_index(drop=True)\n",
    "# check if there is any null values in the bmgc_omics_relation_df\n",
    "print(bmgc_omics_relation_df.isnull().sum())\n",
    "display(bmgc_omics_relation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the bmgc_omics_relation_df to numpy array and save it to the Pretrain_data folder as the edge_index.npy\n",
    "# Keep the columns ['BMGC_From_ID', 'BMGC_To_ID']\n",
    "edge_index_df = bmgc_omics_relation_df[['BMGC_From_ID', 'BMGC_To_ID']].copy()\n",
    "\n",
    "# Map the BMGC_From_ID and BMGC_To_ID by the omics_node_index_dict\n",
    "edge_index_df['BMGC_From_ID'] = edge_index_df['BMGC_From_ID'].map(omics_node_index_dict)\n",
    "edge_index_df['BMGC_To_ID'] = edge_index_df['BMGC_To_ID'].map(omics_node_index_dict)\n",
    "\n",
    "# check the null values in the edge_index_df\n",
    "print(\"Null values in edge_index_df:\")\n",
    "print(edge_index_df.isnull().sum())\n",
    "# print the rows with null values in column BMGC_From_ID the edge_index_df\n",
    "print(edge_index_df[edge_index_df['BMGC_From_ID'].isnull()])\n",
    "display(edge_index_df)\n",
    "# convert the edge_index_df to numpy array and save it to the Pretrain_data folder\n",
    "edge_index_array = edge_index_df.to_numpy().T\n",
    "print('The shape of edge_index_array is:', edge_index_array.shape)\n",
    "print(edge_index_array[:10])  # Print first 10 rows as a sample\n",
    "# save the numpy array to the Pretrain_data folder\n",
    "np.save('./CRISPR-Graph/edge_index.npy', edge_index_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the internal_edge_index by Type belongs to ['Promoter-Gene', 'Gene-Transcript', 'Transcript-Protein']\n",
    "internal_edge_index_df = bmgc_omics_relation_df[bmgc_omics_relation_df['Type'].isin(['Promoter-Gene', 'Gene-Transcript', 'Transcript-Protein'])].reset_index(drop=True)\n",
    "internal_edge_index_df = internal_edge_index_df[['BMGC_From_ID', 'BMGC_To_ID']].copy()\n",
    "# Map the BMGC_From_ID and BMGC_To_ID by the node_index_dict\n",
    "internal_edge_index_df['BMGC_From_ID'] = internal_edge_index_df['BMGC_From_ID'].map(node_index_dict)\n",
    "internal_edge_index_df['BMGC_To_ID'] = internal_edge_index_df['BMGC_To_ID'].map(node_index_dict)\n",
    "display(internal_edge_index_df)\n",
    "# convert the internal_edge_index_df to numpy array and save it to the Pretrain_data folder\n",
    "internal_edge_index_array = internal_edge_index_df.to_numpy().T\n",
    "print('The shape of internal_edge_index_array is:', internal_edge_index_array.shape)\n",
    "print(internal_edge_index_array[:10])  # Print first 10 rows as a sample\n",
    "# save the numpy array to the Pretrain_data folder\n",
    "np.save('./CRISPR-Graph/internal_edge_index.npy', internal_edge_index_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the ppi_edge_index by selecting bmgc_relation_df in Type ['Protein-Protein']\n",
    "ppi_edge_index_df = bmgc_relation_df[bmgc_relation_df['Type'].isin(['Protein-Protein'])].copy()\n",
    "# keep the columns ['BMGC_From_ID', 'BMGC_To_ID']\n",
    "ppi_edge_index_df = ppi_edge_index_df[['BMGC_From_ID', 'BMGC_To_ID']].copy()\n",
    "# Map the BMGC_From_ID and BMGC_To_ID by the node_index_dict\n",
    "ppi_edge_index_df['BMGC_From_ID'] = ppi_edge_index_df['BMGC_From_ID'].map(node_index_dict)\n",
    "ppi_edge_index_df['BMGC_To_ID'] = ppi_edge_index_df['BMGC_To_ID'].map(node_index_dict)\n",
    "# check the null values in the ppi_edge_index_df\n",
    "print(\"Null values in ppi_edge_index_df:\")\n",
    "print(ppi_edge_index_df.isnull().sum())\n",
    "# convert the ppi_edge_index_df to numpy array and save it to the DTI_data folder\n",
    "ppi_edge_index_array = ppi_edge_index_df.to_numpy().T\n",
    "print('The shape of ppi_edge_index_array is:', ppi_edge_index_array.shape)\n",
    "print(ppi_edge_index_array)\n",
    "# save the numpy array to the DTI_data folder\n",
    "np.save('./CRISPR-Graph/ppi_edge_index.npy', ppi_edge_index_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3 CRISPR label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.3.1 Build up internal relation for KO drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmgc_promoter_gene_df = bmgc_omics_relation_df[bmgc_omics_relation_df['Type'] == 'Promoter-Gene'].drop(columns=['Type'])\n",
    "bmgc_gene_transcript_df = bmgc_omics_relation_df[bmgc_omics_relation_df['Type'] == 'Gene-Transcript'].drop(columns=['Type'])\n",
    "bmgc_transcript_protein_df = bmgc_omics_relation_df[bmgc_omics_relation_df['Type'] == 'Transcript-Protein'].drop(columns=['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "bmgc_promoter_gene_df.rename(columns={'BMGC_From_ID':'promoterID','BMGC_To_ID':'geneID'}, inplace=True)\n",
    "bmgc_gene_transcript_df.rename(columns={'BMGC_From_ID':'geneID','BMGC_To_ID':'transcriptID'}, inplace=True)\n",
    "bmgc_transcript_protein_df.rename(columns={'BMGC_From_ID':'transcriptID','BMGC_To_ID':'proteinID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge gene_transcript and transcript_protein dataframes\n",
    "bmgc_gene_transcript_protein_df = bmgc_transcript_protein_df.merge(bmgc_gene_transcript_df, on='transcriptID',how='outer')\n",
    "display(bmgc_gene_transcript_protein_df)\n",
    "# Merge promoter\n",
    "bmgc_promoter_gene_transcript_protein_df = bmgc_gene_transcript_protein_df.merge(bmgc_promoter_gene_df, on='geneID',how='outer')\n",
    "display(bmgc_promoter_gene_transcript_protein_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_relation_df = bmgc_promoter_gene_transcript_protein_df.dropna(subset=['geneID'])\n",
    "internal_relation_df = internal_relation_df[['promoterID', 'geneID', 'transcriptID', 'proteinID']].copy()\n",
    "display(internal_relation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.3.2 Build up label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_crispr_df = pd.read_csv('./raw_data/CRISPRGeneEffect.csv')\n",
    "# get the column names of the raw_crispr_df aside from the first column and convert this to a list\n",
    "first_column_name = raw_crispr_df.columns[0]\n",
    "raw_crispr_df.rename(columns={first_column_name: 'Sample'}, inplace=True)\n",
    "display(raw_crispr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dti_crispr_rna_samples_index_df = pd.read_csv('./CRISPR-Graph/train_dti_crispr_rna_samples_index.csv')\n",
    "#display(train_dti_crispr_rna_samples_df)\n",
    "test_dti_crispr_rna_samples_index_df = pd.read_csv('./CRISPR-Graph/test_dti_crispr_rna_samples_index.csv')\n",
    "#display(test_dti_crispr_rna_samples_df)\n",
    "train_crispr_score_df = raw_crispr_df.merge(train_dti_crispr_rna_samples_index_df, on=\"Sample\", how=\"inner\").drop(columns=['Index', 'Pre_Index'])\n",
    "# display(train_crispr_score_df)\n",
    "test_crispr_score_df = raw_crispr_df.merge(test_dti_crispr_rna_samples_index_df, on=\"Sample\", how=\"inner\").drop(columns=['Index', 'Pre_Index'])\n",
    "# display(test_crispr_score_df)\n",
    "\n",
    "# Set Index column to str to keep digit without .00\n",
    "train_crispr_score_t_df = train_crispr_score_df.set_index(\"Sample\").T.reset_index()\n",
    "train_crispr_score_t_df.rename(columns={\"index\": \"HGNC_Symbol\"}, inplace=True)\n",
    "display(train_crispr_score_t_df)\n",
    "test_crispr_score_t_df = test_crispr_score_df.set_index(\"Sample\").T.reset_index()\n",
    "test_crispr_score_t_df.rename(columns={\"index\": \"HGNC_Symbol\"}, inplace=True)\n",
    "display(test_crispr_score_t_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the statistics of the train_crispr_score_t_df and test_crispr_score_t_df\n",
    "print(\"Train CRISPR score statistics:\")\n",
    "print(train_crispr_score_t_df.describe())\n",
    "print(\"Test CRISPR score statistics:\")\n",
    "print(test_crispr_score_t_df.describe())\n",
    "\n",
    "# Normalize the train_crispr_score_t_df and test_crispr_score_t_df by Z-score over each column\n",
    "train_crispr_score_t_df.iloc[:, 1:] = (train_crispr_score_t_df.iloc[:, 1:] - train_crispr_score_t_df.iloc[:, 1:].mean()) / train_crispr_score_t_df.iloc[:, 1:].std()\n",
    "test_crispr_score_t_df.iloc[:, 1:] = (test_crispr_score_t_df.iloc[:, 1:] - test_crispr_score_t_df.iloc[:, 1:].mean()) / test_crispr_score_t_df.iloc[:, 1:].std()\n",
    "# Recheck the statistics of the train_crispr_score_t_df and test_crispr_score_t_df\n",
    "print(\"Train CRISPR score statistics after normalization:\")\n",
    "print(train_crispr_score_t_df.describe())\n",
    "print(\"Test CRISPR score statistics after normalization:\")\n",
    "print(test_crispr_score_t_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmgc_gene_df = pd.read_csv('./BioMedGraphica-Conn/Entity/Gene/BioMedGraphica_Conn_Gene.csv')\n",
    "\n",
    "import re\n",
    "def extract_gene_name(gene):\n",
    "    return re.sub(r\"\\s*\\(.*?\\)\", \"\", str(gene))\n",
    "\n",
    "train_crispr_score_t_df[\"HGNC_Symbol\"] = train_crispr_score_t_df[\"HGNC_Symbol\"].apply(extract_gene_name)\n",
    "\n",
    "unique_Gene_map = bmgc_gene_df[['HGNC_Symbol']].drop_duplicates()\n",
    "unique_omics_Gene = train_crispr_score_t_df[['HGNC_Symbol']].drop_duplicates()\n",
    "# match\n",
    "intersection = set(unique_Gene_map['HGNC_Symbol'])&set(unique_omics_Gene['HGNC_Symbol'])\n",
    "total_Gene = len(unique_Gene_map)\n",
    "\n",
    "match_rate = len(intersection) / total_Gene if total_Gene > 0 else 0\n",
    "#####\n",
    "\n",
    "print(f\"match rate:{match_rate:.2%}\")\n",
    "\n",
    "train_crispr_score_bmgc_df = bmgc_gene_df.merge(train_crispr_score_t_df, on=\"HGNC_Symbol\", how=\"inner\")\n",
    "\n",
    "train_crispr_score_bmgc_df = train_crispr_score_bmgc_df.drop(columns=['BioMedGraphica_ID','NCBI_Gene_ID','Ensembl_Gene_ID_Version','Gene_Start', 'Gene_End','Chromosome','Gene_Type','Ensembl_Gene_ID','HGNC_ID','Gene_Name','RefSeq_ID','OMIM_ID','HGNC_Symbol'])\n",
    "\n",
    "display(train_crispr_score_bmgc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_crispr_score_t_df[\"HGNC_Symbol\"] = test_crispr_score_t_df[\"HGNC_Symbol\"].apply(extract_gene_name)\n",
    "\n",
    "unique_Gene_map = bmgc_gene_df[['HGNC_Symbol']].drop_duplicates()\n",
    "unique_omics_Gene = test_crispr_score_t_df[['HGNC_Symbol']].drop_duplicates()\n",
    "# match\n",
    "intersection = set(unique_Gene_map['HGNC_Symbol'])&set(unique_omics_Gene['HGNC_Symbol'])\n",
    "total_Gene = len(unique_Gene_map)\n",
    "\n",
    "match_rate = len(intersection) / total_Gene if total_Gene > 0 else 0\n",
    "#####\n",
    "\n",
    "print(f\"match rate:{match_rate:.2%}\")\n",
    "\n",
    "test_crispr_score_bmgc_df = bmgc_gene_df.merge(test_crispr_score_t_df, on=\"HGNC_Symbol\", how=\"inner\")\n",
    "\n",
    "test_crispr_score_bmgc_df = test_crispr_score_bmgc_df.drop(columns=['BioMedGraphica_ID','NCBI_Gene_ID','Ensembl_Gene_ID_Version','Gene_Start', 'Gene_End','Chromosome','Gene_Type','Ensembl_Gene_ID','HGNC_ID','Gene_Name','RefSeq_ID','OMIM_ID','HGNC_Symbol'])\n",
    "\n",
    "display(test_crispr_score_bmgc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crispr_score_label = train_crispr_score_bmgc_df.copy()\n",
    "train_crispr_score_label_melted = train_crispr_score_label.melt(id_vars=[\"BioMedGraphica_Conn_ID\"], var_name=\"ACH_ID\", value_name=\"Value\")\n",
    "train_crispr_score_label_melted = train_crispr_score_label_melted.dropna(subset=['Value'])\n",
    "display(train_crispr_score_label_melted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_crispr_score_label = test_crispr_score_bmgc_df.copy()\n",
    "test_crispr_score_label_melted = test_crispr_score_label.melt(id_vars=[\"BioMedGraphica_Conn_ID\"], var_name=\"ACH_ID\", value_name=\"Value\")\n",
    "test_crispr_score_label_melted = test_crispr_score_label_melted.dropna(subset=['Value'])\n",
    "display(test_crispr_score_label_melted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge into internal relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data into the index to fetch\n",
    "# Based on dti_sample_index, convert this to a dict\n",
    "crispr_sample_index_dict = dict(zip(dti_crispr_rna_sample_index['Sample'], dti_crispr_rna_sample_index['Index']))\n",
    "# Based on omics_nodes_index_data_df, convert this to a dict\n",
    "omics_nodes_index_dict = dict(zip(omics_nodes_index_data_df['Node'], omics_nodes_index_data_df['Index']))\n",
    "\n",
    "# Map columns ['ACH_ID', 'BioMedGraphica_Conn_ID'] by the crispr_sample_index_dict and omics_nodes_index_dict\n",
    "train_crispr_score_label_melted['ACH_ID'] = train_crispr_score_label_melted['ACH_ID'].map(crispr_sample_index_dict)\n",
    "train_crispr_score_label_melted['BioMedGraphica_Conn_ID'] = train_crispr_score_label_melted['BioMedGraphica_Conn_ID'].map(omics_nodes_index_dict)\n",
    "test_crispr_score_label_melted['ACH_ID'] = test_crispr_score_label_melted['ACH_ID'].map(crispr_sample_index_dict)\n",
    "test_crispr_score_label_melted['BioMedGraphica_Conn_ID'] = test_crispr_score_label_melted['BioMedGraphica_Conn_ID'].map(omics_nodes_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map internal_relation_df columns ['promoterID', 'geneID', 'transcriptID', 'proteinID'] by the omics_nodes_index_dict\n",
    "internal_relation_map_df = internal_relation_df.copy()\n",
    "internal_relation_map_df['promoterID'] = internal_relation_map_df['promoterID'].map(omics_nodes_index_dict)\n",
    "internal_relation_map_df['geneID'] = internal_relation_map_df['geneID'].map(omics_nodes_index_dict)\n",
    "internal_relation_map_df['transcriptID'] = internal_relation_map_df['transcriptID'].map(omics_nodes_index_dict)\n",
    "internal_relation_map_df['proteinID'] = internal_relation_map_df['proteinID'].map(omics_nodes_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_internal_relation_map_df = internal_relation_map_df.copy()\n",
    "display(ko_internal_relation_map_df)\n",
    "ko_internal_relation_index_df = ko_internal_relation_map_df.groupby([\"promoterID\", \"geneID\"], as_index=False).agg({\n",
    "    \"transcriptID\": lambda x: list(set(x.dropna())), \n",
    "    \"proteinID\": lambda x: list(set(x.dropna()))  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove .0 suffix from numbers in lists\n",
    "def remove_decimal_suffix(list_with_decimals):\n",
    "    if isinstance(list_with_decimals, list):\n",
    "        return [int(x) if not pd.isna(x) else x for x in list_with_decimals]\n",
    "    return list_with_decimals\n",
    "\n",
    "# Apply the function to both columns\n",
    "ko_internal_relation_index_df['transcriptID'] = ko_internal_relation_index_df['transcriptID'].apply(remove_decimal_suffix)\n",
    "ko_internal_relation_index_df['proteinID'] = ko_internal_relation_index_df['proteinID'].apply(remove_decimal_suffix)\n",
    "\n",
    "# Display the result to verify\n",
    "display(ko_internal_relation_index_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crispr_score_label_melted_ko = train_crispr_score_label_melted.merge(ko_internal_relation_index_df, left_on='BioMedGraphica_Conn_ID',right_on='geneID' ,how='left')\n",
    "train_crispr_score_label_melted_ko = train_crispr_score_label_melted_ko.drop(columns=['BioMedGraphica_Conn_ID'])\n",
    "display(train_crispr_score_label_melted_ko)\n",
    "\n",
    "# Create a new column 'merged_ids' by combining the columns into lists\n",
    "train_crispr_score_label_melted_ko['merged_ids'] = train_crispr_score_label_melted_ko.apply(\n",
    "    lambda row: [row['promoterID'], row['geneID']] + \n",
    "                (row['transcriptID'] if isinstance(row['transcriptID'], list) else []) +\n",
    "                (row['proteinID'] if isinstance(row['proteinID'], list) else []),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "train_crispr_score_label_melted_ko = train_crispr_score_label_melted_ko.drop(columns=['promoterID', 'geneID', 'transcriptID', 'proteinID'])\n",
    "display(train_crispr_score_label_melted_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the columns to ['ACH_ID', 'merged_ids', 'Value']\n",
    "train_crispr_score_label_melted_ko = train_crispr_score_label_melted_ko[['ACH_ID', 'merged_ids', 'Value']].copy()\n",
    "display(train_crispr_score_label_melted_ko)\n",
    "# Convert train_crispr_score_label_melted_ko to numpy array and save it to the CRISPR-Graph folder\n",
    "train_crispr_score_label_melted_ko_array = train_crispr_score_label_melted_ko.to_numpy()\n",
    "print('The shape of train_crispr_score_label_melted_ko_array is:', train_crispr_score_label_melted_ko_array.shape)\n",
    "print(train_crispr_score_label_melted_ko_array[:10])  # Print first 10 rows as a sample\n",
    "# Save the numpy array to the CRISPR-Graph folder\n",
    "np.save('./CRISPR-Graph/train_crispr_score.npy', train_crispr_score_label_melted_ko_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_crispr_score_label_melted_ko = test_crispr_score_label_melted.merge(ko_internal_relation_index_df, left_on='BioMedGraphica_Conn_ID',right_on='geneID' ,how='left')\n",
    "test_crispr_score_label_melted_ko = test_crispr_score_label_melted_ko.drop(columns=['BioMedGraphica_Conn_ID'])\n",
    "display(test_crispr_score_label_melted_ko)\n",
    "\n",
    "# Create a new column 'merged_ids' by combining the columns into lists\n",
    "test_crispr_score_label_melted_ko['merged_ids'] = test_crispr_score_label_melted_ko.apply(\n",
    "    lambda row: [row['promoterID'], row['geneID']] + \n",
    "                (row['transcriptID'] if isinstance(row['transcriptID'], list) else []) +\n",
    "                (row['proteinID'] if isinstance(row['proteinID'], list) else []),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "test_crispr_score_label_melted_ko = test_crispr_score_label_melted_ko.drop(columns=['promoterID', 'geneID', 'transcriptID', 'proteinID'])\n",
    "display(test_crispr_score_label_melted_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the columns to ['ACH_ID', 'merged_ids', 'Value']\n",
    "test_crispr_score_label_melted_ko = test_crispr_score_label_melted_ko[['ACH_ID', 'merged_ids', 'Value']].copy()\n",
    "display(test_crispr_score_label_melted_ko)\n",
    "# Convert test_crispr_score_label_melted_ko to numpy array and save it to the CRISPR-Graph folder\n",
    "test_crispr_score_label_melted_ko_array = test_crispr_score_label_melted_ko.to_numpy()\n",
    "print('The shape of test_crispr_score_label_melted_ko_array is:', test_crispr_score_label_melted_ko_array.shape)\n",
    "print(test_crispr_score_label_melted_ko_array[:10])  # Print first 10 rows as a sample\n",
    "# Save the numpy array to the CRISPR-Graph folder\n",
    "np.save('./CRISPR-Graph/test_crispr_score.npy', test_crispr_score_label_melted_ko_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mkg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
